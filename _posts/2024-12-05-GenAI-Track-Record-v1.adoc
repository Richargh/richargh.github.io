---
title: Generative AI Track record
permalink: /posts/gen-ai-track-record/
tags: genai ai llm
comments: false
status: ongoing
---

//https://poloclub.github.io/transformer-explainer/

// McDonalds order errors
// NY legal errors

== 2024-11-27 link:https://www.theverge.com/2024/11/27/24307284/microsoft-debunks-office-ai-data-scraping-rumors[Microsoft says it isn’t using M360 data to train AI models]
* Microsoft says it isn’t using customer data from its Microsoft 365 apps to train its AI models.
* The confusion arose from a privacy setting in Microsoft Office that toggles “optional connected experiences”

== 2024-11-21 link:https://www.businessinsider.com/microsoft-copilot-oversharing-problem-fix-customers-2024-11[Microsoft Copilot shares sensitive information, ignoring rights]
* A [Microsoft] Copilot security issue that inadvertently let employees access sensitive information such as CEO emails and HR documents.
* Microsoft Copilot and Github Copilot are different services. The first one is integrated into M365, the latter into IDEs to generate code.

== 2024-11-13 link:https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai[OpenAI, Google and Anthropic are struggling to build more advanced AI]
* [OpenAis new Model] Orion fell short when trying to answer coding questions that it hadn’t been trained on
* An upcoming iteration of [Google's] Gemini software is not living up to internal expectations
* Anthropic, meanwhile, has seen the timetable slip for the release of its long-awaited Claude model called 3.5 Opus.
* The companies are facing several challenges.
** It’s become increasingly difficult to find new, untapped sources of high-quality, human-made training data that can be used to build more advanced AI systems.
** Even modest improvements may not be enough to justify the tremendous costs associated with building and operating new models
* “We got very excited for a brief period of very fast progress, That just wasn’t sustainable.”
* Like Google and Anthropic, OpenAI is now shifting attention from the size of these models to newer use cases, including a crop of AI tools called agents that can book flights or send emails on a user’s behalf.

== 2024-10-21 link:https://www.ciodive.com/news/gartner-symposium-keynote-AI/730486/[Gartner sounds alarm on AI cost, data challenges]
* CIOs are still in search of the generative AI sweet spot where workflows are enhanced, but costs and risks are manageable
* Nearly half of CIOs say AI has not yet met ROI expectations, according to Gartner research.
* “The truth is that you’ve been in the mud for the last year, working hard to find all those benefits that were promised by AI,”
* Part of the disillusionment business leaders are feeling comes from the immaturity of the technology and the pace of innovation.
* “Cost is as big an AI risk as security. With generative AI, it’s really easy to waste money.”
* CIOs could miscalculate AI costs by as much as 1,000% as they scale AI plans, Gartner research suggests.
* “Set aside all that hype and focus on your pace,” LeHong said. “Choose the one that’s right for you and run your own race.”

// 2024-10-07 link:https://arxiv.org/pdf/2410.05229[Understanding the Limitations of Mathematical Reasoning in Large Language Models]

== 2024-09-27 link:https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html[OpenAI Is Growing Fast and Burning Through Piles of Money]
* OpenAI’s monthly revenue hit $300 million in August, up 1,700 percent since the beginning of 2023, and the company expects about *$3.7 billion in annual sales* this year
* Roughly *10 million* ChatGPT users pay the company a *$20 monthly fee*, according to the documents. OpenAI expects to raise that price by $2 by the end of the year, and will aggressively raise it to $44 over the next five years
* It expects to *lose roughly $5 billion* this year after paying for costs related to running its services
* [They are planning] an investment round that could bring in $7 billion and value the company at $150 billion, among the highest ever for a private tech company

== 2024-09-16 link:https://www.cio.com/article/3540579/devs-gaining-little-if-anything-from-ai-coding-assistants.html[CIO: Devs gaining little (if anything) from AI coding assistants]
* Uplevel, using data generated by its customers, compared the output of about 800 developers using GitHub Copilot over a three-month period to their output in a three-month period before adoption.
* The study measured pull request (PR) cycle time, or the time to merge code into a repository, and PR throughput, the number of pull requests merged. It found *no significant improvements* for developers using Copilot.
* Use of GitHub Copilot also introduced *41% more bugs*

//== 2024-09-16 link:https://www.wheresyoured.at/subprimeai/[The Subprime AI Crisis] The AI Bubble implosion

== 2024-09-20 link:https://edition.cnn.com/2024/09/20/energy/three-mile-island-microsoft-ai/index.html[Microsoft revives the nuclear reactor that was responsible for the worst nuclear disaster in US history, to power its AI efforts]
* Three Mile Island, the site of worst nuclear disaster in the United States, is reopening and will exclusively sell the power to Microsoft as the company searches for energy sources to fuel its AI ambitions.
* The Unit 1 reactor, which closed five years ago, is expected to be revived in 2028


// == 2024-09-05 link:https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566[The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers]

== 2024-08-23 link:https://www.ciodive.com/news/generative-ai-hype-moment-reckoning-trough-disillusionment-gartner/725033/[GenerativeAI on the Gartner HypeCycle - Trough of disillusionment]
* Enthusiasm for generative AI shows signs of cooling
* In Gartner’s annual Hype Cycle for Emerging Technologies report, the research and advisory company placed generative AI past the peak of inflated expectations, and down the path towards what it calls the *trough of disillusionment*.
* Unhappiness with the technology — likely stems from three areas:
** Current models are versatile but mainly general purpose, and enterprises have struggled to steer them into enterprise use cases.
** Organizations have underestimated the challenge of setting up governance and data infrastructure for these capabilities.
** The initial wave of generative AI solutions, while valuable, may not be delivering the high promise vendors claimed.
* “It would be a loss if the short-term disillusionment results in enterprises completely pulling away from AI”

== 2024-07-29 link:https://www.gartner.com/en/newsroom/press-releases/2024-07-29-gartner-predicts-30-percent-of-generative-ai-projects-will-be-abandoned-after-proof-of-concept-by-end-of-2025[Gartner Predicts 30% of Generative AI Projects Will Be Abandoned After Proof of Concept By End of 2025]
* At least 30% of generative AI (GenAI) projects will be abandoned after proof of concept by the end of 2025, due to poor data quality, inadequate risk controls, escalating costs or unclear business value

== 2024-07-03 link:https://www.datacenterknowledge.com/sustainability/google-s-emissions-shot-up-48-over-five-years-due-to-ai[Google’s Emissions Shot Up 48% Over Five Years Due to AI]
* According to a new environmental report from [Google]
* [The] emissions climbed by almost half over five years
* [It'll be hard] to meet [their] goal of eliminating carbon emissions by 2030

== 2024-06-29 link:https://www.theguardian.com/business/article/2024/jun/29/ai-drive-brings-microsofts-green-moonshot-down-to-earth-in-west-london[AI drive brings Microsoft’s ‘green moonshot’ down to earth in west London]
* [AI] ambition is jarring with its target of being carbon negative by 2030.
* the company’s scope 3 emissions – such as CO2 related to the materials in its buildings and the electricity people consume when using products such as Xbox – are *more than 30% above* their 2020 level.

== 2024-06-29 link:https://www.goldmansachs.com/images/migrated/insights/pages/gs-research/gen-ai--too-much-spend%2C-too-little-benefit-/TOM_AI%202.0_ForRedaction.pdf[Goldman Sachs on Gen Ai: Too much spend, too little benefit?]
* Tech giants and beyond are set to spend over $1tn on AI capex in coming years, with so far little to show for it.
* AI’s “killer application” has yet to emerge

// 2024-05-13 link:https://www.mdpi.com/2076-3417/14/10/4115[The Impact of Large Language Models on Programming Education and Student Learning Outcomes]

== 2024-04-14 link:https://mastodon.social/@nixCraft/112269408187496933[Sam Altman, We have no idea how we may one day generate revenue]
[quote, Sam Altman - CEO of OpenAI]
____
We have no current plans to make revenue. We have no idea how we may one day generate revenue. We have made a soft promise to investors that once we build this generally intelligent system, basically we will ask it to figure out an investment return for you.
____

== 2024-04-06 link:https://archive.ph/2BYtu[NY Times: How Tech Giants Cut Corners to Harvest Data for A.I.]
Big Tech has no more sources of data to tap, for their scaling ideas.
* In late 2021, OpenAI faced a *supply problem*.
** It needed more data to train the next version of its technology — lots more. So OpenAI researchers created a speech recognition tool called Whisper. It could transcribe the audio from YouTube videos...
** But YouTube prohibits people from not only using its videos for “independent” applications, but also accessing its videos by “any automated means (such as robots, botnets or scrapers).”
** Ultimately, an OpenAI team transcribed more than one million hours of YouTube videos,
* Meta
** But by early [2023], Meta had hit the same hurdle as its rivals: not enough data.
** Meta’s vice president of generative A.I., told executives that his team had used almost every available English-language book, essay, poem and news article on the internet to develop a model
** Discussed buying the publishing house Simon & Schuster to procure long works
** They also conferred on gathering copyrighted data from across the internet, even if that meant facing lawsuits. Negotiating licenses [...] would take too long
* Google
** transcribed YouTube videos to harvest text for its A.I. models. That potentially violated the copyrights to the videos, which belong to their creators.
** [Google] didn’t stop OpenAI because [they] had also used transcripts of YouTube videos to train its A.I. models
** [Their licensing terms also changed allowing them] to tap *publicly available Google Docs*
* The volume of data is crucial. Leading chatbot systems have learned from pools of digital text spanning as many as three trillion words, or roughly twice the number of words stored in Oxford University’s Bodleian Library, which has collected manuscripts since 1602.
* The most prized data, A.I. researchers said, is high-quality information, such as published books and articles, which have been carefully written and edited by professionals.
* “The data needed is so massive that even collective licensing really can’t work.”
* “Scale is all you need”
* Synthetic data
** [aka] text generated by A.I.
** “As long as you can get over the synthetic data event horizon, where the model is smart enough to make good synthetic data, everything will be fine,”
** Easier said than done. [they] can get caught in a loop where they reinforce their own quirks, mistakes and limitations.

== 2024-02-12 link:https://arxiv.org/abs/2402.08021[Careless Whisper: Speech-to-Text Hallucination Harms]
* We evaluate Open AI's Whisper [...] we find that roughly 1\% of audio transcriptions contained entire hallucinated phrases or sentences which did not exist in any form in the underlying audio [... and of those] 38\% of hallucinations include explicit harms.

// 2024-01-09 link:https://codescene.com/hubfs/whitepapers/Refactoring-vs-Refuctoring-Advancing-the-state-of-AI-automated-code-improvements.pdf[Refactoring vs Refuctoring: Advancing the state of AI-automated code improvements]

== 2023-10-06 link:https://en.wikipedia.org/wiki/Gemini_(chatbot)[Google Bard is relaunched as Gemini]
* the company's "largest and most capable AI model"

== 2023-10-09 link:https://www.neowin.net/news/microsoft-reportedly-is-losing-lots-of-money-per-user-on-github-copilot/[Microsoft reportedly is losing lots of money per user on GitHub Copilot]
* [Github Copilot] is available now for $10 a month or $100 for a year's subscription.
* In the first few months of this year, [Microsoft] was *losing n average more than $20 a month* per user, according to a person familiar with the figures, who said some users were costing [Microsoft] as much as *$80 a month*.

== 2023-09 link:https://en.wikipedia.org/wiki/DALL-E[DALL-E 3 revealed]
* capable of understanding "significantly more nuance and detail" than previous iterations.

== 2023-06-19 link:https://www.theregister.com/2023/06/19/even_google_warns_its_own/[Google warns its own employees: Do not use code generated by Bard]
* Google has warned its own employees not to disclose confidential information or use the code generated by its AI chatbot, Bard.
* Other large firms have similarly cautioned their staff against leaking proprietary documents or code, and have banned them using other AI chatbots.
* [Google] told Reuters its internal ban was introduced because Bard can output "undesired code suggestions." Issues could potentially lead to buggy programs or complex, bloated software that will cost developers more time to fix than if they didn't use AI to code at all.

== 2023-04-06 link:https://jonathanturley.org/2023/04/06/defamed-by-chatgpt-my-own-bizarre-experience-with-artificiality-of-artificial-intelligence/[ChatGPT invented a sexual harassment scandal and named a real law prof as the accused]
* I have been writing about the threat of AI to free speech. Then recently I learned that ChatGPT falsely reported on a claim of sexual harassment that was *never made* against me on a trip that *never occurred* while I was on a faculty where I *never taught*. ChapGPT relied on a cited Post article that was *never written* and quotes a statement that was *never made* by the newspaper.

== 2023-03 link:https://en.wikipedia.org/wiki/ChatGPT#Model_versions[ChatGPT release]
* Based on GPT 4 (Generative Pre-trained Transformer)

== 2023-02-24 link:https://en.wikipedia.org/wiki/Llama_(language_model)[Meta LLaMA is announced]

== 2023-02-06 link:https://en.wikipedia.org/wiki/Gemini_(chatbot)[Google Bard is announced]
* Multiple media outlets and financial analysts described Google as "rushing" Bard's announcement to preempt rival Microsoft's planned February 7 event unveiling its partnership with OpenAI to integrate ChatGPT into its Bing search engine
* After an "underwhelming" February 8 livestream in Paris showcasing Bard, Google's stock fell eight percent, equivalent to a $100 billion loss in market value, and the YouTube video of the livestream was made private.

== 2022-11 link:https://en.wikipedia.org/wiki/ChatGPT#Model_versions[First ChatGPT release]
* Based on GPT 3.5 (Generative Pre-trained Transformer)
* Gained one million users in five days and 100 millions in two months, becoming the fastest-growing internet application in history.

'''

== 2022-06-22 link:https://www.neowin.net/news/github-copilot-is-now-generally-available-starts-at-10month/[GitHub Copilot is now generally available, starts at $10/month]
* More than 1.2 million users enrolled in the preview for GitHub Copilot since June 2021.
* The program is now available to *all developers for $10/month* and $100/year.
* Verified students and owners of established open-source projects can keep using it for free.
* The extension is available on numerous editors such as Visual Studio, Visual Studio Code, Neovim, and JetBrains IDEs.
* The extension works well with multiple coding languages with notable ones being Python, JavaScript, TypeScript, and Go.

== 2022-04-06 link:https://en.wikipedia.org/wiki/DALL-E[DALL-E 2 revealed]
* designed to generate more realistic images at higher resolutions that "can combine concepts, attributes, and styles".

== 2021-01-05 link:https://en.wikipedia.org/wiki/DALL-E[DALL-E 1 revealed]
* uses a version of GPT-3 modified to generate images.
* The software's name is a portmanteau of the names of animated robot Pixar character WALL-E and the Catalan surrealist artist Salvador Dalí.

'''

== 2017-06-12 link:https://arxiv.org/abs/1706.03762[Attention is all you need]
* We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.

A Google paper that lays the foundation upon which all generative AI tools are based on.