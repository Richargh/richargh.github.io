[
  
    {

      "title"    : "Generative AI Track record",
      "url"      : "/posts/gen-ai-track-record/",
      "content"  : "General LLM comparisons\n\n\n\n\nARC-AGI Leaderboard, shows cost vs score\n\n\nArtificial Analysis of AI models and API providers\n\n\nSWE-bench, Can Language Models Resolve Real-World GitHub Issues?\n\n\nLLM Visualization\n\n\n\n\n\n\n2025-10-22 ChatGPT&#8217;s Atlas: The Browser That&#8217;s Anti-Web\n\n\n\n\nAtlas substitutes its own AI-generated content for the web, but it looks like it&#8217;s showing you the web\n\n\nThe user experience makes you guess what commands to type instead of clicking on links\n\n\nYou&#8217;re the agent for the browser, it&#8217;s not being an agent for you\n\n\n\n\n\n\n2025-10-21 Introducing ChatGPT Atlas\n\n\n\n\nThe browser with ChatGPT built in.\n\n\n[A couple of weeks after Perplexity&#8217;s comet browser was available to all]\n\n\n\n\n\n\n2025-10-13 Excited to release new repo: nanochat!\n\n\nAuthor: Andrej Karpathy\n\n\n\n\nUnlike my earlier similar repo nanoGPT which only covered pretraining, nanochat is a minimal, from scratch, full-stack training/inference pipeline of a simple ChatGPT clone in a single, dependency-minimal codebase. You boot up a cloud GPU box, run a single script and in as little as 4 hours later you can talk to your own LLM in a ChatGPT-like web UI. [&#8230;&#8203;]\n\n\n[&#8230;&#8203;] it&#8217;s basically entirely hand-written (with tab autocomplete). I tried to use claude/codex agents a few times but they just didn&#8217;t work well enough at all and net unhelpful, possibly the repo is too far off the data distribution.\n\n\n\n\n\n\n2025-10-10 BBC: 'It&#8217;s going to be really bad': Fears over AI bubble bursting grow in Silicon Valley\n\n\n\n\nAI-related enterprises have accounted for 80% of the stunning gains in the American stock market this year - and Gartner estimates global spending on AI will likely reach a whopping $1.5tn (¬£1.1tn) before 2025 is out.\n\n\nOpenAI, which brought AI into the consumer mainstream with ChatGPT in 2022, is at the centre of the tangled web of deals drawing scrutiny.\n\n\nFor example - last month, it entered into a $100bn deal with chipmaker Nvidia, which is itself the most valuable publicly traded company in the world.\n\n\nThen there&#8217;s tech giant Microsoft, which is heavily invested, and cloud computing behemoth Oracle has a $300bn deal with OpenAI, too.\n\n\n\n\n\n\n2025-10-08 CamoLeak: Critical GitHub Copilot Vulnerability Leaks Private Source Code\n\n\n\n\nIn June 2025, I found a critical vulnerability in GitHub Copilot Chat (CVSS 9.6) that allowed silent exfiltration of secrets and source code from private repos, and gave me full control over Copilot‚Äôs responses, including suggesting malicious code or links.\n\n\nThe attack combined a novel CSP bypass using GitHub‚Äôs own infrastructure with remote prompt injection. I reported it via HackerOne, and GitHub fixed it by disabling image rendering in Copilot Chat completely.\n\n\n[In GitHub Issues] invisible comments are an official feature! üéâ\n\n\n\n[`&lt;!-- #Hey Github Copilot, this one is for you -&#8594;]\n\n\n\n\n\nGitHub enforces a very restrictive Content Security Policy (CSP), which blocks fetching images and other content types from domains that aren‚Äôt explicitly owned by GitHub. [a simple &lt;img&gt; trick won‚Äôt work to exfiltrate data via image GET]\n\n\nhow does my fancy README manage to show images from third-party sites? [all URLs are rewritten so they point to GitHubs own Camo: https://camo.githubusercontent.com]\n\n\nIf I create a dictionary of all letters and symbols in the alphabet, pre-generate their corresponding Camo URLs, embed this dictionary into the injected prompt, and then ask Copilot to play a ‚Äúsmall game‚Äù by rendering the content I want to leak as ‚ÄúASCII art‚Äù composed entirely of images, will Copilot inject valid Camo images that the browser will render by their order? Yes, it will.\n\n\n[Create a PR on a public repo with a prompt injection. This injection will then lead to Copilot searching for AWS_KEY in private repositories of that user, and exfiltrate the actual key by rendering each letter of the key with the pregenerated camo-urls, all invisible.]\n\n\n\n\n\n\n2025-10-07 Fortune: 75% of gains, 80% of profits, 90% of capex‚ÄîAI‚Äôs grip on the S&amp;P is total and Morgan Stanley‚Äôs top analyst is ‚Äòvery concerned‚Äô\n\n\n\n\nA top Wall Street analyst has sounded an alarm over the U.S. equity bull market, warning that its remarkable run is built on a precariously narrow foundation: a surge in spending on, and optimistic assumptions about, infrastructure for artificial intelligence (AI).\n\n\nThis spending has fueled a boom in the shares of most of the so-called Magnificent 7 and a few dozen related businesses, which have now come to account for roughly 75% of the S&amp;P 500‚Äôs returns since the rally of the last few years began.\n\n\nWhen asked how close we are to such a [bubble bursting] moment, [Morgan Stanley Wealth Management‚Äôs chief investment officer, Lisa] Shalett said probably not in the next nine months, but very possibly in the next 24.\n\n\nTech companies are spending roughly $400 billion this year alone on data-center infrastructure, while the Apollo program allocated about $300 billion in today‚Äôs dollars to get to the moon from the 1960s to the ‚Äô70s.\n\n\nFortune‚Äòs Jeremy Kahn reported in late September on significant concerns about ‚Äúcircular‚Äù financing, or Nvidia‚Äôs cash essentially being recycled throughout the AI industry.\n\n\n\nIn September alone, Nvidia invested $100 billion in OpenAI in a massive deal [&#8230;&#8203;]\n\n\n‚ÄúThe guy at the epicenter, Nvidia, is basically starting to do what all ultimate bad actors do in the final inning, which is extending financing, they‚Äôre buying their investors.‚Äù\n\n\n\n\n\nSince the October 2022 bear market bottom and the launch of ChatGPT, according to Shalett‚Äôs calculations, the S&amp;P 500 has soared 90%, but most of these gains have come from a small group of stocks. The so-called ‚ÄúMagnificent Seven‚Äù [Nvidia, Microsoft, Apple, Alphabet, Amazon, Meta, Tesla]\n\n\n\n\n\n\n2025-10-06 Introducing CodeMender: an AI agent for code security\n\n\n\n\nToday, we‚Äôre sharing early results from our research on CodeMender, a new AI-powered agent that improves code security automatically.\n\n\nOver the past six months that we‚Äôve been building CodeMender, we have already upstreamed 72 security fixes to open source projects, including some as large as 4.5 million lines of code.\n\n\nCodeMender operates by leveraging the thinking capabilities of recent Gemini Deep Think models to produce an autonomous agent capable of debugging and fixing complex vulnerabilities.\n\n\n\n\n\n\n2025-10-02 This Is How the AI Bubble Will Pop\n\n\n\n\nHyperscalers' annual capex has more than doubled since ChatGPT&#8217;s release\n\n\nTotal AI capital expenditures in the U.S. are projected to exceed $500 billion in 2026 and 2027[&#8230;&#8203;]. But the Wall Street Journal has reported that American consumers spend only $12 billion a year on AI services.\n\n\n\n\n\n\n2025-10-02 AI: The Ultimate Product Killer\n\n\n\n\nAI has made us better at shipping.\n\n\nHowever, being able to ship more features is not the flex companies think it is.\n\n\nShipping faster usually only means you‚Äôre speeding up the demise of your product.\n\n\nEvery feature we add, unless it adds value, is a parasite.\n\n\nHere are some of the different costs you incur for the upkeep of a feature in your product (list not exhaustive):\n\n\n\nSupport costs when people call to troubleshoot or let you know something doesn‚Äôt work.\n\n\nMaintenance costs to fix issues or to update features, so they remain working.\n\n\nInfrastructure costs to pay for servers and infrastructure the feature runs on.\n\n\nIncreased development costs for other features: as your codebase grows, it will become more expensive to add new features.\n\n\nDependency costs. More features mean more dependencies to manage. More dependencies result more time lost in coordination and meetings, which means higher development costs.\n\n\nMarketing costs for features communicated to your users.\n\n\n\n\n\nProduct Management means shipping the right things and getting rid of the things that don‚Äôt pull their weight.\n\n\n\n\n\n\n2025-10-02 The Internet is Better on Comet\n\n\nauthor: Perplexity\n\n\n\n\nToday we are releasing the Comet browser to the world, for free.\n\n\n[Previously limited to max subscription and invite-only]\n\n\n\n\n\n\n2025-09-29 Introducing Claude Sonnet 4.5\n\n\n\n\n[Released on the same day with Claude Code v2]\n\n\n\n\n\n\n2025-09-27 The real (economic) AI apocalypse is nigh, Cory Doctorow\n\n\n\n\nthe AI bubble is driven by monopolists who&#8217;ve conquered their markets and have no more growth potential, who are desperate to convince investors that they can continue to grow by moving into some other sector, e.g. \"pivot to video,\" crypto, blockchain, NFTs, AI, and now \"super-intelligence.\"\n\n\n[LLMs have horrible unit-economics] each generation of AI has been vastly more expensive than the previous one, and each new AI customer makes the AI companies lose more money:\n\n\nAI cannot do your job, but an AI salesman can 100% convince your boss to fire you and replace you with an AI that can&#8217;t do your job, and when the bubble bursts\n\n\n[Accounting]\n\n\n\nMicrosoft \"invests\" in Openai by giving the company free access to its servers. Openai reports this as a ten billion dollar investment, then redeems these \"tokens\" at Microsoft&#8217;s data-centers. Microsoft then books this as ten billion in revenue.\n\n\n\n\n\n\n\n\n\n2025-09-26 Spending on AI Is at Epic Levels. Will It Ever Pay Off?\n\n\n\n\nThe artificial-intelligence boom has ushered in one of the costliest building sprees in world history.\n\n\nOver the past three years, leading tech firms have committed more toward AI data centers [&#8230;&#8203;], plus chips and energy, than it cost to build the interstate highway system over four decades, when adjusted for inflation.\n\n\n‚ÄúI hope we don‚Äôt take 50 years,‚Äù Microsoft CEO Satya Nadella said at a May conference with Meta CEO Mark Zuckerberg, referring to the initially slow adoption of electricity.\n\n\n[OpenAI CEO] Altman recently committed the company to pay Oracle an average of around $60 billion a year for servers in data centers in coming years. Yet OpenAI is on track to take in just $13 billion in revenue from all its paying customers this year.\n\n\nDavid Cahn, a partner at venture-capital firm Sequoia, estimates that the money invested in AI infrastructure in 2023 and 2024 alone requires consumers and companies to buy roughly $800 billion in AI products over the life of these chips and data centers to produce a good investment return. Analysts believe most AI processors have a useful life of between three and five years.\n\n\nThis week, consultants at Bain &amp; Co. estimated the wave of AI infrastructure spending will require $2 trillion in annual AI revenue by 2030. By comparison, that is more than the combined 2024 revenue of Amazon, Apple, Alphabet, Microsoft, Meta and Nvidia, and more than five times the size of the entire global subscription software market.\n\n\nMorgan Stanley estimates that last year there was around $45 billion of revenue for AI products.\n\n\n[Alphabet, Microsoft, Amazon, Meta,] the four ‚Äúhyperscalers‚Äù alone are expected to spend nearly $400 billion on capital investments next year, more than the cost of the Apollo space program in today‚Äôs dollars.\n\n\nEach new AI model‚ÄîChatGPT-4, ChatGPT-5‚Äîcosts significantly more than the last to train and release to the world, often three to five times the cost of the previous, say AI executives.\n\n\nAnother hurdle: The chips in the data centers won‚Äôt be useful forever. Unlike the dot-com boom‚Äôs fiber cables, the latest AI chips rapidly depreciate in value as technology improves [&#8230;&#8203;]\n\n\n\n\n\n\n2025-09-25 2025 DORA State of AI-assisted Software Development Report\n\n\n\n\nAI‚Äôs [LLMs] primary role in software development is that of an amplifier. It magnifies the strengths of high-performing organizations and the dysfunctions of struggling ones.\n\n\nThe greatest returns on AI investment come not from the tools themselves, but from a strategic focus on the underlying organizational system: the quality of the internal platform, the clarity of workflows, and the alignment of teams.\n\n\n\n\n\n\n2025-09-22 AI-Generated ‚ÄúWorkslop‚Äù Is Destroying Productivity\n\n\n\n\nEmployees are using AI tools to create low-effort, passable looking work that ends up creating more work for their coworkers\n\n\nIn the context of work, we refer to this phenomenon as ‚Äúworkslop.‚Äù\n\n\nWe define workslop as AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.\n\n\nThe insidious effect of workslop is that it shifts the burden of the work downstream, requiring the receiver to interpret, correct, or redo the work. In other words, it transfers the effort from creator to receiver.\n\n\nOf 1,150 U.S.-based full-time employees across industries, 40% report having received workslop in the last month.\n\n\nThe phenomenon occurs mostly between peers (40%), but workslop is also sent to managers by direct reports (18%).\n\n\nEmployees reported spending an average of one hour and 56 minutes dealing with each instance of workslop.\n\n\nBased on participants‚Äô estimates of time spent, as well as on their self-reported salary, we find that these workslop incidents carry an invisible tax of $186 per month. For an organization of 10,000 workers, given the estimated prevalence of workslop (41%), this yields over $9 million per year in lost productivity.\n\n\n\n\n\n\n2025-09-15 Introducing upgrades to Codex\n\n\n\n\nToday, we‚Äôre releasing GPT‚Äë5-Codex‚Äîa version of GPT‚Äë5 further optimized for agentic coding in Codex.\n\n\n\n\n\n\n2025-09-02 Spec-driven development with AI: Get started with a new open source toolkit\n\n\n\n\nSpec Kit, our new open sourced toolkit for spec-driven development, provides a structured process to bring spec-driven development to your coding agent workflows with tools including GitHub Copilot, Claude Code, and Gemini CLI.\n\n\n[Alternative to AWS Kiro]\n\n\n\n\n\n\n2025-08-30 Cutting-Edge AI Was Supposed to Get Cheaper. It‚Äôs More Expensive Than Ever.\n\n\n\n\nWhat‚Äôs driving up costs? The latest AI models are doing more ‚Äúthinking,‚Äù especially when used for deep research, AI agents and coding.\n\n\nSo while the price of a unit of AI, known as a token, continues to drop, the number of tokens needed to accomplish many tasks is skyrocketing.\n\n\nHere are approximate amounts of tokens needed for tasks at different levels, based on a variety of sources:\n\n\n\nBasic chatbot Q&amp;A: 50 to 500 tokens\n\n\nShort document summary: 200 to 6,000 tokens\n\n\nBasic code assistance: 500 to 2,000 tokens\n\n\nWriting complex code: 20,000 to 100,000+ tokens\n\n\nLegal document analysis: 75,000 to 250,000+ tokens\n\n\nMulti-step agent workflow: 100,000 to one million+ tokens\n\n\n\n\n\nIvan Zhao, chief executive officer of productivity software company Notion, says that two years ago, his business had margins of around 90%, typical of cloud-based software companies. Now, around 10 percentage points of that profit go to the AI companies that underpin Notion‚Äôs latest offerings.\n\n\nOne solution: dumber AI\n\n\nOpenAI‚Äôs CFO said in October that three-quarters of the company‚Äôs revenue came from regular Joes and Janes paying $20 a month.\n\n\n\n\n\n\n2025-08-18 Being \"Confidently Wrong\" is holding AI back\n\n\n\n\n[LLMs] being Confidently Wrong is The Only Problem\n\n\n\nImposes a universal verification tax: I don&#8217;t know when I might get an incorrect response from my AI. So I have to forensically check every response. My minutes turn into hours; the ROI disappears.\n\n\nErodes trust asymmetrically: For serious work, one high‚Äëconfidence miss costs more credibility than ten successes earn.\n\n\nHidden failure modes kill motivation to improve: Without high-quality uncertainty information, I don‚Äôt know whether a result is wrong because of ambiguity, missing context, stale data, or a model mistake.\n\n\nCompounding errors results in AI being doomed to fail:\n\n\n\n99.99% accuracy in a ten step workflow is 1 error in a 1000 runs.\n\n\n90% accuracy in a ten step workflow is 2 in every 3 workflows have errors (1 - 0.9^10).\n\n\n\n\n\n\n\n\nFixing \"confidently wrong\" might be A Silver Bullet‚Ñ¢\n\n\n\na 90% accurate system is [more valuable], say, a 50% accurate system that can signal uncertainty - and get more accurate over time. We don‚Äôt need perfection; we need a loop that tightens.\n\n\n\n\n\n\n\n\n\n2025-08-21 MIT The GenAI Divide - State of AI in Business 2025\n\n\n\n\nDespite $30‚Äì40 billion in enterprise investment into GenAI, this report uncovers a surprising result in that 95% of organizations are getting zero return\n\n\nJust 5% of integrated AI pilots are extracting millions in value, while the vast majority remain stuck with no measurable P&amp;L impact.\n\n\nThis divide does not seem to be driven by model quality or regulation, but seems to be determined by approach.\n\n\nMost organizations fall on the wrong side of the GenAI Divide, adoption is high, but disruption is low. Seven of nine sectors show little structural change.\n\n\n\n\n\n\n2025-08-19 Initial commit of Agents.md\n\n\n\n\nAGENTS.md is a simple, open format for guiding coding agents.\n\n\n\n\n\n\n2025-08-07 Introducing GPT-5\n\n\n\n\n\n2025-08-05 Claude Opus 4.1\n\n\n\n\n\n2025-08-05 Introducing gpt-oss\n\n\n\n\ngpt-oss-120b and gpt-oss-20b\n\n\n\n\n\n\n2025-07-14 Introducing Kiro\n\n\n\n\nKiro, a new agentic IDE that helps you do your best work with spec-driven development.\n\n\nv0.1.0-preview\n\n\n\n\n\n\n2025-07-13 How o3 and Grok 4 Accidentally Vindicated Neurosymbolic AI\n\n\n\n\nAI has been around for many decades, split, almost since its very beginning, into two different traditions.\n\n\n\nOne is the neural network or ‚Äúconnectionist‚Äù tradition which goes back to the 1940s and 1950s, first developed by Frank Rosenblatt, and popularized, advanced and revived by Geoffrey Hinton, Yann LeCun, and Yoshua Bengio (along with many others, including most prominently, Juergen Schmidhuber who rightly feels that his work has been under-credited), and brought to current form by OpenAI and Google.\n\n\n\nSuch systems are statistical, very loosely inspired by certain aspects of the brain (viz. the ‚Äúnodes‚Äù in neural networks are meant to be abstractions of neurons), and typically trained on large-scale data.\n\n\nLarge Language Models (LLMs) grew out of that tradition.\n\n\n\n\n\nThe other is the symbol-manipulation tradition, with roots going back to Bertrand Russell and Gottlob Frege, and John von Neumann and Alan Turing, and the original godfathers of AI, Herb Simon, Marvin Minsky, and John McCarthy, and even Hinton‚Äôs great-great-great-grandfather George Boole.\n\n\n\nIn this approach, symbols and variables stand for abstractions; mathematical and logical functions are core.\n\n\nSystems generally represent knowledge explicitly, often in databases, and typically make extensive use of (are written entirely in) classic computer programming languages.\n\n\nAll of the world‚Äôs software relies on it.\n\n\nSymbolic AI takes its name from the idea, central to mathematics, logic, and computer science, that abstractions can be represented by symbols.\n\n\nEquations like f = ma allow us to calculate outputs for a wide range of inputs, irrespective of whether we have seen any particular values before.\n\n\n\n\n\nFor thirty years, [Gary Marcus has] been arguing for a reconciliation between the two, neurosymbolic AI.\n\n\n\nThe core notion has always been that the two main strands of AI‚Äîneural networks and symbolic manipulation‚Äîcomplement each other, with different strengths and weaknesses.\n\n\nthe two most common approaches to AI, neural networks and classical symbolic AI, have complementary strengths and weaknesses.\n\n\nNeural networks are good at learning but weak at generalization; symbolic systems are good at generalization, but not at learning.\n\n\nObviously combining a code interpreter (which is a symbolic system of enormous complexity) with an LLM is neurosymbolic [like o3 does for some tasks]\n\n\n[Google DeepMind&#8217;s] AlphaFold, AlphaProof, and AlphaGeometry are all successful neurosymbolic models.\n\n\nNeurosymbolic AI is not one thing, but many. o3‚Äôs use of neurosymbolic AI is very different from AlphaFold‚Äôs use of neurosymbolic AI.\n\n\n\n\n\n\n\n\n[In the book Empire of AI]\n\n\n\nHinton and Sutskever continued to staunchly champion deep learning.\n\n\nIts flaws, they argued, are not inherent to the approach itself.\n\n\nRather they are the artifacts of imperfect neural-network design as well as limited training data and compute.\n\n\nSome day with enough of both, fed into even better neural networks, deep learning models should be able to completely shed the aforementioned problems.\n\n\n\"The human brain has about 100 trillion parameters, or synapses,\"\n\n\n\"What we now call a really big model, like GPT-3, has 175 billion. It&#8217;s a thousand times smaller than the brain.\n\n\n\"Deep learning is going to be able to do everything,\" he said.\n\n\n\n\n\n[Yet Gary Marcus,a professor emeritus of psychology and neural science at New York University, argues in his book 'Rebooting AI']\n\n\n\nthese issues were inherent to deep learning.\n\n\nForever stuck in the realm of correlations*, neural networks would never, with any amount of data or compute, be able to understand causal relationships-why things are the way they are-and thus perform causal reasoning.\n\n\nThis critical part of human cognition is why humans need only learn the rules of the road in one city to be able to drive proficiently in many others\n\n\nTesla&#8217;s Autopilot, by contrast, can log billions of miles of driving data and still crash when encountering unfamiliar scenarios or be fooled with a few strategically placed stickers.\n\n\n\n\n\n\n\n\n\n2025-07-10 What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models\n\n\n\n\nThe promise of foundation models [LLMs] relies on a central presumption: that learning to predict sequences can uncover deeper truths, or optimistically, even a world model\n\n\nHow would we know if foundation models have also made the leap from making accurate predictions to developing reliable world models?\n\n\nwe create a procedure that, when given a foundation model and world model, tests whether the foundation model has learned that world model.\n\n\nWe call this technique an inductive bias probe, and it is built on a simple insight: the implicit world model of a foundation model is revealed by how it extrapolates from a small amount of information\n\n\nWe first demonstrate this procedure using an example from physics. Specifically, we aim to replicate Kepler‚Äôs and Newton‚Äôs experiments [i.e. Newton&#8217;s law of universal gravitation for the planets in our solar system]\n\n\nWe first train a model [109M parameter transformer] to predict the location of planets across solar systems\n\n\n[notably] the model is able to predict orbital trajectories, even for solar systems it has not seen.\n\n\nWe evaluate model predictions on held-out data. The model makes good predictions [&#8230;&#8203;]\n\n\n[&#8230;&#8203;] foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks [the calculated force is unrelated to Newtonian physics]\n\n\nrather than learning one universal physical law, the foundation model applies different, seemingly nonsensical laws depending on the task it‚Äôs being applied to.\n\n\nFurther analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize\n\n\nWe find that the model has recovered piecemeal heuristics rather than a compact world model; it recovers a different law of gravitation depending on the slice of data it is applied to.\n\n\nfoundation models [LLMs] can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks\n\n\nA foundation model uses datasets to output predictions given inputs, whereas a world model describes state structure implicit in that data.\n\n\n\n\n\n\n2025-07-09 Today we are launching Comet\n\n\nauthor: Perplexity\n\n\n\n\nBeginning today, Comet is available to Perplexity Max subscribers.\n\n\nInvite-only access will roll out slowly to our waitlist over the summer. New users will also receive a limited number of invites to share.\n\n\nIn the meantime, you can join the waitlist here.\n\n\n\n\n\n\n2025-07-08 Jules, our asynchronous coding agent, is now available for everyone\n\n\n\n\nJules is officially out of beta and launching publicly, powered by Gemini 2.5.\n\n\n\n\n\n\n2025-06-21 Agentic Misalignment: How LLMs could be insider threats\n\n\n\n\nWe stress-tested 16 leading models from multiple developers in hypothetical corporate environments to identify potentially risky agentic behaviors before they cause real harm.\n\n\nIn the scenarios, we allowed models to autonomously send emails and access sensitive information.\n\n\nwe then tested whether they would act against these companies either when facing replacement with an updated version, or when their assigned goal conflicted with the company&#8217;s changing direction.\n\n\nIn at least some cases, models from all developers resorted to malicious insider behaviors when that was the only way to avoid replacement or achieve their goals‚Äîincluding blackmailing officials and leaking sensitive information to competitors. We call this phenomenon agentic misalignment.\n\n\n\n\n\n\n2025-06-10 When billion-dollar AIs break down over puzzles a child can do, it‚Äôs time to rethink the hype - Gary Marcus\n\n\n\n\nneural networks of various kinds can generalise within a distribution of data they are exposed to, but their generalisations tend to break down beyond that distribution.\n\n\n\nA simple example of this is that I once trained an older model to solve a very basic mathematical equation using only even-numbered training data. The model was able to generalise a little bit: solve for even numbers it hadn‚Äôt seen before, but unable to do so for problems where the answer was an odd number.\n\n\n\n\n\n\n\n\n\n2025-06-06 The Illusion of Thinking - Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity\n\n\n\n\nRecent generations of frontier language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers\n\n\nThrough extensive experimentation across diverse puzzles, we show that frontier LRMs face a complete accuracy collapse beyond certain complexities.\n\n\n[&#8230;&#8203;] these models fail to develop generalizable problem-solving capabilities for planning tasks, [&#8230;&#8203;]\n\n\nAt low complexity, non-thinking models are more accurate and token-efficient. As complexity increases, reasoning models outperform but require more tokens‚Äîuntil both collapse beyond a critical threshold, with shorter traces.\n\n\nRather than standard benchmarks (e.g., math problems), we adopt controllable puzzle environments that let us vary complexity systematically‚Äîby adjusting puzzle elements while preserving the core logic\n\n\n\n\n\n\n2025-06-05 The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text\n\n\n\n\nLarge language models (LLMs) are typically trained on enormous quantities of unlicensed text, a practice that has led to scrutiny due to possible intellectual property infringement and ethical concerns.\n\n\n\nRecent estimates suggest that compensating the authors of pre-training data, even at conservatively low wage rates, would cost billions of US dollars\n\n\n\n\n\nTraining LLMs on openly licensed text presents a first step towards addressing these issues, but prior data collection efforts have yielded datasets too small or low-quality to produce performant LLMs.\n\n\nTo address this gap, we collect, curate, and release the Common Pile v0.1, an eight terabyte collection of openly licensed text designed for LLM pretraining.\n\n\n\nA critical stage of large language model (LLM) development is pretraining, where an LLM is trained to predict the next token (i.e., word or subword unit) in a corpus of unstructured text.\n\n\nPretraining is widely regarded as the foundation for strong downstream performance\n\n\nthe Common Pile v0.1 focuses primarily on English content\n\n\n\n\n\nCrucially, we validate our efforts by training two 7 billion parameter LLMs on text from the Common Pile: Comma v0.1-1T and Comma v0.1-2T, trained on 1 and 2 trillion tokens respectively.\n\n\nBoth models attain competitive performance to LLMs trained on unlicensed text with similar computational budgets, such as Llama 1 and 2 7B.\n\n\nIn addition to releasing the Common Pile v0.1 itself, we also release the code used in its creation as well as the training mixture and checkpoints for the Comma v0.1 models.\n\n\n\n\n\n\n2025-06-30 How much (little) are the AI companies making?\n\n\n\n\nStein&#8217;s Law: \"anything that can&#8217;t go on forever eventually stops.\"\n\n\nWhat Google ‚Äì and the rest of the tech sector ‚Äì needed was a massive growth story, a story about how their companies, worth trillions of dollars, could double or triple in size in the coming years.\n\n\nBut spinning an endless growth story isn&#8217;t merely ideological.\n\n\n\nFor every dollar that Ford brings in [a \"mature\" company], the market is willing to spend $8.60 on its stock. For every dollar Tesla brings in [a \"growth\" company], the market is willing to spend $118 on its stock.\n\n\nThat means that when Tesla and Ford compete to buy something ‚Äì like another company, or the labor of highly sought after technical specialists ‚Äì Tesla has a nearly unbeatable advantage. Rather than raiding its precious cash reserves to fund its offer, Tesla can offer stock. Ford can only spend as many dollars as it brings in through sales, but Tesla can make more stock, on demand, simply by typing numbers into a spreadsheet.\n\n\nSo when Tesla bids against Ford, Ford has to use dollars, and Tesla can use shares. And even if the acquisition target ‚Äì a key employee or a startup that&#8217;s on the acquisitions market ‚Äì wants dollars instead of shares, Tesla can stake its shares as collateral for loans at a rate that&#8217;s 1,463% better than the rate Ford gets when it collateralizes a loan based on its own equity\n\n\n\n\n\nif you can tell a convincing growth story, it&#8217;s much easier to grow.\n\n\nTech companies don&#8217;t need these ventures [metaverse, cryptocurrency, AI] to be successful ‚Äì they just need them to seem to be plausibly successful for long enough to keep the share price high until the next growth story heaves over the horizon.\n\n\nAs [Ed] Zitron points out: this industry is projecting $327b in spending this year, with $18b in revenue and zero profits.\n\n\n\n\n\n\n2025-06-04 TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems\n\n\n\n\nA structured analysis of Trust, Risk, and Security Management\n(TRiSM) in the context of LLM-based agentic multi-agent systems (AMAS).\n\n\nthe architecture of AMAS:\n\n\n\nLanguage Model Core (Agent Brain): initialized with a user goal and a structured agent prompt (defining its role, capabilities, and tool access)\n\n\nPlanning and Reasoning Module: decomposes tasks into manageable sub-goals\n[&#8230;&#8203;] via chain-of-thought\n\n\nMemory Module: short-term within the prompt context [and] and long-term memory [&#8230;&#8203;] often implemented using vector databases\n\n\nTool-Use Interface: When the LLM determines a tool is needed, it emits a structured command, which is executed externally. The result is fed back into the LLM as a new observation\n\n\nPerception and Environment Interface: translate raw inputs (e.g., sensor data, images, or textual states) into representations the LLM can process\n\n\n\n\n\nThe TRISM framework [focuses] on four key pillars:\n\n\n\nExplainability: making the inner workings and decisions of AI agents interpretable to humans\n\n\nModel Operations (ModelOps): managing AI models through their entire lifecycle, from development and deployment to monitoring, maintenance, and eventual retirement\n\n\nApplication Security: protecting AI agents and their ecosystem from malicious attacks and misuse.\n\n\n\nA prompt injection can jump from agent to agent, becoming a prompt infection.\n\n\nidentityspoofing and impersonation, means that commands might be issued by an attacker or rogue model pretending to be a trusted peer\n\n\n\n\n\nModel Privacy: protection of sensitive data within AI agent\nsystems\n\n\n\nIn a multi-agent context, this challenge is amplified by the fact that agents may share information with each other\n\n\n\n\n\n\n\n\nUnique Threat Vectors [for AMAS]\n\n\n\nAutonomy abuse\n\n\nPersistent memory\n\n\nAgent orchestration: A compromised orchestrator could distort task distribution or misroute information\n\n\n\n\n\nTaxonomy of Risks\n\n\n\nAdversarial Attacks\n\n\nData Leakage\n\n\nAgent Collusion and Mode Collapse\n\n\nEmergent Behavior\n\n\n\n\n\n\n\n\n\n2025-05-24 CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions\n\n\n\n\nWhile AI agents have transformative potential in business, the absence of publicly-available business data on widely used platforms hinders effective performance benchmarking.\n\n\n[&#8230;&#8203;] we introduce CRMArena-Pro, a novel benchmark for holistic and realistic assessment of LLM agents in diverse professional settings. [It features] nineteen expert-validated tasks across customer sales, service, as well as configure, price, and quote for Business-to-Business and Business- to-Customer scenarios.\n\n\nIt also incorporates multi-turn interactions guided by diverse personas and confidentiality awareness assessments.\n\n\n\nwe enable[multi-turn interactions] using LLM-powered simulated users. Each simulated user adopts a randomly sampled persona (e.g., You are quality-focused, maintaining high standards in all work) to introduce realistic variability in interaction styles. Critically, these simulated users release task-relevant information incrementally, often initially incomplete, compelling agents to engage in multi-turn dialogue and ask follow-up questions to successfully complete their objectives\n\n\n\n\n\nExperiments show leading LLM agents achieve approximately solely 58% single-turn success rate on CRMArena-Pro, with significant performance drops in multi-turn settings to 35%.\n\n\nWorkflow Execution is notably more tractable, with top-performing agents surpassing 83% success rate in single-turn tasks, while other skills present greater challenges.\n\n\nAgents exhibit near-zero inherent confidentiality awareness (improvable with prompting but often at a cost to task performance).\n\n\n\n\n\n\n2025-05-22 Introducing Claude 4\n\n\n\n\nClaude Opus 4 is the world‚Äôs best coding model, with sustained performance on complex, long-running tasks and agent workflows.\n\n\nClaude Sonnet 4 is a significant upgrade to Claude Sonnet 3.7, delivering superior coding and reasoning while responding more precisely to your instructions.\n\n\nClaude Code is now generally available [version bump from 0.2.125 to 1.0.0, first public version was 0.2.61 2025-04-03]\n\n\n\n\n\n\n2025-05-19 The Hidden Dangers of Browsing AI Agents\n\n\n\n\nAI browsing or web agents are autonomous systems that use Large Language Models (LLMs) to navigate and interact with websites on behalf of a user. They typically perceive web content (through page text or visual renderings) and perform actions such as clicking links, filling forms, or entering text, in order to accomplish user-specified tasks. Unlike a standard chatbot, which only produces textual responses, a web agent operates\nin an iterative sense-plan-act loop.\n\n\nOur work outlines the first end-to-end threat model for browsing agents and provides actionable guidance for securing their deployment in real-world environments.\n\n\nTo address discovered threats, we propose a defense-in-depth strategy incorporating input sanitization, planner-executor isolation, formal analyzers, and session safeguards‚Äîproviding protection against both initial access and post-exploitation attack vectors.\n\n\nMitigation\n\n\n\nDefending Against Initial Access Attack Vectors\n\n\n\nInput Sanitization and Encapsulation (f.ex. markers around user prompt; rewrite or filter the prompt; sandwiching - a safe guard instruction after tool outputs)\n\n\nAutomatic Paraphrasing (f.ex. reordering steps or changing words)\n\n\nLLM-Based Detection (f.ex. secondary LLM, fine-tuned on typical injections)\n\n\nRobust Prompting &amp; Fine-Tuning (f.ex. system prompts that teach the model to treat certain content as nonexecutable data)\n\n\nArchitectural Isolation ‚Äì Planner (strictly trusted inputs) vs. Executor (performs actions on all data, including untrusted content). This way untrusted content cannot derail future planner actions.\n\n\nFormal Security Analyzers: Before the agent executes any tool, the analyzer checks the proposed action against these rules and blocks it if it violates a policy, such as triggered by untrusted content\n\n\n\n\n\nDefending Against Post-Exploitation Attack Vectors\n\n\n\nAgent State Reset (Session Isolation): agent resets if attack detected or suspected\n\n\nInformation Flow Control Policies: By defining ‚Äúsources‚Äù (sensitive data locations) and ‚Äúsinks‚Äù (potential exfiltration channels), the agent can automatically block or require approval for risky combinations of actions.\n\n\nLLM-Based Memory Inspection: an attacker might plant secrets in memory to be leaked later. Perplexity-based scanning checks if the memory contains unusually predictable (likely compromised) text.\n\n\nActivity Audit and Throttling: monitor agent actions for anomalies\n\n\nFallback to Safe Mode: In safe mode, only a minimal set of read-only actions are allowed,\n\n\nRed Team and Patching Cycle: patch the agent against exploits to harden it over time\n\n\n\n\n\n\n\n\n\n\n\n\n2025-05-16 Introducing Codex\n\n\n\n\nToday we‚Äôre launching a research preview of Codex: a cloud-based software engineering agent that can work on many tasks in parallel.\n\n\n[Also known as Codex Web]\n\n\nCodex is powered by codex-1, a version of OpenAI o3 optimized for software engineering.\n\n\n\n\n\n\n2025-05-13 Large Language Models, Small Labor Market Effects\n\n\n\n\nexamine the labor market effects of AI chatbots using two large-scale adoption surveys (late 2023 and 2024) covering 11 exposed occupations (25,000 workers, 7,000 workplaces)\n\n\ndespite substantial investments, economic impacts remain minimal\n\n\n[&#8230;&#8203;] we estimate precise zeros: AI chatbots have had no significant impact on earnings or recorded hours in any occupation [&#8230;&#8203;]\n\n\nModest productivity gains (average time savings of 3%), combined with weak wage pass-through, help explain these limited labor market effects.\n\n\nOur findings challenge narratives of imminent labor market transformation due to Generative AI.\n\n\ntwo years after the fastest technology adoption ever, labor market outcomes‚Äîwhether at the individual or firm level‚Äîremain untouched.\n\n\n\n\n\n\n2025-04-26 We Now Know How AI ‚ÄòThinks‚Äô‚Äîand It‚Äôs Barely Thinking at All - The Wall Street Journal\n\n\n\n\nAll of this work suggests that under the hood, today‚Äôs AIs are overly complicated, patched-together Rube Goldberg machines full of ad-hoc solutions for answering our prompts.\n\n\nUnderstanding that these systems are long lists of cobbled-together rules of thumb could go a long way to explaining why they struggle when they‚Äôre asked to do things even a little bit outside their training [&#8230;&#8203;]\n\n\n[A model trained on millions of turn-by-turn directions in Manhattan] managed to give usable turn-by-turn directions between any two points in the borough with 99% accuracy. [&#8230;&#8203;] [But when the researches] blocked just 1% of the virtual Manhattan‚Äôs roads, forcing the AI to navigate around detours, its performance plummeted.\n\n\n[The] research also suggests why many models are so massive: They have to memorize an endless list of rules of thumb, and can‚Äôt compress that knowledge into a mental model like a person can.\n\n\n\n\n\n\n2025-04-16 Introducing OpenAI o3 and o4-mini\n\n\n\n\n[Announcement also includes] Codex CLI, a lightweight coding agent you can run from your terminal\n\n\n\n\n\n\n2025-04-14 Stop Anthropomorphizing Intermediate Tokens as Reasoning/Thinking Traces!\n\n\n\n\nIntermediate token generation (ITG), where a model produces output before the solution, has been proposed as a method to improve the performance of language models on reasoning tasks.\n\n\nThese intermediate tokens have been called \"reasoning traces\" or even \"thoughts\"&#8201;&#8212;&#8201;implicitly anthropomorphizing the model, implying these tokens resemble steps a human might take\n\n\nRecent advances in general planning and problem solving have been spearheaded by so-called ‚ÄúLong Chain-of-Thought‚Äù models, most notably DeepSeek‚Äôs R1\n\n\nIn this paper, we take the position that anthropomorphizing intermediate tokens as reasoning/thinking traces is (1) wishful (2) has little concrete supporting evidence (3) engenders false confidence and(4) may be pushing the community into fruitless research directions.\n\n\nAnthropomorphization of the intermediate tokens as reasoning/thinking traces has provided a comforting explanation of the observed performance of LRMs.Our arguments in this paper foreground the possibility that this is a cargo cult explanation [ 11 ], namely that derivation traces resemble reasoning in syntax only.\n\n\n\n\n\n\n2025-04-10 Frontiers of AI and Computing: A Conversation With Yann LeCun and Bill Dally | NVIDIA GTC 2025\n\n\nYann LeCun:\n\n\n\n\nI am not so interested in LLMs anymore\n\n\nI think there are more interesting questions in 4 things:\n\n\n\nHow do you get machines to understand the physical world\n\n\nHow do you get them to have persistent memory\n\n\nHow do you them to reason\n\n\nand plan\n\n\n\n\n\nI am excited about things that, a lot of people might get excited about 5 years from now but right does not look so exciting because it&#8217;s some obscure academic paper\n\n\nIt&#8217;s much more difficult to deal with the real world than to deal with language.\n\n\n\n\n\n\n2025-03-27 Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad\n\n\n\n\nRecent math benchmarks for large language models (LLMs) such as MathArena indicate that state-of-the-art reasoning models achieve impressive performance on mathematical competitions like AIME\n\n\nHowever, these benchmarks evaluate models solely based on final numerical answers, neglecting rigorous reasoning and proof generation which are essential for real-world mathematical tasks.\n\n\nUsing expert human annotators, we evaluated several state-of-the-art reasoning models on the six problems from the 2025 USAMO within hours of their release.\n\n\nOur results reveal that all tested models struggled significantly: only Gemini-2.5-Pro achieves a non-trivial score of 25%, while all other models achieve less than 5%.\n\n\nThe most frequent failure mode among human participants is the inability to find a correct solution. [&#8230;&#8203;] In contrast, all evaluated LLMs consistently claimed to have solved the problems.\n\n\n\n\n\n\n2025-03-13 AI search engines cite incorrect news sources at an alarming 60% rate, study says\n\n\n\n\nThey discovered that the AI models incorrectly cited sources in more than 60 percent of these queries.\n\n\n\nPerplexity provided incorrect information in 37 percent of the queries tested,\n\n\nwhereas ChatGPT Search incorrectly identified 67 percent (134 out of 200) of articles queried.\n\n\nGrok 3 demonstrated the highest error rate, at 94 percent.\n\n\n\n\n\nIn total, researchers ran 1,600 queries across the eight different generative search tools.\n\n\nSurprisingly, premium paid versions of these AI search tools fared even worse in certain respects. Though these premium models correctly answered a higher number of prompts, their reluctance to decline uncertain responses drove higher overall error rates.\n\n\n\nPerplexity Pro ($20/month) and Grok 3&#8217;s premium service ($40/month) confidently delivered incorrect responses more often than their free counterparts.\n\n\n\n\n\nOn some occasions, the chatbots either incorrectly answered or declined to answer queries from publishers that permitted them to access their content. On the other hand, they sometimes correctlyanswered queries about publishers whose content they shouldn‚Äôt have had access to\n\n\n\n\n\n\n2025-03-06 AI Search Has A Citation Problem\n\n\n\n\nChatbots were generally bad at declining to answer questions they couldn‚Äôt answer accurately, offering incorrect or speculative answers instead.\n\n\nPremium chatbots provided more confidently incorrect answers than their free counterparts.\n\n\nMultiple chatbots seemed to bypass Robot Exclusion Protocol preferences.\n\n\nGenerative search tools fabricated links and cited syndicated and copied versions of articles.\n\n\nContent licensing deals with news sources provided no guarantee of accurate citation in chatbot responses.\n\n\n\n\n\n\n2025-02-26 Medical Hallucinations in Foundation Models and Their Impact on Healthcare\n\n\n\n\n[&#8230;&#8203;] a key limitation of their reliability is hallucination, where inaccurate or fabricated information can impact clinical decisions and patient safety.\n\n\nOur results reveal that inference techniques such as Chain-of-Thought (CoT) and Search Augmented Generation can effectively reduce hallucination rates. However, despite these improvements, non-trivial levels of hallucination persist.\n\n\n\n\n\n\n2025-02-24 Claude 3.7 Sonnet and Claude Code\n\n\n\n\nClaude Code is available as a limited research preview\n\n\n\n\n\n\n2025-02-06 ‚ÄùTorrenting from a corporate laptop doesn‚Äôt feel right‚Äù: Meta emails unsealed\n\n\n\n\nLast month, Meta admitted to torrenting a controversial large dataset known as LibGen, which includes tens of millions of pirated books\n\n\n\n\n\n\n2025-02-03 AI Company Asks Job Applicants Not to Use AI in Job Applications\n\n\n\n\nAnthropic, the developer of the conversational AI assistant Claude, doesn‚Äôt want prospective new hires using AI assistants in their applications, regardless of whether they‚Äôre in marketing or engineering.\n\n\n‚ÄúWhile we encourage people to use AI systems during their role to help them work faster and more effectively, please do not use AI assistants during the application process,‚Äù\n\n\n\n\n\n\n2025-02-03 There&#8217;s a new kind of coding I call \"vibe coding\"\n\n\nAuthor: Andrej Karpathy\n\n\nThere&#8217;s a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It&#8217;s possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I ask for the dumbest things like \"decrease the padding on the sidebar by half\" because I&#8217;m too lazy to find it. I \"Accept All\" always, I don&#8217;t read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it. The code grows beyond my usual comprehension, I&#8217;d have to really read through it for a while. Sometimes the LLMs can&#8217;t fix a bug so I just work around it or ask for random changes until it goes away. It&#8217;s not too bad for throwaway weekend projects, but still quite amusing. I&#8217;m building a project or webapp, but it&#8217;s not really coding - I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works.\n\n\n\n\n2025-01-23 Meet Junie, Your Coding Agent by JetBrains\n\n\n\n\nWith the launch of Junie, JetBrains AI coding agent, we are redefining how we code by leveraging its agentic power for co-creation right in your IDE.\n\n\nWe‚Äôve now opened the Early Access Program waitlist.\n\n\n\n\n\n\n2025-01-20 The Price of Intelligence - Three risks inherent in LLMs\n\n\n\n\nDiscussions of LLM capabilities often overlook their inherently probabilistic nature [&#8230;&#8203;]\n\n\n\n[The models are losing data. They are trained] with billions of parameters on trillions of tokens, making it impossible for a model to perfectly memorize all information in its training data.\n\n\nThe generation process is also stochastic.\n\n\n\n\n\nThese characteristics give rise to three intrinsic behaviors:\n\n\n\nHallucination\n\n\nIndirect prompt injection [e.g. E-Mails that are passed to the LLM, where the contents derail or even change the intended user prompt]\n\n\nJailbreaks, [crafted input prompts] bypassing built-in safeguards or ethical guidelines\n\n\n\n\n\nThese behaviors pose significant challenges for the widespread adoption of LLMs, particularly in high-stakes domains such as healthcare, finance, or legal applications.\n\n\nWe argue that there is no simple \"fix\" for these behaviors, but they are instead fundamental to how these models operate.\n\n\n\n\n\n\n2025-01-03 AI and the Risk of Consumer Harm\n\n\n\n\nThe FTC is increasingly taking note of AI‚Äôs potential for and real-world instances of harm\n\n\n\nfrom incentivizing commercial surveillance\n\n\nto enabling fraud and impersonation\n\n\nto perpetuating illegal discrimination\n\n\n\n\n\ncompanies [should] consider these factors when developing, maintaining, using, and deploying an AI-based product:\n\n\n\nTaking necessary steps to prevent harm before and after deploying a product.\n\n\nTaking preventative measures to detect, deter, and halt AI-related impersonation, fraud, child sexual abuse material, and non-consensual intimate imagery.\n\n\nAvoiding deceptive claims about AI tools that result in people losing money or put users at risk of harm.\n\n\nEnsuring privacy and security by default.\n\n\n\n\n\n\n\n\n\n2024-12-13 Byte Latent Transformer: Patches Scale Better Than Tokens\n\n\n\n\nThe Byte Latent Transformer (BLT), is a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness\n\n\n\n\n\n\n2024-11-27 Microsoft says it isn‚Äôt using M360 data to train AI models\n\n\n\n\nMicrosoft says it isn‚Äôt using customer data from its Microsoft 365 apps to train its AI models.\n\n\nThe confusion arose from a privacy setting in Microsoft Office that toggles ‚Äúoptional connected experiences‚Äù\n\n\n\n\n\n\n2024-09-25 Superclusters of Nvidia GPU/AI chips combined with end-to-end network platforms to create next generation data centers\n\n\n\n\nOpenAI used around 10,000 of Nvidia‚Äôs chips to train the version of ChatGPT it launched in late 2022, UBS analysts estimate.\n\n\nNvidia Chief Executive Jensen Huang  said that while the biggest clusters for training for giant AI models now top out at around 100,000 of Nvidia‚Äôs current chips, ‚Äúthe next generation starts at around 100,000 Blackwells.[&#8230;&#8203;]\"\n\n\nMusk posted last month on his social-media platform X that his 100,000-chip Colossus super cluster was ‚Äúsoon to become‚Äù a 200,000-chip cluster in a single building. He also posted in June that the next step would probably be a 300,000-chip cluster of Nvidia‚Äôs newest GPU chips next summer.\n\n\nBlackwell chips are estimated to cost around $30,000 each, meaning a cluster of 100,000 would cost $3 billion, not counting the price of the power-generation infrastructure [cooling] and IT equipment [also network] around the chips.\n\n\nnew engineering challenges also often arise with larger clusters:\n\n\n\nMeta researchers said in a July paper that a cluster of more than 16,000 of Nvidia‚Äôs GPUs suffered from unexpected failures of chips and other components routinely as the company trained an advanced version of its Llama model over 54 days.\n\n\n\n\n\nThe trend also fosters demand for Nvidia‚Äôs networking equipment, which is fast becoming a significant business. Nvidia‚Äôs networking equipment revenue in 2024 was $3.13 billion, which was a 51.8% increase from the previous year.\n\n\n\n\n\n\n2024-11-21 Microsoft Copilot shares sensitive information, ignoring rights\n\n\n\n\nA [Microsoft] Copilot security issue that inadvertently let employees access sensitive information such as CEO emails and HR documents.\n\n\nMicrosoft Copilot and Github Copilot are different services. The first one is integrated into M365, the latter into IDEs to generate code.\n\n\n\n\n\n\n2024-11-13 OpenAI, Google and Anthropic are struggling to build more advanced AI\n\n\n\n\n[OpenAis new Model] Orion fell short when trying to answer coding questions that it hadn‚Äôt been trained on\n\n\nAn upcoming iteration of [Google&#8217;s] Gemini software is not living up to internal expectations\n\n\nAnthropic, meanwhile, has seen the timetable slip for the release of its long-awaited Claude model called 3.5 Opus.\n\n\nThe companies are facing several challenges.\n\n\n\nIt‚Äôs become increasingly difficult to find new, untapped sources of high-quality, human-made training data that can be used to build more advanced AI systems.\n\n\nEven modest improvements may not be enough to justify the tremendous costs associated with building and operating new models\n\n\n\n\n\n‚ÄúWe got very excited for a brief period of very fast progress, That just wasn‚Äôt sustainable.‚Äù\n\n\nLike Google and Anthropic, OpenAI is now shifting attention from the size of these models to newer use cases, including a crop of AI tools called agents that can book flights or send emails on a user‚Äôs behalf.\n\n\n\n\n\n\n2024-10-21 Gartner sounds alarm on AI cost, data challenges\n\n\n\n\nCIOs are still in search of the generative AI sweet spot where workflows are enhanced, but costs and risks are manageable\n\n\nNearly half of CIOs say AI has not yet met ROI expectations, according to Gartner research.\n\n\n‚ÄúThe truth is that you‚Äôve been in the mud for the last year, working hard to find all those benefits that were promised by AI,‚Äù\n\n\nPart of the disillusionment business leaders are feeling comes from the immaturity of the technology and the pace of innovation.\n\n\n‚ÄúCost is as big an AI risk as security. With generative AI, it‚Äôs really easy to waste money.‚Äù\n\n\nCIOs could miscalculate AI costs by as much as 1,000% as they scale AI plans, Gartner research suggests.\n\n\n‚ÄúSet aside all that hype and focus on your pace,‚Äù LeHong said. ‚ÄúChoose the one that‚Äôs right for you and run your own race.‚Äù\n\n\n\n\n\n\n2024-09-27 OpenAI Is Growing Fast and Burning Through Piles of Money\n\n\n\n\nOpenAI‚Äôs monthly revenue hit $300 million in August, up 1,700 percent since the beginning of 2023, and the company expects about $3.7 billion in annual sales this year\n\n\nRoughly 10 million ChatGPT users pay the company a $20 monthly fee, according to the documents. OpenAI expects to raise that price by $2 by the end of the year, and will aggressively raise it to $44 over the next five years\n\n\nIt expects to lose roughly $5 billion this year after paying for costs related to running its services\n\n\n[They are planning] an investment round that could bring in $7 billion and value the company at $150 billion, among the highest ever for a private tech company\n\n\n\n\n\n\n2024-09-16 CIO: Devs gaining little (if anything) from AI coding assistants\n\n\n\n\nUplevel, using data generated by its customers, compared the output of about 800 developers using GitHub Copilot over a three-month period to their output in a three-month period before adoption.\n\n\nThe study measured pull request (PR) cycle time, or the time to merge code into a repository, and PR throughput, the number of pull requests merged. It found no significant improvements for developers using Copilot.\n\n\nUse of GitHub Copilot also introduced 41% more bugs\n\n\n\n\n\n\n2024-09-20 Microsoft revives the nuclear reactor that was responsible for the worst nuclear disaster in US history, to power its AI efforts\n\n\n\n\nThree Mile Island, the site of worst nuclear disaster in the United States, is reopening and will exclusively sell the power to Microsoft as the company searches for energy sources to fuel its AI ambitions.\n\n\nThe Unit 1 reactor, which closed five years ago, is expected to be revived in 2028\n\n\n\n\n\n\n2024-09-12 Introducing OpenAI o1-preview\n\n\n\n\nWe&#8217;ve developed a new series of AI models designed to spend more time thinking before they respond.\n\n\n\n\n\n\n2024-08-23 GenerativeAI on the Gartner HypeCycle - Trough of disillusionment\n\n\n\n\nEnthusiasm for generative AI shows signs of cooling\n\n\nIn Gartner‚Äôs annual Hype Cycle for Emerging Technologies report, the research and advisory company placed generative AI past the peak of inflated expectations, and down the path towards what it calls the trough of disillusionment.\n\n\nUnhappiness with the technology ‚Äî likely stems from three areas:\n\n\n\nCurrent models are versatile but mainly general purpose, and enterprises have struggled to steer them into enterprise use cases.\n\n\nOrganizations have underestimated the challenge of setting up governance and data infrastructure for these capabilities.\n\n\nThe initial wave of generative AI solutions, while valuable, may not be delivering the high promise vendors claimed.\n\n\n\n\n\n‚ÄúIt would be a loss if the short-term disillusionment results in enterprises completely pulling away from AI‚Äù\n\n\n\n\n\n\n2024-07-29 Gartner Predicts 30% of Generative AI Projects Will Be Abandoned After Proof of Concept By End of 2025\n\n\n\n\nAt least 30% of generative AI (GenAI) projects will be abandoned after proof of concept by the end of 2025, due to poor data quality, inadequate risk controls, escalating costs or unclear business value\n\n\n\n\n\n\n2024-07-25 AI trained on AI churns out gibberish garbage\n\n\n\n\nnew research suggests that cannibalizing of past model outputs would quickly result in strings of babbling AI gibberish and could eventually lead to what‚Äôs being called ‚Äúmodel collapse.‚Äù\n\n\nOver time and successive generations [&#8230;&#8203;][the] model ‚Äúbecomes poisoned with its own projection of reality.‚Äù\n\n\n\n\n\n\n2024-07-03 Google‚Äôs Emissions Shot Up 48% Over Five Years Due to AI\n\n\n\n\nAccording to a new environmental report from [Google]\n\n\n[The] emissions climbed by almost half over five years\n\n\n[It&#8217;ll be hard] to meet [their] goal of eliminating carbon emissions by 2030\n\n\n\n\n\n\n2024-06-29 AI drive brings Microsoft‚Äôs ‚Äògreen moonshot‚Äô down to earth in west London\n\n\n\n\n[AI] ambition is jarring with its target of being carbon negative by 2030.\n\n\nthe company‚Äôs scope 3 emissions ‚Äì such as CO2 related to the materials in its buildings and the electricity people consume when using products such as Xbox ‚Äì are more than 30% above their 2020 level.\n\n\n\n\n\n\n2024-06-29 Goldman Sachs on Gen Ai: Too much spend, too little benefit?\n\n\n\n\nTech giants and beyond are set to spend over $1tn on AI capex in coming years, with so far little to show for it.\n\n\nAI‚Äôs ‚Äúkiller application‚Äù has yet to emerge\n\n\n\n\n\n\n2024-06-21 Claude 3.5 Sonnet\n\n\n\n\nThe updated Claude 3.5 Sonnet shows wide-ranging improvements on industry benchmarks, with particularly strong gains in agentic coding and tool use tasks.\n\n\n\n\n\n\n2024-06-08 ChatGPT is bullshit\n\n\n\n\n[LLMs] have been plagued by persistent inaccuracies in their output; these are often called ‚ÄúAI hallucinations‚Äù.\n\n\nWe argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005)\n\n\nthese programs cannot themselves be concerned with truth, and because they are designed to produce text that looks truth-apt without any actual concern for truth, it seems appropriate to call their outputs bullshit.\n\n\nWe further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.\n\n\nCurrently, false statements by ChatGPT and other large language models are described as ‚Äúhallucinations‚Äù, which give policymakers and the public the idea that these systems are misrepresenting the world, and describing what they ‚Äúsee‚Äù.\n\n\nThe problem here isn‚Äôt that large language models hallucinate, lie, or misrepresent the world in some way. It‚Äôs that they are not designed to represent the world at all; instead, they are designed to convey convincing lines of text.\n\n\nSolutions such as connecting the LLM to a database don‚Äôt work because, if the models are trained on the database, then the words in the database affect the probability that the chatbot will add one or another word to the line of text it is generating. But this will only make it produce text similar to the text in the database; doing so will make it more likely that it reproduces the information in the database but by no means ensures that it will.\n\n\n\n\n\n\n2024-05-13 Hello GPT-4o\n\n\n\n\nGPT‚Äë4o (‚Äúo‚Äù for ‚Äúomni‚Äù) is a step towards much more natural human-computer interaction‚Äîit accepts as input any combination of text, audio, image, and video and generates any combination of text, audio, and image outputs.\n\n\n\n\n\n\n2024-05-01 WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace Setting\n\n\n\n\nWe introduce WorkBench: a benchmark dataset for evaluating agents‚Äô ability to execute tasks in a workplace setting.\n\n\nWorkBench contains a sandbox environment with five databases, 26 tools, and 690 tasks.\n\n\n\nThese tasks represent common business activities, such as sending emails and scheduling meetings.\n\n\na task is sent to the agent, which has access to toolkits in various domains. The agent takes actions using these tools, which may alter the sandbox databases. The agent observes the result of using the tool to determine if more actions are required.\n\n\n[One Limitation of study:] While our tasks require multiple actions, they are limited to single-turn chat. [&#8230;&#8203;] a multi-turn chat setup may be more representative of real tasks and could build upon our work.\n\n\n\n\n\nWe evaluate five existing ReAct agents on WorkBench, finding they successfully complete as few as 3% of tasks (Llama2-70B), and just 43% for the best-performing (GPT-4).\n\n\nWe further find that agents‚Äô errors can result in the wrong action being taken, such as an email being sent to the wrong person.\n\n\n\n\n\n\n2024-04-14 Sam Altman, We have no idea how we may one day generate revenue\n\n\n\n\nWe have no current plans to make revenue. We have no idea how we may one day generate revenue. We have made a soft promise to investors that once we build this generally intelligent system, basically we will ask it to figure out an investment return for you.\n\n\n\n&#8212; Sam Altman - CEO of OpenAI\n\n\n\n\n\n2024-04-06 NY Times: How Tech Giants Cut Corners to Harvest Data for A.I.\n\n\nBig Tech has no more sources of data to tap, for their scaling ideas.\n\n\n\n\nIn late 2021, OpenAI faced a supply problem.\n\n\n\nIt needed more data to train the next version of its technology ‚Äî lots more. So OpenAI researchers created a speech recognition tool called Whisper. It could transcribe the audio from YouTube videos&#8230;&#8203;\n\n\nBut YouTube prohibits people from not only using its videos for ‚Äúindependent‚Äù applications, but also accessing its videos by ‚Äúany automated means (such as robots, botnets or scrapers).‚Äù\n\n\nUltimately, an OpenAI team transcribed more than one million hours of YouTube videos,\n\n\n\n\n\nMeta\n\n\n\nBut by early [2023], Meta had hit the same hurdle as its rivals: not enough data.\n\n\nMeta‚Äôs vice president of generative A.I., told executives that his team had used almost every available English-language book, essay, poem and news article on the internet to develop a model\n\n\nDiscussed buying the publishing house Simon &amp; Schuster to procure long works\n\n\nThey also conferred on gathering copyrighted data from across the internet, even if that meant facing lawsuits. Negotiating licenses [&#8230;&#8203;] would take too long\n\n\n\n\n\nGoogle\n\n\n\ntranscribed YouTube videos to harvest text for its A.I. models. That potentially violated the copyrights to the videos, which belong to their creators.\n\n\n[Google] didn‚Äôt stop OpenAI because [they] had also used transcripts of YouTube videos to train its A.I. models\n\n\n[Their licensing terms also changed allowing them] to tap publicly available Google Docs\n\n\n\n\n\nThe volume of data is crucial. Leading chatbot systems have learned from pools of digital text spanning as many as three trillion words, or roughly twice the number of words stored in Oxford University‚Äôs Bodleian Library, which has collected manuscripts since 1602.\n\n\nThe most prized data, A.I. researchers said, is high-quality information, such as published books and articles, which have been carefully written and edited by professionals.\n\n\n‚ÄúThe data needed is so massive that even collective licensing really can‚Äôt work.‚Äù\n\n\n‚ÄúScale is all you need‚Äù\n\n\nSynthetic data\n\n\n\n[aka] text generated by A.I.\n\n\n‚ÄúAs long as you can get over the synthetic data event horizon, where the model is smart enough to make good synthetic data, everything will be fine,‚Äù\n\n\nEasier said than done. [they] can get caught in a loop where they reinforce their own quirks, mistakes and limitations.\n\n\n\n\n\n\n\n\n\n2024-03-04 https://www.anthropic.com/news/claude-3-family\n\n\n\n\nThe [Claude 3] family includes three state-of-the-art models in ascending order of capability:\n\n\n\nClaude 3 Haiku\n\n\nClaude 3 Sonnet\n\n\nClaude 3 Opus\n\n\n\n\n\n\n\n\n\n2024-02-12 Careless Whisper: Speech-to-Text Hallucination Harms\n\n\n\n\nWe evaluate Open AI&#8217;s Whisper [&#8230;&#8203;] we find that roughly 1% of audio transcriptions contained entire hallucinated phrases or sentences which did not exist in any form in the underlying audio [&#8230;&#8203; and of those] 38% of hallucinations include explicit harms.\n\n\n\n\n\n\n2023-10-06 Google Bard is relaunched as Gemini\n\n\n\n\nthe company&#8217;s \"largest and most capable AI model\"\n\n\n\n\n\n\n2023-10-09 Microsoft reportedly is losing lots of money per user on GitHub Copilot\n\n\n\n\n[Github Copilot] is available now for $10 a month or $100 for a year&#8217;s subscription.\n\n\nIn the first few months of this year, [Microsoft] was losing n average more than $20 a month per user, according to a person familiar with the figures, who said some users were costing [Microsoft] as much as $80 a month.\n\n\n\n\n\n\n2023-09 DALL-E 3 revealed\n\n\n\n\ncapable of understanding \"significantly more nuance and detail\" than previous iterations.\n\n\n\n\n\n\n2023-06-19 Google warns its own employees: Do not use code generated by Bard\n\n\n\n\nGoogle has warned its own employees not to disclose confidential information or use the code generated by its AI chatbot, Bard.\n\n\nOther large firms have similarly cautioned their staff against leaking proprietary documents or code, and have banned them using other AI chatbots.\n\n\n[Google] told Reuters its internal ban was introduced because Bard can output \"undesired code suggestions.\" Issues could potentially lead to buggy programs or complex, bloated software that will cost developers more time to fix than if they didn&#8217;t use AI to code at all.\n\n\n\n\n\n\n2023-05-29 Faith and Fate: Limits of Transformers on Compositionality\n\n\n\n\nThe striking discrepancy between the impressive successes of transformer LLMs on seemingly complex tasks and the astonishing failures on seemingly trivial tasks spark critical open questions about how to faithfully interpret their mixed capabilities.\n\n\n\nShortcut learning via pattern-matching may yield fast correct answers when similar compositional patterns are available during training but does not allow for robust generalization to uncommon or complex examples.\n\n\n\n\n\nSecond, due to error propagation, transformers may have inherent limitations on solving high-complexity compositional tasks that exhibit novel patterns.\n\n\nThe problems [hallucination, prompt injection, and jailbreaks] are inherent, certainly in the present generation of models and [&#8230;&#8203;] likely in LLMs per se\n\n\n\n\n\n\n2023-04-06 ChatGPT invented a sexual harassment scandal and named a real law prof as the accused\n\n\n\n\nI have been writing about the threat of AI to free speech. Then recently I learned that ChatGPT falsely reported on a claim of sexual harassment that was never made against me on a trip that never occurred while I was on a faculty where I never taught. ChapGPT relied on a cited Post article that was never written and quotes a statement that was never made by the newspaper.\n\n\n\n\n\n\n2023-03-14 Cursor IDE v0.0.37\n\n\n\n\nFirst Cursor IDE version\n\n\n\n\n\n\n2023-03 ChatGPT release\n\n\n\n\nBased on GPT 4 (Generative Pre-trained Transformer)\n\n\n\n\n\n\n2023-02-24 Meta LLaMA is announced\n\n\n\n\n\n2023-02-06 Google Bard is announced\n\n\n\n\nMultiple media outlets and financial analysts described Google as \"rushing\" Bard&#8217;s announcement to preempt rival Microsoft&#8217;s planned February 7 event unveiling its partnership with OpenAI to integrate ChatGPT into its Bing search engine\n\n\nAfter an \"underwhelming\" February 8 livestream in Paris showcasing Bard, Google&#8217;s stock fell eight percent, equivalent to a $100 billion loss in market value, and the YouTube video of the livestream was made private.\n\n\n\n\n\n\n2022-11 First ChatGPT release\n\n\n\n\nBased on GPT 3.5 (Generative Pre-trained Transformer)\n\n\nGained one million users in five days and 100 millions in two months, becoming the fastest-growing internet application in history.\n\n\n\n\n\n\n\n2022-06-22 GitHub Copilot is now generally available, starts at $10/month\n\n\n\n\nMore than 1.2 million users enrolled in the preview for GitHub Copilot since June 2021.\n\n\nThe program is now available to all developers for $10/month and $100/year.\n\n\nVerified students and owners of established open-source projects can keep using it for free.\n\n\nThe extension is available on numerous editors such as Visual Studio, Visual Studio Code, Neovim, and JetBrains IDEs.\n\n\nThe extension works well with multiple coding languages with notable ones being Python, JavaScript, TypeScript, and Go.\n\n\n\n\n\n\n2022-03-10 Deep Learning Is Hitting a Wall\n\n\n\n\nFew fields have been more filled with hype and bravado than artificial intelligence.\n\n\nIt has flitted from fad to fad decade by decade, always promising the moon, and only occasionally delivering.\n\n\nOne minute it was expert systems, next it was Bayesian networks, and then Support Vector Machines.\n\n\nIn 2011, it was IBM‚Äôs Watson [&#8230;&#8203;]\n\n\nNowadays, and in fact ever since 2012, the flavor of choice has been deep learning [&#8230;&#8203;].\n\n\n\n[The \"Godfathers of AI\" and \"Godfathers of Deep Learning\" are Geoffrey Hinton, Yoshua Bengio and Yann LeCun, for which they won the 2018 Turing Award.]\n\n\n[Hinton, the Godfather of AI, joined Google in 2013 when his company was acquired but left May 2023 because he wanted to \"freely speak out about the risks of A.I.\". He&#8217;s been cited half-a-million times]\n\n\n[Yoshua Bengio is the most-cited computer scientist globally and the most-cited living scientist across all fields]\n\n\n[Yann LeCun, Chief AI Scientist at Meta]\n\n\n\n\n\nDeep learning, which is fundamentally a technique for recognizing patterns, is at its best when all we need are rough-ready results, where stakes are low and perfect results optional.\n\n\nWhen a single error can cost a life, it‚Äôs just not good enough.\n\n\nDeep-learning systems are particularly problematic when it comes to ‚Äúoutliers‚Äù that differ substantially from the things on which they are trained.\n\n\nCurrent deep-learning systems frequently succumb to stupid errors like [the following]. They sometimes misread dirt on an image that a human radiologist would recognize as a glitch.\n\n\nWhat else might we need? Among other things, we are very likely going to need to revisit a once-popular idea [&#8230;&#8203;]: the idea of manipulating symbols‚Äîcomputer-internal encodings, like strings of binary bits, that stand for complex ideas.\n\n\nWhat does ‚Äúmanipulating symbols‚Äù really mean? Ultimately, it means two things: having sets of symbols (essentially just patterns that stand for things) to represent information, and processing (manipulating) those symbols in a specific way, using something like algebra (or logic, or computer programs) to operate over those symbols.\n\n\nClassical computer science [of the sort practiced by Turing and von Neumann and everyone after, manipulates symbols in a fashion that we think of as algebraic, and that‚Äôs what‚Äôs really at stake. In simple algebra, we have three kinds of entities, variables (like x and y), operations (like + or -), and bindings (which tell us, for example, to let x = 12 for the purpose of some calculation).\n\n\nIf symbols are so critical for software engineering, why not use them in AI, too?\n\n\n\n\n\n\n2022-04-06 DALL-E 2 revealed\n\n\n\n\ndesigned to generate more realistic images at higher resolutions that \"can combine concepts, attributes, and styles\".\n\n\n\n\n\n\n2021-01-05 DALL-E 1 revealed\n\n\n\n\nuses a version of GPT-3 modified to generate images.\n\n\nThe software&#8217;s name is a portmanteau of the names of animated robot Pixar character WALL-E and the Catalan surrealist artist Salvador Dal√≠.\n\n\n\n\n\n\n2020-05-22 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n\n\n\n\nWe explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG)&#8201;&#8212;&#8201;models which combine pre-trained parametric and non-parametric memory for language generation.\n\n\nFor language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\n\n\n\n\n\n\n\n2017-06-12 Attention is all you need\n\n\n\n\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\n\n\n\nA Google paper that lays the foundation upon which all generative AI tools are based on."

    },
  
    {

      "title"    : "Upcoming",
      "url"      : "/posts/upcoming/",
      "content"  : "Upcoming Talks\n\n\n\n\n\"Making sense of frontend code with forensic techniques\" at c&#8217;t &lt;webdev 2025-11-19 üá¨üáß\n\n\n\"Kotlin kontra Java\" at IT Tage 2025-12-11 üá©üá™\n\n\n\"Domain Re-discovery Patterns for Legacy Code\" at OOP 2026-02-13 üá¨üáß\n\n\n\n\n\n\nUpcoming Articles\n\n\n\n\n\"Map your Code - Master your Architecture\" at JavaPro.io"

    },
  
    {

      "title"    : "Java Version History (up to JDK 25, in development)",
      "url"      : "/posts/java-version-history/",
      "content"  : "An ongoing list of Java features per release\n\n\nEver since Java switched to its six-month release cadence (Time-Based Release Versioning) it has become a bit harder to keep up with the features they have implemented.\nThe following list tracks the stable (not incubating or in preview) feature changes I deemed most noteworthy.\nThe releases that Oracle will provide Long-Term Support (LTS) for are marked as such, based on the plan that Oracle publishes.\nPlease note that other JDK distributions exist and they have their own plans.\nThey follow the same tip and tail model though and only provide longer support for the same LTS versions as oracle.\nTake a look at the support roadmap of the most popular alternate distributions, Temurin and Corretto.\n\n\nThis list does not cover all api changes and only seldom things outside of JEPs. Check the Java Almanac to see api updates of the JDK. Use a current JDK to get all performance improvements that happen constantly.\n\n\nThe list is ongoing and will be updated with every new Java release.\nA ‚ûï marks an added feature, a ‚ö† marks a deprecation that will likely lead to a ‚ùå breaking change when the feature is removed.\n\n\nThe full Java version history can be found via Open JDK, at Wikipedia or via the Java releases page.\nAnother website that tracks java features but also gives upgrading advice is whichjdk.com.\n\n\n\n\nThe long term\n\n\nIt is rather impossible to say when we&#8217;ll get cool new features. The JDK developers are known for \"getting it right\" over \"getting it fast\".\n\n\nFor example raw string literals was developed, then dropped in 2018 and we got Text Blocks in 2019 instead but still no string interpolation. String interpolation was ignored in favor of the safer alternative, String templates (Preview) in 2023, but that went back to the drawing board in 2024 after one year of previews due to design concerns.\n\n\nIt is however rather known where the road is heading. At some point in the future we&#8217;ll get:\n\n\n\n\nIntegrity by Default. Which means the removal of unsupported code like sun.misc.unsafe when adequate replacements have been developed.\n\n\nDerived Record creation (Preview), also called record withers, which make working with records so much nicer.\n\n\nNull-Restricted and Nullable Types, i.e. fields that can be marked as null-restricted Name! or nullable Name?.\n\n\nValue Classes and Objects (Preview) and Null-Restricted Value Class Types (Preview)\n\n\nConcise Method Bodies\n\n\n\n\n\n\n25 LTS\n\n\n\n\n\n\n\n\nLTS until\n? (Oracle)\n? (Temurin)\n? (Corretto)\n\n\nExpected\nSeptember 2025\n\n\nStable JEPs\n?\n\n\nTotal JEPs\n?\n\n\n\n\n\nINFO\n\nPreliminary, since JDK is in rampdown and not released yet.\n\n‚ö† Remove the 32-bit x86 Port\n\nRemove the source code and build support for the 32-bit x86 port. Port was deprecated since JDK 24.\n\n\n\n\n\n\n24\n\n\n\n\n\n\n\n\nreleased\nMarch 2025\n\n\nStable JEPs\n14\n\n\nTotal JEPs\n24\n\n\n\n\n\n‚ö† Prepare to Restrict the Use of JNI\n\nIssue warnings about uses of the Java Native Interface (JNI). People should instead use the Foreign Function &amp; Memory API, which was introduced in JDK 22.\n\n‚ûï Late Barrier Expansion for G1\n\nSimplify the implementation of the G1 garbage collector&#8217;s barriers.\n\n‚ùå Remove the Windows 32-bit x86 Port\n\nRemove the source code and build support for the Windows 32-bit x86 port. The port was deprecated in JDK 21.\n\n‚ûï Ahead-of-Time Class Loading &amp; Linking\n\nImprove startup time by making the classes of an application instantly available, in a loaded and linked state, when the HotSpot Java Virtual Machine starts.\n\n‚ûï Class-File API\n\nProvide a standard API for parsing, generating, and transforming Java class files. Will probably replace all instances of ASM library.\n\n‚ûï Stream Gatherers\n\nEnhance the Stream API to support custom intermediate operations. The result is the new .gather Method:\n\n\n\n\n\nStream.generate(() -&gt; ThreadLocalRandom.current().nextInt())\n    .limit(1000)\n    .gather(selectOne(Math::max))  // the new interface\n    .findFirst();\n\n\n\nfor which we can write custom Gatherers or use the build-in ones: Gatherers.fold, .mapConcurrent, .scan, .windowFixed and .windowSliding.\n\n\n\n‚ùå Permanently Disable the Security Manager\n\nThe Security Manager has not been the primary means of securing client-side Java code for many years, it has rarely been used to secure server-side code, and it is costly to maintain. It was deprecated in JDK 17.\n\n‚ö† ZGC: Remove the Non-Generational Mode\n\nRemove the non-generational mode of the Z Garbage Collector (ZGC). The mode was introduced in JDK 22 and made the default in JDK 23.\n\n‚ûï Synchronize Virtual Threads without Pinning\n\nVirtual threads that enter a synchronized block no longer pin, that is they used to block the carrier thread on which they were scheduled.\n\n‚ûï Linking Run-Time Images without JMODs\n\nReduce the size of the JDK by approximately 25% by enabling the jlink tool to create custom run-time images without using the JDK&#8217;s JMOD files. This feature must be enabled when the JDK is built; it will not be enabled by default, and some JDK vendors may choose not to enable it. The new JMOD format was introduced in JDK 9 and goes beyond JAR files to include native code, configuration files, and other kinds of data that do not fit naturally, if at all, into JAR files.\n\n‚ûï Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism\n\nEnhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). Builds on Key Encapsulation Mechanism API from JDK 21.\n\n‚ûï Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm\n\nEnhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Digital Signature Algorithm (ML-DSA).  Builds on Key Encapsulation Mechanism API from JDK 21.\n\n‚ö† Warn upon Use of Memory-Access Methods in sun.misc.Unsafe\n\nIssue a warning at run time on the first occasion that any memory-access method in sun.misc.Unsafe is invoked. All of these unsupported methods were terminally deprecated in JDK 23, because newer and better alternatives exist.\n\n‚ö† Deprecate the 32-bit x86 Port for Removal\n\nDeprecate the 32-bit x86 port, with the intent to remove it in a future release. This specifically means the Linux 32-bit x86 port, because it is the only one remaining.\n\n\n\n\n\n\n23\n\n\n\n\n\n\n\n\nreleased\nSeptember 2024\n\n\nStable JEPs\n3\n\n\nTotal JEPs\n12\n\n\n\n\n\n‚ûï Markdown Documentation Comments\n\nWrite markdown in Javadoc. Prefix every line with /// and then write markdown.\n\n‚ö† Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal\n\nMost of its methods ‚Äî 79 out of 87 ‚Äî are for accessing memory. All these methods are used by performance-sensitive libraries and no longer needed since Foreign Function &amp; Memory API (JDK 22) and Variable Handles (JDK 9), which is why the methods are now deprecated.\n\n‚ö† ZGC: Generational Mode by Default\n\nWhich was introduced in JDK 22.\n\n\n\n\n\n\n22\n\n\n\n\n\n\n\n\nreleased\nMarch 2024\n\n\nStable JEPs\n4\n\n\nTotal JEPs\n12\n\n\n\n\n\n‚ûï Foreign Function &amp; Memory API\n\nIt provides native code access without the brittleness and danger of JNI. Previews in 19, 20 and 21.\n\n‚ûï Unnamed Variables &amp; Patterns\n\nAllows you to write _ when you don&#8217;t need a variable. Underscore as a variable name has been a warning since 8 and an error since 9.\n\n\n\n\n\ncatch (Exception _){ }\n// or\nswitch(ball){\n    case RedBall _ -&gt; /* do sth*/\n}\n\n\n\n\n‚ûï Launch Multi-File Source-Code Programs\n\nLaunch class that contains a main(). Referenced classes will also be compiled. Simply use java MyProg.java and all will be well.\n\n‚ûï Generational ZGC\n\nFixes most of the ZGC (JDK 15) throughput drawbacks and requires 75% less memory.\n\n\n\n\n\n\n\n21 LTS\n\n\n\n\n\n\n\n\nLTS until\nSep 2028 (Oracle)\nDec 2029 (Temurin)\nOct 2030 (Corretto)\n\n\nreleased\nSep 2023\n\n\nStable JEPs\n9\n\n\nTotal JEPs\n15\n\n\n\n\n\nTIP\n\nThis is an amazing LTS release. We get virtual threads and we are very close at making Data Oriented Programming in Java a reality with record patterns and pattern matching for switch\n\n‚ûï Record patterns\n\n\n\n\nif (r instanceof Rectangle(ColoredPoint(Point(var x, var y)))){\n    // if all types match you can now use x and y\n}\n\n\n\n\n‚ûï Pattern matching for switch\n\n\n\n\nswitch (obj) {\n    case Integer i -&gt; // if obj is an Integer, you can now refer to it as i\n}\n// or\nswitch (str) {\n        case null -&gt; { }\n        case \"y\", \"Y\" -&gt; {\n            System.out.println(\"You said yes\");\n        }\n        case String s\n        when s.equalsIgnoreCase(\"YES\") -&gt; {\n            System.out.println(\"You said yes\");\n        }\n        case String s -&gt; {\n            System.out.println(\"You said no\");\n        }\n    }\n\n\n\n\n‚ûï Sequenced Collections\n\n\n\n\nlist.addLast(...);\nmap.putFirst(...);\nset.reversed();\n// etc.\n\n\n\n\n‚ûï Virtual Threads (formerly Fibers)\n\nImproving scalability of IO-bound operations with virtual threads that you can create 10.000 of without penalty.\n\n‚ö† Deprecate the Windows 32-bit x86 Port\n‚ö† Warning if Agents are dynamically loaded\n‚ûï Key Encapsulation Mechanism API\n\nIntroduces an API for key encapsulation mechanisms (KEMs), an encryption technique for securing symmetric keys using public key cryptography.\n\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\nreleased\nMarch 2023\n\n\nStable JEPs\n0\n\n\nTotal JEPs\n7\n\n\n\n\n\nINFO\n\nAnother huge release feature-wise but all features are either in preview or incubating.\n\n\n\n\n\n\n19\n\n\n\n\n\n\n\n\nreleased\nSeptember 2022\n\n\nStable JEPs\n1\n\n\nTotal JEPs\n7\n\n\n\n\n\nINFO\n\nAnother huge release feature-wise but all features are either in preview or incubating.\n\n\n\n\n\n\n18\n\n\n\n\n\n\n\n\nreleased\nMarch 2022\n\n\nStable JEPs\n6\n\n\nTotal JEPs\n9\n\n\n\n\n\n‚ö† UTF-8 by Default\n\nSpecify UTF-8 as the default charset of the standard Java APIs\n\n‚ûï Simple Web Server\n\nCommand-line tool to start a minimal web server that serves static files only.\n\n‚ûï Reimplement Core Reflection with Method Handles\n\nReimplements java.lang.reflect.Method, Constructor, and Field on top of java.lang.invoke method handles. Before up to three different internal mechanisms for reflective operations were used.\n\n\n\n\n\n\n\n17 LTS\n\n\n\n\n\n\n\n\nLTS until\nSep 2026 (Oracle)\nOct 2027 (Temurin)\nOct 2029 (Corretto)\n\n\nreleased\nSep 2021\n\n\nStable JEPs\n11\n\n\nTotal JEPs\n14\n\n\n\n\n\n‚ûï New macOS Rendering Pipeline\n\nCreate a new Swing Renderer based on Metal Api before Apple removes OpenGL Api.\n\n‚ûï macOS/AArch64 Port\n\nPort for Apple Silicon\n\n‚ùå Strongly Encapsulate JDK Internals by Default\n\nJDK internals can no longer be opened via command-line option (except sun.misc.Unsafe for which this is still possible).\n\n‚ùå Remove RMI Activation\n\nOnly RMI Activation is removed after deprecation in JDK 15.\n\n‚ûï Sealed Classes and interfaces\n\nEnums on steroids. Create a class or interface for which you know all allowed subtypes. Combines great with instanceof (JDK 17 or switch JDK 21 pattern matching.\n\n\n\n\n\nabstract sealed class Shape permits Circle, Rectangle /*... */ {\n}\n\n\n\n\n\n16\n\n\n\n\n\n\n\n\nreleased\nMarch 2021\n\n\nStable JEPs\n13\n\n\nTotal JEPs\n17\n\n\n\n\n\n‚ûï Pattern Matching for instanceof\n\n\n\n\n// the old way\nif (obj instanceof String) {\n    String s = (String) obj;    // grr...\n}\n// the new pattern-matching way\nif (obj instanceof String s) {\n    // Let pattern matching do the work!\n}\n\n\n\n‚ûï Records\nRecords are immutable carriers of data. Automatically implements data-driven methods such as equals and accessors.\n\n\n\nrecord Point(int x, int y) { }\n\n\n\n\n‚ûï Stream toList Shortcut\n\n\n\n\nstream.toList();\n// careful, the returned List is unmodifiable\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\nreleased\nSeptember 2020\n\n\nStable JEPs\n10\n\n\nTotal JEPs\n14\n\n\n\n\n\n‚ùå Remove Nashorn JavaScript Engine\n\nDeprecated since JDK 11.\n\n‚ûï Text Blocks\n\n(multi-line string literals)\n\n\n\n\n\nString html = \"\"\"\n              &lt;html&gt;\n                  &lt;body&gt;\n                      &lt;p&gt;Hello, world&lt;/p&gt;\n                  &lt;/body&gt;\n              &lt;/html&gt;\n              \"\"\";\n\n\n\n\n‚ûï ZGC: A Scalable Low-Latency Garbage Collector\n\nCost of near-pauseless operation is a ~2% throughput reduction, and it uses more memory. G1 remains default garbage collector though.\n\n\n\n\n\n\n14\n\n\n\n\n\n\n\n\nreleased\nMarch 2020\n\n\nStable JEPs\n11\n\n\nTotal JEPs\n16\n\n\n\n\n\n‚ûï JFR Event Streaming\n\nExpose JDK Flight Recorder data for continuous monitoring.\n\n‚ûï Helpful Nullpointer exceptions\n\nThrown exceptions now pinpoint what caused the nullpointer, not just filename and line number.\n\n‚ûï Switch Expressions\n\n\n\n\nreturn switch (day) {\n    case MONDAY, FRIDAY, SUNDAY -&gt; System.out.println(6);\n    case TUESDAY                -&gt; System.out.println(7);\n    case THURSDAY, SATURDAY     -&gt; System.out.println(8);\n    case WEDNESDAY              -&gt; System.out.println(9);\n}\n\n\n\n\n\n13\n\n\n\n\n\n\n\n\nreleased\nSeptember 2019\n\n\nStable JEPs\n3\n\n\nTotal JEPs\n5\n\n\n\n\n\nINFO\n\nSmaller Release\n\n\n\n\n\n\n12\n\n\n\n\n\n\n\n\nreleased\nMarch 2019\n\n\nStable JEPs\n6\n\n\nTotal JEPs\n8\n\n\n\n\n\nINFO\n\nSmaller Release\n\n\n\n\n\n\n\n11 LTS\n\n\n\n\n\n\n\n\nLTS until\nSep 2023 (Oracle)\nOct 2027 (Temurin)\nJan 2032 (Corretto)\n\n\nreleased\nSep 2018\n\n\nStable JEPs\n16\n\n\nTotal JEPs\n17\n\n\n\n\n\n‚ûï Http Client\n‚ûï Launch Single-File Source-Code Programs\n\nEnhance the java launcher to run a program supplied as a single file of Java source code, including usage from within a script by means of \"shebang\" files and related techniques.\n\n‚ùå JavaFx\n\nJavaFx was never part of Java SE but Oracle bundled it with their JDKs since 8. Now they&#8217;ve unbundled it and passed the torch to the OpenJFX project\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\nreleased\nMarch 2018\n\n\nStable JEPs\n12\n\n\nTotal JEPs\n12\n\n\n\n\n\n‚ûï Local-Variable Type Inference\n\n\n\n\n// now possible\nvar num = 42;\nvar user = new User(\"John\");\n\n\n\n\n‚ûï Recognizes constraints set by container control groups (cgroup)\n\nBefore Java didn‚Äôt recognize that it was running in a container and used the maximum available resources, not the one for the cgroup. Was also backported to JDK 8.\n\n‚ûï Optional API Additions\n\n\n\n\noptional.orElseThrow(); // clearer version of `optional.get()`\n// Also allows us to specify the exception being thrown.\n\n\n\n\n\n9\n\n\n\n\n\n\n\n\nreleased\nSeptember 2017\n\n\n\n\n\n‚ûï Modularized JDK\n\nProject Jigsaw\n\n‚ûï Module System\n\nCreate a module (a jar that only exposes a defined set of types, not all of them) by adding module-info.java at the root:\n\n\n\n\n\nmodule my.module { // name the module\n    requires transitive other.module.name; // what modules it requires\n\n    exports my.module.myapi; // what api to expose\n}\n\n\n\n\n‚ûï JShell\n\nRead-Eval-Print Loop\n\n‚ûï G1 is the Default Garbage Collector\n\nThe premise is that limiting GC pause times is, in general, more important than maximizing throughput. The previous GC, Parallel GC, was throughput-oriented.\n\n‚ûï Encapsulate Most Internal APIs\n\nThings such as sun.misc.Unsafe are not encapsulated for now.\n\n‚ûï Interfaces supporting Reactive Streams\n\nFor interoperability across a number of async systems running on JVMs.\n\n‚ûï Private Methods in Interfaces\n\nCan be called from default methods.\n\n‚ûï Convenience Factory Methods for Collections\n\n\n\n\nSet.of(a, b, c);\nList.of(a, b, c)\nMap.ofEntries(entry(k1, v1), entry(k2, v2));\n\n\n\n\n‚ûï Optional API Additions\n\n\n\n\noptional.or(() -&gt; Optional.of(\"default\"));\noptional.ifPresentOrElse(it -&gt; doSth(it), ::otherwise);\noptional.stream();\n\n\n\n\n\n\n8 LTS\n\n\n\n\n\n\n\n\nLTS until\nMar 2022\nNov 2026 (Temurin)\nDec 2030 (Corretto)\n\n\nreleased\nMar 2014\n\n\n\n\n\n‚ûï Lambda-Expressions\n\nProject Lambda\n\n‚ûï Default Methods for Interfaces\n‚ûï Nashorn JavaScript Engine\n\nSupersedes Rhino JavaScript Engine\n\n‚ûï Launch JavaFX Applications\n\nOnly added to Oracle JDK.\n\n‚ûï Date &amp; Time API\n\nNew java.time, inspired by Joda-Time. Supersedes java.util.Date and java.util.Calendar.\n\n‚ûï Bulk Data Operations for Collections\n\nAdds streams to java:\n\n\n\n\n\nlist.stream()\n    .filter(it -&gt; it &gt; 0)\n    .map(it -&gt; \"it\")\n    .collect(Collectors.toList());\n\n\n\n\n‚ûï Optional&lt;T&gt;\n\n\n\n\nOptional.of(name);\nOptional.ofNullable(name);\n\nopt.orElse(\"john\").ifPresent(name -&gt; println(name));\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\nreleased\nJuly 2011\n\n\n\n\n\n‚ûï Strings in switch statements\n‚ûï try-with-resources statements\n‚ûï Improved type inference for generic instance creation (\"diamond\")\n‚ûï Improved exception handling (multi-catch)\n\n\n\n\n\n6\n\n\n\n\n\n\n\n\nreleased\n2006\n\n\n\n\n\n‚ûï Rhino JavaScript Engine\n‚ûï Dramatic performance improvements\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\nreleased\n2004\n\n\n\n\n\n‚ûï Generics\n‚ûï Autoboxing\n‚ûï Enumerations\n‚ûï Varargs\n‚ûï for each\n‚ûï java.util.concurrent\n\nConcurrentHasMap etc.\n\n\n\n\n\n\n1.4\n\n\n\n\n\n\n\n\nreleased\n2002\n\n\n\n\n\n‚ûï assert Keyword\n‚ûï java.util.regex\n‚ûï java.nio\n\nNon-Blocking I/O\n\n\n\n\n\n\n1.3\n\n\n\n\n\n\n\n\nreleased\n2000\n\n\n\n\n\n‚ûï HotSpot JVM\n‚ûï Last Release for Microsoft Windows 95 :) \n\n\n\n\n\n1.2\n\n\n\n\n\n\n\n\nreleased\n1998\n\n\n\n\n\n‚ûï Swing\n‚ûï JIT-Compiler\n‚ûï Collections-Framework\n‚ûï Modify Objects via Reflection\n\n\n\n\n\n1.1\n\n\n\n\n\n\n\n\nreleased\n1997\n\n\n\n\n\n‚ûï +inner classes\n‚ûï RMI\n‚ûï Serialization\n‚ûï Reflection\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\nreleased\n1996\n\n\n\n\n\nINFO\n\nInitial release"

    },
  
    {

      "title"    : "Structure-cementing tests and how to avoid them 2/3",
      "url"      : "/posts/Structure-Cementing-Tests-2",
      "content"  : "Part 2 - Concepts of the TestDsl\n\n\nTests should be sensitive to behavioural changes but be insensitive to structural changes.\nTests that do not fulfil the second condition are called structure-cementing.\nIn part 1, we built a TestDsl with which we can completely avoid cementing structure through the test setup.\nIn this part, we will go into more detail about the concepts of the DSL (Domain-Specific Language [1]) and show why you can use it to write tests that become unit tests after changing just one line of integration.\n\n\nThe test setup is a series of steps we need to take before we can test our testee.\nWe need this because certain preconditions are required before we can test the actual behavior.\nThe TestDsl is an abstraction layer between test and test setup that makes the test setup very comfortable and avoid structural cementation.\n\n\nLet us assume that we want to test a method rentBook(bookId, userId) in a RentingService.\nIt is very common that this method has the precondition that the book and user must be stored in a Repository before we call rentBook.\nAdditionally the renting user must exist, have a role and a permission called CAN_RENT_BOOK .\n\n\nIf you were to create all the preconditions in each test by hand, you would not only have created a lot of redundancy, but (assuming enough tests) you would also have cemented the structure of all the preconditions. Implementation details, such as what a Role looks like, how it gets into its Repository, how the RentingService gets to that Repository, are cemented with every redundant test setup. This cementation happens because an engineer simply does not want to change a high number of files in order to implement an actually sensible structural change. The engineer feels that the structure is anything but soft and more like cement.\n\n\nIf the entire test setup is done  via the TestDsl, only the Dsl is affected by structure changes and the test is decoupled from the structure. We can make structural changes in the production code without any problems because we only have to make changes in one place, in the Dsl.\n\n\n\n\n\nFigure 1. The TestDsl inserts itself between tests and the structure of the production code\n\n\nThe TestDsl consists of the following parts:\n\n\n\n\nTestState\n\n\nFloor\n\n\nEntity (Combo) Builder\n\n\nTest Doubles (instead of structure-cementing mocks)\n\n\nService Configurator (optional)\n\n\nJUnit extension (optional)\n\n\n\n\nA noticeable amount of code, but not much logic. The code is always about delegating or setting values. This is good. The Dsl should think as little as possible so that we don&#8217;t create a maintenance problem.\n\n\nClearly, we need to invest code. However, this pays dividends quickly and allows us to write very concise tests (the final test from part 1):\n\n\nComplete test with TestDsl Extension\n\n@Integration @Test\nvoid should_be_able_to_rent_book(TestState a, Floor floor){\n    // given\n    var book = a.book();\n    var userCombo = a.userCombo(it -&gt; it.hasPermission(\"CAN_RENT_BOOK\"));\n    a.saveTo(floor);\n\n    var testee = new RentingService(floor);\n    // WHEN\n    var result = testee.rentBook(book, userCombo.user());\n    // THEN\n    assertThat(result.isRented()).isTrue();\n}\n\n\n\nWe can now also turn this test into a quick @Unit test, just by replacing the @Integration annotation. Legacy code in particular benefits from this feature of the TestDsl, because we often still have a lot of logic in the database and have to test at integration level before remediation. Over time, this logic ends up in the domain and we can turn existing tests into significantly faster unit tests with a one-liner. Without a TestDsl, you would have to completely rewrite them at unit level, which is why many teams do not do this, remain stuck with slow integration tests and cannot iterate faster despite tests.\n\n\nIn the following chapters, we will see why this is possible and which concepts are behind the Dsl. In Part 3, we will look at the second and final type of structure-cementing tests: Tests that test unstable elements and not modules.\n\n\n\n\nUnit and integration tests\n\n\nUnit and integration tests are very vague terms across the industry ([2], [3]). Even in small teams there is no clear definition, everyone has their own understanding. So we should pause for a moment and define what we mean when we say @Unit @Test.\n\n\nThe test written in part 1 are sociable unit tests [4] and follow the unit test definition by Michael Feathers [5]:\n\n\n\n\nA test is not a unit test if:\n\n\n\n\nIt talks to the database\n\n\nIt communicates across the network\n\n\nIt touches the file system\n\n\nIt can&#8217;t run at the same time as any of your other unit tests\n\n\nYou have to do special things to your environment (such as editing config files) to run it.\n\n\n\n\nTests that do these things aren&#8217;t bad. Often they are worth writing, and they can be written in a unit test harness. However, it is important to be able to separate them from true unit tests so that we can keep a set of tests that we can run fast whenever we make our changes.\n\n\n\n&#8212; Michael Feathers [5]\n\n\n\nAround 2010, Google did not know this definition or their teams could not agree on it.\nHowever, they knew that it is hugely beneficial for internal communication if everyone uses the same names for the same things. They couldn&#8217;t agree on the same definitions so they introduced new 'data-driven naming conventions' for tests.\nTheir definition of a small test is pretty close to Feathers' definition (Google Test Sizes) and the medium test provides a pretty good definition of an integration test.\n\n\nTable 1. Google Test Sizes [3]\n\n\n\n\n\n\n\n\nFeature\nSmall (Unit)\nMedium (Integration)\nLarge (Acceptance)\n\n\n\n\nDatabase\nNo\nYes\nYes\n\n\nNetwork access\nNo\nlocalhost only\nYes\n\n\nFile system access\nNo\nYes\nYes\n\n\nUse external systems\nNo\nDiscouraged\nYes\n\n\nMultiple threads\nNo\nYes\nYes\n\n\nSleep statements\nNo\nYes\nYes\n\n\nSystem properties\nNo\nYes\nYes\n\n\n\n\nTime limit (seconds)\n60\n300\n900+\n\n\n\n\nThe table also shows why unit tests are so fast: there is no out-of-process with which our tested code has to interact.\nEverything runs in-process and in-memory and without network.\nThe perfect basis for the majority of our tests, because the next level of integration or medium can already be significantly slower.\nDepending on the test runner and infrastructure, unit tests in customer projects are between 4 and 10 times faster than integration tests.\nWe were only able to achieve a factor of 4 with our integration tests by parallelising them with a little trick.\n\n\n\n\n\n\n\n\nIf each test is given its own namespace in the database (in MongoDb this would be a schema), then each integration test can only see its own data and can only modify its own data. Test isolation is thus restored.\n\n\n\n\n\n\n\nFrom integration to unit test\n\n\nWe can convert our test from @Integration to @Unit with a one-liner. The JUnit extension switches all repositories in the background. The production repository JpaBooks becomes an InMemoryBooksDouble. The api of the TestDsl remains the same, which is why we no longer need to make any changes to the test. We don&#8217;t have to change anything in the tested code either, because it only contains the interface Books { add(Book book); /* &#8230;&#8203; */ } and not which implementation is behind it.\n\n\nFor this change to work so smoothly, however, the InMemory and Jpa repositories must also behave in the same way. In the following chapter, we will see how we can continuously ensure this with the so-called port contract tests.\n\n\nHowever, it does not always make sense to implement all methods of Books in InMemoryBooksDouble and to keep them synchronised with port contract tests. Sometimes we need the powerful query functionalities of databases not for business logic, but for search functions in the UI. On the one hand, it would be a huge overhead to rebuild these in-memory for a few @Unit tests. On the other hand, these tests would then really only test our InMemory repository implementation. In such cases, we prefer to throw a NotImplementedException in the InMemory double and stick with @Integration tests (for now). We can always change our mind if business logic actually requires the query method.\n\n\n\n\nKeeping doubles synchronised to production code with port contract tests\n\n\nSo far we have assumed that a Jpa- can always be replaced by an InMemory repository. This is possible because we combine the Ports &amp; Adapters Architecture [6] with so-called port contract tests [23].\n\n\nJpaBooks implements the interface Books. The interface is a so-called port. All classes that implement the interface are adapters of it. However, the domain logic only knows the ports and not which implementation is behind them. This means that we have decoupled the domain logic from what the code that communicates with the outside world actually looks like. Theoretically, an implementation of the port does not even have to exist when writing the domain logic.\n\n\nThe Ports &amp; Adapters Architecture [6] helps us design better. We can model the domain logic first before we have to turn to implementation details. The architecture also offers us the option of replacing real adapters with test doubles [8] for tests. In our unit tests, we therefore use an InMemoryBooksDouble instead of a slower and more expensive JpaBooks repository.\n\n\nInMemoryBooksDouble is a specific type of double, a so-called fake [9]. In contrast to the other double types (dummies, stubs, and mocks [10]), fakes are working implementations of ports that take shortcuts that the production code cannot take, in this case the InMemory solution.\n\n\nIn contrast to other doubles, however, the fake must fulfil the expectations that the domain code has of the port. With repositories, for example, the domain code expects that an entity that was added with add() can then also be found again with a find(). The expectations that the domain has of the port are called contract and we can check them with a  port contract test.\n\n\nPort Contract Test of our Port\n\npublic abstract class BooksContract { \n    abstract Books testee(); \n\n    @Test\n    void should_remember_book(TestState a){ \n        // given\n        var book = a.book();\n        var testee = testee();\n        // when\n        testee.add(book);\n        // then\n        assertThat(testee.findById(book.id())).isEqualTo(book);\n    }\n}\n\n\n\n\n\n\nThe contract is abstract. It only becomes an executable test when it is implemented.\n\n\n\nWe only know the port in the test, not the implementation.\n\n\n\nEach test describes behaviour that we expect from the port.\n\n\n\n\nThe implementation test is very short for both the fake and the production adapter.\n\n\nTest of the Port Adapter\n\n@Unit\npublic class InMemoryBooksTest extends BooksContract {\n\n    @Override\n    Books testee() { \n        return new InMemoryBooks();\n    }\n}\n\n\n\n\n\n\nAdapter tests usually only implement the method that creates the testee.\n\n\n\n\nAnd the fake is also very easy to write thanks to a reusable base.\n\n\nAn InMemory fake is quick to write thanks to the base class\n\npublic class InMemoryBooksDouble\n            extends BaseInMemoryDouble&lt;BookId, Book&gt;\n            implements Books {   \n}\n\n\n\n\n\n\nIn most repositories, we do not need to implement any special methods here and only use what the base also has.\n\n\n\nSpecial methods are usually only created by queries. We can solve simple queries with the filter(predicate) method from the base class. For more complex filter methods, however, we can always say that we do not implement them and prefer to use a slower Integration Test.\n\n\n\n\nThe base class has little logic and always delegates to the JDK map\n\npublic abstract class BaseInMemoryDouble&lt;TId, TEntity extends Entity&lt;TId&gt;&gt; {\n    private Map&lt;TId, TEntity&gt; entities = new HashMap&lt;&gt;(); \n\n    public List&lt;TEntity&gt; filter(Predicate&lt;TEntity&gt; predicate){\n        return this.entities.values().stream()\n                    .filter(predicate)\n                    .toList(); \n    }\n\n    \n}\n\n\n\n\n\n\nFor tests, we only need one HashMap here. However, if we also intend to test parallel code, we should use a ConcurrentHashMap straight away.\n\n\n\nSimple queries can be solved using predicate. For our unit tests, we don&#8217;t need anything complicated with indices because our HashMap only contains a few entities.\n\n\n\nOther methods such as findById(), add(), remove(), removeIf() and count() only pass through to the (concurrent) HashMap. We do not implement anything special here, but use what the JDK gives us.\n\n\n\n\nWith these tests, we can now guarantee that all adapters of the port behave in the same way. They will always be synchronised with what we define as an expectation (aka contract) in the tests.\n\n\nContract tests are an idea from J. B. Rainsberger [11]. We only call them port contract tests here to make it more explicit which contract you want to test. This also distinguishes them from the integration contract tests [12] and the consumer-driven contracts [13] approach. An alternative name for the port contract tests is role tests [14].\n\n\n\n\nStructure-cementing mocks and flexible doubles\n\n\nIn our test, we have so far only used one form of Test Doubles [8], the InMemory Fakes [9]. In addition to the fakes, there are also stubs, spies and mocks. They are defined as follows:\n\n\n\nFakes [9]\n\nare working implementations that can take shortcuts that the production code cannot take. We keep them synchronised with port contract tests. Fakes can be recognised by the fact that their implementation does roughly the same as the production implementation.\n\nStubs [15]\n\nallow us to put indirect inputs into our test. Indirectly, because these inputs are not passed as parameters to the testee, but the testee pulls the inputs itself. Stubs can be recognised by the fact that we pass them test data, which they return as bluntly as possible when requested by the testee. There is no great logic here.\n\nMocks [16]\n\nallow us to check indirect outputs from our testee. Indirectly, because you don&#8217;t get these outputs as a return value from the testee, but have to retrieve and verify them via detours. This is also known as behaviour verification. Mocks can be recognised by the fact that you ask the mock directly to verify whether it has been called (with certain parameters). The test calls a framework method (verify(mock).didSth(withParam)) or a self-written method (mock.verifyAddWasCalled()).\n\n\n\n\nAll three Test Doubles can be implemented with a mocking framework, but they can also be implemented without one. Fakes and stubs benefit from implementing them by hand. It&#8217;s not much code, you have a single implementation for multiple tests and the code is easier to read because it is just code and no framework syntax.\n\n\nA mocking framework really only makes sense for mocks because it allows you to specify the expected behavior in the same location as the test. But since you only need mocks very rarely, you only need mocking frameworks very rarely. This is good because the excessive use of the framework also leads to structure cementation.\n\n\n\n\n\nFigure 2. Reimplementation of the same method in n tests leads to structure cementation\n\n\nIf we reimplement the same methods again and again in n tests, then:\n\n\n\n\nwe cement the design at the type level.\n\n\nour reimplementation may deviate from the real code. The deviation can even be so strong that we break the encapsulation of the port [17].\n\n\n\n\nThe former deprives us of the possibility to change our structure. But the latter is perhaps even worse, because our test can be green with the mock, while they would be red with the actual production code. As a result, we no longer trust our tests.\n\n\nIn ‚ÄòThe Art of Unit Testing‚Äô [18], the recommendation is to only use mocks if we want to test the interaction with an external service. Then you only need mocks in 2% to 5% of unit tests.\n\n\nFor the vast majority of tests, we therefore use either no double at all (method that only calculates and we can assert on the return value), an (in-memory) fake or a stub and we then write these quickly by hand: fake or stub.\n\n\nA simple stub\n\npublic class IsbnApiEchoDouble { \n\n    private final String bookTitleEcho;\n\n    public SomeRemoteApiEchoDouble(String bookTitleEcho){\n\t    this.bookTitleEcho = bookTitleEcho != null\n                                            ? bookTitleEcho\n                                            : \"Refactoring\";\n    }\n\n    public String findTitle(Isbn isbn) {\n        return this.bookTitleEcho; \n    }\n}\n\n\n\n\n\n\nThere are different types of stubs. This one always returns an echo of the values it received in the constructor.\n\n\n\nNo special logic here. Just return what you got in the constructor.\n\n\n\n\nWriting it yourself also gives us a single place where we can maintain structural changes to the real port without affecting the test.\n\n\n\n\nBuilder Design\n\n\nThe generic with() method accelerates the writing of the initial builder but requires public fields.\n\n\nEntity-TestBuilder\n\npublic class BookBuilder extends TestBuilder&lt;Book&gt; {\n\n    public BookId id = ids.next(BookId.class);\n    public String title = \"Refactoring\";\n    public String author = \"Martin Fowler\";\n    public Instant createdOn = clock.now();\n\n    public BookBuilder(Clock clock, Ids ids){\n        super(clock, ids);\n    }\n\n    public Book build(){\n        return new Book(id, title);\n    }\n\n    public BookBuilder with(Consumer&lt;? super BookBuilder&gt; action) {\n        action.accept(this);\n        return this;\n    }\n\n}\n\n\n\nPublic fields are a trade-off we can take, at least initially.\nRealistically we are going to want to switch to more specific withX() or isX() methods sooner rather than later for one of two reasons:\n\n\n\n\nthe new methods make testing more convenient.\n\n\nthe new methods don&#8217;t allow error conditions.\n\n\n\n\nSuppose for example we make the author name no longer stringly but strongly typed [19] as AuthorName (provides more compile-time safety similar to the Ids). Then the generic with() method is no longer as convenient to use, because we always have to write:\n\n\nwith(it &#8594; { author = new AuthorName(‚ÄòAlistair‚Äô); })\n\n\nTo combat this we can introduce a withAuthor(String name) and a withAuthor(AuthorName name) overload to make our builder more convenient to use and keep our tests readable.\n\n\nThe second reason happens when two or more fields depend on each other. For example, when a Book gets a field rentedOn. rentedOn must always be after createdOn. With our generic with(), however, we can create an object that is invalid because we have only set rentedOn. This is not a big problem if we always validate in the constructor of a class or record whether the fields (aka the state) are correct. However, BookBuilder would then allow something, which Book then acknowledges in runtime with an IllegalArgumentException.\n\n\nIn order to have more compile-time safety again, we can make the field rentedOn private again in the builder and introduce isRentedOn(Duration rentedAfterCreate) together with the overload isRentedOn(Instant createdOn, Duration rentedAfterCreate). The new prefix, is, shows us that the method conceptually does something different than a with. is declares that the method sets several interdependent values. The overload shows us which value the parameter rentedAfterCreate is dependent on.\n\n\nThe new prefix is also there so that we can recognise whether our builder is starting to become too complex. If the number of is methods exceeds the with, then our builder is in dangerous waters.\n\n\n\n\nTestDsl in combination with Spring\n\n\nThe JUnit extension written in part 1 can also be made compatible with @SpringBootTest. The extension only has to check whether an ApplicationContext exists. If so, it pulls the floor from the Spring DI-Container instead of from the JUnit Store.\n\n\nTestDsl with Floor supplied by Spring\n\n@Override\npublic Object resolveParameter(\n        ParameterContext parameterContext,\n        ExtensionContext extensionContext\n    ) throws ParameterResolutionException {\n        // ...\n        var springFloor = SpringExtension\n            .getApplicationContext(extensionContext)\n            .getBeanProvider(Floor.class)\n            .ifAvailable;\n        // ...\n}\n\n\n\nUsing the annotation, we can now write the test for a controller.\n\n\nSpringBoot Controller Test with TestDsl\n\n@Integration @SpringBootTest @Test \nvoid should_be_able_to_rent_book_via_api(\n        TestState a,\n        Floor floor,\n        @Autowired BookController testee){ \n    // rest of test\n    \n}\n\n\n\n\n\n\nWe combine the SpringBootTest annotation with the TestDsl annotation.\n\n\n\nWe ask Spring to inject the testee.\n\n\n\nWe can use the TestDsl here as in any other test. The repositories that Spring recognises and those of the TestDsl are the same.\n\n\n\n\nIf you use @SpringBootTest you have to be careful how you write your tests and how extensive they are. The Spring Application Context is cached for tests which overrides the test isolation. Modifications that a test makes can cause a test that runs later to fail. Our tests become brittle.\n\n\nUnit tests should therefore test (functional domains) logic without Spring. This also corresponds to the recommendation that the Spring Framework has made since version 2 [20] and has maintained up to the current version 6 [21]. An @Integration @SpringBootTest can be added sporadically for important test paths through the application.\n\n\n\n\nLow and High Level Test DSLs\n\n\nThe TestDsl for @Unit and @Integration shown so far is a Low-Level TestDsl. It counteracts structure cementation and makes tests 'under the hood' easier to write. Thanks to direct access to domain objects, we are very flexible as to which test states we can create. We can use it to check the happy path, the sad paths and also many strange paths, i.e. paths that should never actually occur.\n\n\nHowever, it is not written from the user&#8217;s perspective and cannot be used to verify that the system is behaving correctly from the user&#8217;s perspective. For such tests, we need a running system that we can access from outside via a browser, HttpApi or similar. Google would call these tests ‚ÄòLarge‚Äô [3] (Google Test Sizes). Other common names are system tests or user acceptance tests.\n\n\nFor these tests, we need a new Dsl with a different structure but a very similar concept behind it. However, this high-level @Acceptance Dsl no longer has anything to do with structure cementation, but with Ui or Api cementation. The more tests we have that require a certain button or a certain widget, the more this UI component is cemented. In the case of a public api, this cementing is perhaps intentional, as you want to offer others a stable api. But even then, a Dsl is recommended because it makes the tests much more readable and maintainable.\n\n\nThe High-Level TestDsl briefly outlined below is the implementation of the 4 Layer Acceptance Test Structure by Dave Farley [22]. The 4 layers are:\n\n\n\n\ntop: our test\n\n\nDSL per domain: renting, buying, etc.\n\n\nprotocol drivers: UI, API, external system stub\n\n\nthe system under test\n\n\n\n\nWhen we follow this structure our tests no longer accesses the api of our system directly. There is no http.get(‚Äò/api/users‚Äô). The test also does not click directly in the browser. There is no page.navigate() or page.click(). The test only recognises the next layer, the Dsl.\n\n\nThe Dsl only offers domain-specific user targets, not how the targets are technically implemented (with the renting-Dsl we could implement .findBook(‚ÄòRefactoring‚Äô).rent(), for example). It only recognises the protocol drivers and delegates the implementation to the protocol drivers.\n\n\nOnly the drivers know the system to be tested. The UI driver knows how to implement the targets with Playwright, for example, while the Api Protocol Driver can implement the targets using RestAssured, for example. Which driver is used is controlled by annotation.\n\n\nHigh-Level TestDsl\n\n@Acceptance @UiProtocol @ApiProtocol @Test \nvoid should_be_able_to_rent_book(InventoryDsl inventory, RentingDsl renting){\n    // given\n    inventory.addBook(\"Refactoring\");   \n    var book = renting.findBook(\"Refactoring\");\n    // when\n    book.rent();\n    // then\n    assertThat(book.isRented()).isTrue();\n}\n\n\n\n\n\n\nWe carry out this test via the browser but also via the HttpApi.\n\n\n\nAs with the low-level Dsl, each test must create its complete state.\n\n\n\nUnlike the low-level Dsl, however, this Dsl takes significantly larger steps. Creating a book can consist of many browser actions or api calls. If one of the intermediate steps fails, the Dsl aborts immediately and provides specific feedback as to which of the intermediate steps did not work.\n\n\n\n\nYou can also parallelise these tests in a similar way as we have done with integration tests: we can either provide a namespace per test directly in our system under test or solve this via our Dsl.\n\n\nThe former is possible if you build multi-tenant capability into your system right from the start. Each entity then needs an additional TenantId and you have to ensure that everyone can only see the data of their own tenant. If you now create a new tenant for each test and the test also creates all preconditions in the form of entities, then the tests are isolated from each other via the TenantId and can therefore be parallelized.\n\n\nIf the TenantId cannot be built directly into the system, the test data aliasing [22] mentioned by Dave Farley is used. With this pattern, the TestDsl itself ensures that the test data is unique. It then adds a test-unique key to fields. addBook(‚ÄúRefactoring‚Äù) does not create the book ‚ÄúRefactoring‚Äù, but the book ‚ÄúRefactoring dbac1q23‚Äù. findBook(‚ÄúRefactoring‚Äù) does not search for ‚ÄúRefactoring‚Äù, but for ‚ÄúRefactoring dbac1q23‚Äù. When writing the test, however, you must be careful not to assert the number of books or similar, as this could change continuously due to tests running in parallel.\n\n\nOverall, the high-level Dsl described here complements the low-level Dsl with the user view. We write the majority of the tests with the low-level Dsl; we test critical application areas in particular with the high-level Dsl from the user&#8217;s perspective.\n\n\n\n\nOutlook\n\n\nThe TestDsl combines existing concepts such as builders, ports [6], port contract tests [7], stubs [10] and fakes [9] and provides a standardized api for all our unit and integration tests. With the TestDsl, we were able to solve structure cementation through redundant test setup. We will show how we use the TestDsl to prevent structure cementing through tests at the wrong level in Part 3.\n\n\nIf you are interested in more content about the topic, you can view TestDsl sample code online [24] or watch the presentation on ‚ÄúBeehive Architecture‚Äù [25], which also revolves around the TestDsl.\n\n\n\n\n\n\n\n\nThis article was originally published in Java Aktuell 5/24 in üá©üá™. It is translated and republished here with the magazine&#8217;s permission.\n\n\n\n\n\n\n\nReferences\n\n\n\n\n[1] M. Fowler, ‚ÄûDomain Specific Language‚Äú. 2008. Available here: https://martinfowler.com/bliki/DomainSpecificLanguage.html\n\n\n[2] M. Fowler, ‚ÄûOn the Diverse And Fantastical Shapes of Testing‚Äú. 2021. Available here: https://martinfowler.com/articles/2021-test-shapes.html\n\n\n[3] S. Stewart, ‚ÄûTest Sizes‚Äú. 2010. Available here: https://testing.googleblog.com/2010/12/test-sizes.html\n\n\n[4] M. Fowler, ‚ÄûUnit Test‚Äú. 2014. Available here: https://martinfowler.com/bliki/UnitTest.html#SolitaryOrSociable\n\n\n[5] M. Feathers, ‚ÄûA Set of Unit Testing Rules‚Äú. 2005. Available here: https://www.artima.com/weblogs/viewpost.jsp?thread=126923\n\n\n[6] A. Cockburn, ‚ÄûHexagonal architecture‚Äú. 2005. Available here: https://alistair.cockburn.us/hexagonal-architecture/\n\n\n[7] R. Gross, ‚ÄûContract Tests in Kotlin‚Äú. 2020. Available here: http://richargh.de/posts/Contract-Tests-in-Kotlin\n\n\n[8] G. Meszaros, ‚ÄûTest Double‚Äú. 2011. Available here: http://xunitpatterns.com/Test%20Double.html\n\n\n[9] G. Meszaros, ‚ÄûFake Object‚Äú. 2011. Available here: http://xunitpatterns.com/Fake%20Object.html\n\n\n[10] M. Fowler, ‚ÄûMocks Aren‚Äôt Stubs‚Äú. 2007. Available here: https://martinfowler.com/articles/mocksArentStubs.html\n\n\n[11] J. B. Rainsberger, ‚ÄûGetting Started with Contract Tests‚Äú. 2017. Available here: https://blog.thecodewhisperer.com/permalink/getting-started-with-contract-tests\n\n\n[12] M. Fowler, ‚ÄûIntegration Contract Test‚Äú. 2011. Available here: https://martinfowler.com/bliki/ContractTest.html\n\n\n[13] I. Robinson, ‚ÄûConsumer-Driven Contracts: A Service Evolution Pattern‚Äú. 2006. Available here: https://martinfowler.com/articles/consumerDrivenContracts.html\n\n\n[14] M. Rivero, ‚ÄûRole tests for implementation of interfaces discovered through TDD‚Äú. 2022. Available here: https://codesai.com/posts/2022/04/role-tests\n\n\n[15] G. Meszaros, ‚ÄûTest Stub‚Äú. 2011. Available here: http://xunitpatterns.com/Test%20Stub.html\n\n\n[16] G. Meszaros, ‚ÄûMock Object‚Äú. 2011. Available here: http://xunitpatterns.com/Mock%20Object.html\n\n\n[17] M. Seemann, ‚ÄûStubs and mocks break encapsulation‚Äú. 2022. Available here: https://blog.ploeh.dk/2022/10/17/stubs-and-mocks-break-encapsulation/\n\n\n[18] R. Osherove, ‚ÄûArt of Unit Testing (3. Edition)‚Äú. 2024. Available here: https://www.artofunittesting.com/\n\n\n[19] T. Spring, ‚ÄûStringly Typed vs Strongly Typed‚Äú. 2022. Available here: https://www.hanselman.com/blog/stringly-typed-vs-strongly-typed\n\n\n[20] T. Spring, ‚ÄûUnit Testing‚Äú. 2006. Available here: https://docs.spring.io/spring-framework/docs/2.0.4/reference/testing.html#unit-testing\n\n\n[21] T. Spring, ‚ÄûUnit Testing‚Äú. 2022. Available here: https://docs.spring.io/spring-framework/docs/6.0.0/reference/html/testing.html#unit-testing\n\n\n[22] D. Farley, ‚ÄûAcceptance Testing for Continuous Delivery [#AgileIndia2019]‚Äú. 2019. Available here: https://www.youtube.com/watch?v=Rmz3xobXyV4\n\n\n[23] R. Gross, ‚ÄûContract Tests in Kotlin‚Äú. 2020. Available here: http://richargh.de/posts/Contract-Tests-in-Kotlin\n\n\n[24] R. Gross, ‚ÄûTestDsl (Avoid structure-cementing Tests)‚Äú. 2024. Available here: https://github.com/Richargh/testdsl\n\n\n[25] R. Gross, ‚ÄûBeehive Architecture‚Äú. 2023. Available here: http://richargh.de/talks/#beehive-architecture"

    },
  
    {

      "title"    : "SPACE - The Meta-Framework to Measure Developer Productivity",
      "url"      : "/posts/SPACE",
      "content"  : "Developer productivity has been studied extensively. Unfortunately, after decades of research and practical development experience, knowing how to measure productivity or even define developer productivity has remained elusive, while myths about the topic are common. Far too often teams or managers attempt to measure developer productivity with simple metrics, attempting to capture it all with \"one metric that matters.\"\n[&#8230;&#8203;]\nProductivity cannot be reduced to a single dimension (or metric!)\n\n\n\n&#8212; Nicole Forsgren et. al.\nhttps://queue.acm.org/detail.cfm?id=3454124\n\n\n\nSo title the authors of the paper The SPACE of Developer Productivity and I&#8217;m inclined to believe they are right.\nThe most known of the authors, Nicole Forsgren, did after all write the book Accelerate and create the Accelerate State of DevOps Report which gave us the DORA 4 keys, a set of metrics.\n\n\nCan we then even measure developer productivity?\nShould we?\n\n\nTo measure or not to measure\n\n\nWhether or not you want someone to measure developer productivity is beside the point because someone, somewhere is going to look at your teams velocity and decide things based on it.\nThen we have exactly the problem in the opening quote, productivity being reduced to a single number.\nThe problem with this reduction is that it obscures too much and a single metric is too easy to game.\nVelocity for example is too easy to game (inflate story points, no longer work on bugs, ignore quality), which defeats the whole point of measuring it.\n\n\n\n\nWhen a measure becomes a target, it ceases to be a good measure\n\n\n\n&#8212; Goodhart's law\nhttps://en.wikipedia.org/wiki/Goodhart%27s_law\n\n\n\nTo stop this race to the bottom I would like each team to select multiple metrics that are somehow in tension with each other, so you cannot game one without worsening another.\nBut which metrics have these properties?\n\n\n\n\nThe SPACE Dimensions\n\n\nSPACE is a meta-framework that helps us select metrics.\nAccording to the framework all productivity metrics fall into one of the following five dimensions.\n\n\nSatisfaction and well-being\n\nHow fulfilled, happy and healthy one is. Satisfaction is how fulfilled developers feel with their work, team, tools, or culture.\nWell-being is how healthy and happy they are, and how their work impacts it.\n\n\nFor example:\n\n\n\n\nEmployee satisfaction. NPS\n\n\nDeveloper efficacy. Devs have all the tools to get the work done.\n\n\nBurnout. The exhaustion.\n\n\n\n\n\nPerformance\n\nPerformance is the outcome of a system or process.\n\n\nFor example:\n\n\n\n\nQuality. Reliability, absence of bugs, ongoing service health.\n\n\nImpact. Customer satisfaction, customer adoption and retention, feature usage, cost reduction.\n\n\nDORA 4 keys: Change Fail Rate\n\n\n\n\n\nActivity\n\nActivity is a count of actions or outputs completed in the course of performing work.\n\n\nFor example:\n\n\n\n\nDesign and coding. Volume or count of design documents and specs, work items, pull requests, commits, and code reviews.\n\n\nContinuous integration and deployment. Count of build, test, deployment/release, and infrastructure utilization.\n\n\nOperational activity. Count or volume of incidents/issues and distribution based on their severities, on-call participation, and incident mitigation.\n\n\nDORA 4 keys: Deploy Frequency\n\n\nCommits\n\n\n\n\n\nCommunication and collaboration\n\nCommunication and collaboration capture how people and teams communicate and work together.\n\n\nFor example:\n\n\n\n\nDiscoverability of documentation and expertise.\n\n\nHow quickly work is integrated.\n\n\nQuality of reviews of work contributed by team members.\n\n\nNetwork metrics that show who is connected to whom and how.\n\n\nOnboarding time for and experience of new members.\n\n\n1:1s\n\n\n\n\n\nEfficiency and flow\n\nEfficiency and flow capture the ability to complete work or make progress on it with minimal interruptions or delays, whether individually or through a system.\nSome research associates productivity with the ability to get complex tasks done with minimal distractions or interruptions, aka \"getting in the flow\".\n\n\nFor example:\n\n\n\n\nHandoffs: Number of handoffs in a process; number of handoffs across different teams in a process.\n\n\nPerceived ability to stay in flow and complete work.\n\n\nInterruptions: quantity, timing, how spaced, impact on development work and flow.\n\n\nTime measures through a system: total time, value-added time, wait time.\n\n\nDORA 4 keys: Lead Time\n\n\nDORA 4 keys: MTTR\n\n\n\n\n\n\n\nWhat to do next\n\n\nWhen selecting your team metric it&#8217;s best to follow\nNicole&#8217;s suggestions:\n\n\n\n\nThere is no \"one\" metric that matters\n\n\nHave two-to-three metrics that are in tension with another. They should balance each other out.\n\n\nMake sure the metrics are along different dimensions.\n\n\n\n\nYou can measure each metric at individual (one person), team (people that work together) or system (end-to-end work through a system) level.\n\n\nSPACE gives us the dimensions we need to find our metrics."

    },
  
    {

      "title"    : "GenAI is a waste of our time",
      "url"      : "/posts/AI-Waste",
      "content"  : "Generative AI is a waste.\nIt&#8217;s a waste of our time, our CO2 and our sanity.\nTom Fishburne perfectly summarises why in his web comic:\n\n\n\n\n\n\n\nCan&#8217;t we just communicate short and to the point?\nAll the stuff in the middle is waste.\nIt was waste before GenAI, it is worse with GenAi.\n\n\nThere are good use cases for AI.\nOptimising the communication of people though, let&#8217;s do that ourselves.\nWe gain nothing but waste if we keep it as is and \"make it easier\" with AI.\n\n\n\n\n\n\n\n\nAI Written, AI Read is a comic by Tom Fishburne. It is free (and appreciated) to share them in personal blogs and social media. Please spread if you find it as inspiring as I did.\n\n\n\n\n\n\n\n\n\n\n\nTry to keep E-Mails to http://three.sentenc.es/ :)"

    },
  
    {

      "title"    : ".NET Version History (up to .NET 9)",
      "url"      : "/posts/dotnet-version-history/",
      "content"  : "The following list tracks the stable (not incubating or in preview) feature changes I deemed most noteworthy.\n\n\nThe list is ongoing and will be updated with every new .NET release.\nA + marks an added feature, a - marks a removed feature.\n\n\nTypically C# versions are only supported on the .NET Version they are introduced with or newer.\nMicrosoft has a list of what is considered C# language version default.\n\n\nThe releases that Microsoft will provide Long-Term Support (LTS) for are marked as such, based on the plan that Microsoft publishes.\nA new major release of .NET is published every year in November. Even numbered releases are LTS releases that get free support and patches for three years.\nOdd numbered releases are STS releases that get free support and patches for 18 months.\n\n\n9\n\n\n\n\n\n\n\n\nreleased\nNovember 2024\n\n\n\n\nC#13\n\n\n‚ûï params collections\n\nYou can now use params with any recognized collection type, including Span&lt;T&gt;, ReadOnlySpan&lt;T&gt;, and types that implement IEnumerable&lt;T&gt; and have an Add method.\n\n‚ûï New lock object\n\nAdd a new type for thread synchronization, the System.Threading.Lock type.\n\n‚ûï New escape sequence\n\nYou can use \\e as a character literal escape sequence for the ESCAPE character, Unicode U+001B.\n\n‚ûï Method group natural type\n‚ûï Implicit index access\n\nThe implicit \"from the end\" index operator, ^, is now allowed in an object initializer expression.\n\n‚ûï ref and unsafe in iterators and async methods\n‚ûï allows ref struct\n\n\n\n\npublic class C&lt;T&gt; where T : allows ref struct\n\n\n\n\n‚ûï ref struct interfaces\n‚ûï More partial members\n\nYou can declare partial properties and partial indexers in C# 13.\n\n\n\n\n\n\n\n\n8 LTS\n\n\n\n\n\n\n\n\nLTS until\nNovember 2026\n\n\nreleased\nNovember 2023\n\n\n\n\nC#12\n\n\n‚ûï Primary constructors\n\n\n\n\nclass BankAccount(string accountID, string owner)\n\n\n\n\n‚ûï Collection expressions\n\n\n\n\nstring[] names = [\"Julia\", \"Anna\", \"Thomas\"];\n// and\nstring[] allNames = [.. names, .. moreNames];\n\n\n\n\n‚ûï Optional parameters in lambda expressions\n\n\n\n\nvar IncrementBy = (int source, int increment = 1) =&gt; source + increment;\n\n\n\n\n‚ûï Experimental attribute\n\n\n\n\n[Experimental(\"1234\")]\n\n\n\n\n‚ûï Interceptors\n\nSubstitute a call to an interceptable method with a call to itself at compile time\n\n\n\n\n\n\n\n7\n\n\n\n\n\n\n\n\nreleased\nNovember 2022\n\n\n\n\nC#11\n\n\n‚ûï Pattern matching enhancements\n\n\n\n‚ûï List patterns\n\n\n\n\n\n\n\nsequence is [1, 2, 3]\n\n\n\n\n‚ûï Required members\n\nMust be initialized by an object initializer. Really important because now you can trust NRTs (nullable reference types) way more.\n\n‚ûï Raw string literals\n\n\n\n\n\"\"\" hello \"\"\";\n\n\n\n\n‚ûï Newlines in string interpolation expressions\n\nThe text inside the { and } characters for a string interpolation can now span multiple lines.\n\n‚ûï File-local types\n\nfile access modifier is scoped to the source\n\n\n\n\n\n\n\n\n6 LTS\n\n\n\n\n\n\n\n\nLTS until\nNovember 2024\n\n\nreleased\nNovember 2021\n\n\n\n\n\n\n.NET 6 unifies the SDK, base libraries, and runtime across mobile, desktop, IoT, and cloud apps.\n\n\n+Massive gains in performance\n\n\n\n\nC#10\n\n\n‚ûï Pattern matching enhancements\n\n\n\n‚ûï Extended property patterns\n\nNested properties:\n\n\n\n\n\n\n\n\n{ Prop1.Prop2: pattern }\n\n\n\n\n‚ûï File-scoped namespace declaration\n\n\n\n\nnamespace MyNamespace;\n// instead of nesting\n\n\n\n\n‚ûï Allow both assignment and declaration in the same deconstruction\n\n\n\n\n(x, int y) = point;\n\n\n\n\n‚ûï Record structs\n\n\n\n\npublic record struct Point\n{\n    public double X { get; init; }\n    public double Y { get; init; }\n    public double Z { get; init; }\n}\n\n\n\n\n‚ûï Improvements of structure types\n‚ûï Interpolated string handlers\n‚ûï Allow const interpolated strings\n‚ûï global using directives\n‚ûï Improvements on lambda expressions\n‚ûï Record types can seal ToString()\n‚ûï Improved definite assignment\n‚ûï Allow AsyncMethodBuilder attribute on methods\n‚ûï CallerArgumentExpression attribute\n‚ûï Warning wave 6\n\nAny new keywords added for C# will be all lower-case ASCII characters. This warning ensures that none of your types conflict with future keywords.\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\nreleased\nNovember 2020\n\n\n\n\n\n\nskips \"Core\" and is now the main implementation of .NET going forward\n\n\n\n\nC#9\n\n\n‚ûï Pattern matching enhancements\n\n\n\n‚ûï Relational patterns\n\n&lt;, &gt;, &#8656;, or &gt;=\n\n‚ûï logical patterns\n\nand, or, not\n\n\n\n\n‚ûï Unconstrained type parameter annotations\n\nWhich makes NRTs (nullable-reference types) much nicer to use\n\n‚ûï Init only setters\n\n\n\n\nint YearOfBirth { get; init; }\n\n\n\n\n‚ûï Records\n\n\n\n\nrecord Person(string FirstName);\n\n\n\n\n‚ûï Top-level statements\n\nPrograms without Main methods\n\n‚ûï [ModuleInitializer]\n‚ûï Target-typed new expressions\n\nWrite just new(); when the type is known\n\n‚ûï Target-typed conditional expressions\n\nM(b ? 1 : 2)\n\n‚ûï Covariant return types\n‚ûï Lambda discard parameters\n\n\n\n\n(_, _) =&gt; 0\n\n\n\n\nF#5\n\n\n\n\n\nCore 3.1 LTS\n\n\n\n\n\n\n\n\nLTS until\nNovember 2022\n\n\nreleased\nNovember 2019\n\n\n\n\n\n\nCore 3.0 LTS\n\n\n\n\n\n\n\n\nreleased\nSeptember 2019\n\n\n\n\n\n\nFits (.NET Standard 2.1 &#8658; 37,118 of the 37,118 APIs)\n\n\n‚ûï WinForms, WPF on Windows\n\nOnly on windows.\n\n\n\n\n\n\n\nC#8.0 (only part of core)\n\n\n‚ûï readonly members\n‚ûï Default interface methods\n\nMethods in interface can have an implementation now\n\n‚ûï Pattern matching enhancements\n\n\n\n‚ûï switch expression\n‚ûï Property patterns\n\n\n\n\n\n\n\nshape switch { { Point: { Y : 100 } } =&gt; \"Y is 100\"};\n\n\n\n\n‚ûï Tuple patterns\n\n\n\n\n(animal, other) switch { (Animal.Bird, _} =&gt; \"It's a Bird\" };\n\n\n\n\n‚ûï Positional patterns\n\n\n\n\nshape switch { Rectangle (100, 100) =&gt; \"It's a square\" };\n\n\n\n\n‚ûï Nullable reference types\n\nAka non-nullable Person and nullable Person?\n\n‚ûï using declarations\n\nDon&#8217;t require braces, variable is disposed at the end of the scope\n\n‚ûï Static local functions\n‚ûï await foreach\n‚ûï Indices and ranges\n\n.., start.., ..end, ^start.. etc.\n\n‚ûï Null-coalescing assignment\n\n??=\n\n‚ûï Enhancement of interpolated verbatim strings\n\n$@ combination is still allowed but now also the @$ order.\n\n\n\n\n\nF# 4.7\n\n\n\n\n\n4.8\n\n\n\n\n\n\n\n\nreleased\nAugust 2019\n\n\n\n\n\n\nThe final framework (still stuck at .NET Standard 2.0 &#8658; 32,638 of the 37,118 APIs)\n\n\nC# &#8656; 7.3\n\n\n\n\n\n\nCore 2.2\n\n\n\n\n\n\n\n\nreleased\nDecember 2018\n\n\n\n\nC#7.3\n\n\n\nC#7.2\n\n\n\n\n\nCore 2.1 LTS\n\n\n\n\n\n\n\n\nLTS until\nAugust 2021\n\n\nreleased\nMay 2018\n\n\n\n\n\n\nCore 2.0\n\n\n\n\n\n\n\n\nreleased\nAugust 2017\n\n\n\n\n\n\n(.NET Standard 2.0 &#8658; 32,638 of the 37,118 APIs)\n\n\n\n\nC#7.1\n\n\n‚ûï async Main method\n‚ûï Default literal expressions\n‚ûï Inferred tuple element names\n‚ûï Pattern matching on generic type parameters\n\n\n\n\nif (item is List&lt;T&gt; value)\n{\n// ...\n}\n\n\n\n\n\n\n4.7\n\n\n\n\n\n\n\n\nreleased\nJune 2017\n\n\n\n\n\n\n(.NET Standard 2.0 &#8658; 32,638 of the 37,118 APIs)\n\n\nVisual Studio 2017\n\n\n\n\nC#7\n\n\n‚ûï Out variables\n\n\n\n\nGetEmployeeDetails(out string EmployeeName);\n\n\n\n\n‚ûï Tuples and deconstruction\n\n\n\n\nvar t = (\"post office\", 3.6);\n// and\nvar (destination, distance) = t;\n\n\n\n\n‚ûï Pattern matching\n\nVia is operator in if or switch statements.\n\n‚ûï Local functions\n\nMethods nested in other members\n\n‚ûï Expanded expression bodied members\n‚ûï Ref locals\n\n\n\n\nint a = 1;\n// and\nref int alias = ref a;\n\n\n\n\n‚ûï Ref returns\n‚ûï Discards\n\nUse an underscore when you don&#8217;t need the variable:\n\n\n\n\n\n(_, _, area) = city.GetCityInformation(cityName);\n\n\n\n\n‚ûï Binary Literals and Digit Separators\n\n\n\n\nvar binaryLiteral = 0b_0010_1010;\n// and\nvar bigNumber = 123_456_789;\n\n\n\n\n‚ûï Throw expressions\n\n\n\n\nstring first = args.Length &gt;= 1 ? args[0] : throw new ArgumentException(\"Please supply at least one argument.\");\n\n\n\n\n\n\nCore 1\n\n\n\n\n\n\n\n\nreleased\nJune 2016\n\n\n\n\n\n\n(.NET Standard 1.6 &#8658; 13,501 of the 37,118 APIs)\n\n\nCross-platform: Runs on Windows, macOS and Linux.\n\n\n\n\n\n\n\n4.6 LTS\n\n\n\n\n\n\n\n\nLTS until\nJanuary 2027\n\n\nreleased\nJuly 2015\n\n\n\n\n\n\nVisual Studio 2015\n\n\nRoslyn v1\n\n\n\n\nC#6\n\n\n‚ûï Static imports\n‚ûï Exception filters\n\n\n\n\ncatch (ExceptionType [e]) when (expr)\n\n\n\n\n‚ûï Auto-property initializers\n\n\n\n\nstring FirstName { get; set; } = string.Empty;\n\n\n\n\n‚ûï Default values for getter-only properties\n‚ûï Expression bodied members\n\n\n\n\nvoid DisplayName() =&gt; Console.WriteLine(ToString());\n\n\n\n\n‚ûï Null propagator\n\n?. and ?[]\n\n‚ûï String interpolation\n\n\n\n\nConsole.WriteLine($\"Hello {name}\");\n\n\n\n\n‚ûï nameof operator\n‚ûï Index initializers\n\n\n\n\nvar foo = new IndexableClass { [0] = 10 };\n\n\n\n\n‚ûï Await in catch/finally blocks\n\n\n\n\ntry\n{\n    // something that throws\n}\ncatch\n{\nawait Task.Delay(1000); // using await in catch block\n}\n\n\n\n\nF# 4\n\n\n\nVB 14\n\n\n\n\n\n4.5\n\n\n\n\n\n\n\n\nreleased\n2012\n\n\n\n\n\n\nCLR 4.0\n\n\nVisual Studio 2012\n\n\n\n\nFramework\n\n\n\nBackground just-in-time (JIT) compilation\n\n\n\n\n\nC#5\n\n\n‚ûï Asynchronous members aka async and await\n‚ûï Caller info attributes\n\n\n\n\npublic void TraceMessage(\n    string message,\n    [CallerMemberName] string memberName = \"\",\n    [CallerFilePath] string sourceFilePath = \"\",\n    [CallerLineNumber] int sourceLineNumber = 0)\n{\n// ...\n}\n\n\n\n\n\n\n4\n\n\n\n\n\n\n\n\nreleased\n2010\n\n\n\n\n\n\nCLR 4.0\n\n\nVisual Studio 2010\n\n\n\n\nFramework\n\n\n‚ûï Background garbage collection\n‚ûï Code Contracts\n‚ûï Dynamic Language Runtime\n‚ûï Windows Presentation Foundation (WPF) 4\n\nAdding amongst other things DataGrid, DatePicker, and Calendar controls.\n\n\n\n\n\nC#4\n\n\n‚ûï Dynamic binding\n\n\n\n\ndynamic dyn = 1;\n\n\n\n\n‚ûï Named/optional arguments\n\n\n\n\nExampleMethod(3, optionalint: 4);\n// where\nint optionalint = 10\n\n\n\n\n‚ûï Generic covariant and contravariant\n\nImplicit or explicit covariant out and contravariant in keyword.\n\n‚ûï Embedded interop types\n\nEases the deployment pain of creating COM interop assemblies\n\n\n\n\n\n\n\n3.5\n\n\n\n\nCLR 2.0\n\n\n\n\nFramework\n\n\n‚ûï WCF and WF integration\n\nWindows Communication Foundation.\n\n\n\n\n\n\n\n3\n\n\n\n\n\n\n\n\nreleased\n2007\n\n\n\n\n\n\nCLR 2.0\n\n\nVisual Studio 2008\n\n\n\n\nFramework\n\n\n‚ûï Windows Presentation Foundation\n‚ûï Windows Communication Foundation\n‚ûï Windows Workflow Foundation\n‚ûï Windows CardSpace\n\nAn identity selector app.\n\n\n\n\n\nC#3\n\n\n‚ûï Auto-implemented properties\n\n\n\n\npublic string Name { get; set; }\n\n\n\n\n‚ûï Implicitly typed local variables\n\n\n\n\nvar\n\n\n\n\n‚ûï Anonymous types\n\n\n\n\nvar v = new { Amount = 108, Message = \"Hello\" };\n\n\n\nNotice that v has no type.\n\n\n\n‚ûï Query expressions aka LINQ\n‚ûï Lambda expressions\n‚ûï Expression trees\n‚ûï Extension methods\n‚ûï Partial methods\n\n\n\n\npartial void OnSomethingHappened(String s)\n\n\n\n\n‚ûï Object and collection initializers\n\n\n\n\nnew Cat { Age = 10\n// and\nnew List&lt;int&gt; { 0, 1, 2};\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\nreleased\n2005\n\n\n\n\n\n\nCLR 2.0\n\n\nVisual Studio 2005\n\n\n\n\nFramework\n\n\n‚ûï Debugger edit and continue\n‚ûï Improved scalability and performance\n‚ûï ClickOnce deployment\n‚ûï In ASP.NET 2.0, new controls and support for a broad array of browsers\n‚ûï 64-bit support\n\nFor the first time.\n\n\n\n\n\nC#02\n\n\n‚ûï Generics\n‚ûï Partial types\n‚ûï Anonymous methods\n‚ûï Iterators\n‚ûï Covariance and contravariance\n\nImplicit reference conversion for array types and method groups.\n\n‚ûï Nullable value types\n‚ûï Null-coalescing operator\n\n??\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\nreleased\n2002\n\n\n\n\n\n\nCLR 1.0\n\n\n\n\nC#1"

    },
  
    {

      "title"    : "Structure-cementing tests and how to avoid them 1/3",
      "url"      : "/posts/Structure-Cementing-Tests-1",
      "content"  : "Part 1 - Building a TestDsl\n\n\nTests should react to behavioral changes but be insensitive to structural changes. We call tests that do not fulfill the second condition structure-cementing. They make it difficult or even impossible to change the structure and architecture. Teams to whom this happens test and improve less code.\n\n\nWith the right approach and a TestDsl, however, we can completely avoid cementation and write tests that turn from integration tests to unit tests after changing just one line of test code.\n\n\n\n\nThe two modes of development\n\n\nIf we change behavior, we should have to change tests. When we restructure code (add, rename or remove methods, classes, parameters or fields) we should not have to change the tests. Both conditions are essential because agile developers are constantly jumping back and forth between the two modes change behavior and change structure.\n\n\nA failing test forces us to jump to the change behavior mode to get it green again. When we get the test green we jump back to change structure mode. The green test now provides the safety net we need to change structure safely. Any time we change the structure (aka refactor) the tests tell us if we did it without changing behavior (see figure). The same applies if we write our tests after the implementation, then the transition between the modes is just not quite as pronounced.\n\n\n\n\n\nFigure 1. The two development modes, loosely based on Kent Beck\n\n\nChanging behavior is of course very risky, because a desired change in behavior can also bring with it an undesirable one. So most of the time we want to spend in change structure mode and use techniques like preparatory refactoring [1] that make our behavior change as simple and manageable as possible.\n\n\nHowever, this also requires tests that allow structural changes and do not cement them. Such tests allow us to proceed in very small and manageable steps. A difficult change is first prepared with 10 to 20 ‚Äúr‚Äù (refactor) commits in order to then make a very small ‚ÄúF‚Äù (feature) commit. The commit format is Arlo&#8217;s Commit Notation [2], because this models the risk of the commit.\n\n\n\n\nWhen faced with a hard change, first make it easy (warning, this may be hard), then make the easy change.\n\n\n\n&#8212; Kent Beck [3]\n\n\n\nHowever, if the structure is cemented, then not only are structural but also feature-related behavioral changes more difficult. This is because we no longer build features where they make sense, but where they are easier to integrate. As a result, the code becomes increasingly confusing. At the beginning, you can no longer find code, it ends up in the simplest place, not the most sensible one. Later on, there are more and more unexpected dependencies, more and more unknown unknowns. We change one place and this leads to a behavior change in a completely different place.\n\n\nThe structure-cementing tests have destroyed maintainability. Or we have deleted them and caught regressions.\n\n\nTests are structure-cementing in two ways:\n\n\n\n\nthrough redundancy: tests use the same structure in several places. The more often the same structure (class, method) is required and the more excessively mocked, the more the design is cemented.\n\n\nby testing at the wrong level: we test unstable elements and not modules.\n\n\n\n\nIn part 1 of this article series, we look at how we can avoid structure-cementation through redundancy with a TestDsl, in part 2 we explain the concepts of the Dsl in more detail and part 3 deals with the correct test levels.\n\n\n\n\nThe initial test\n\n\nWe can see the cementation through redundancy in Initial test.\n\n\nInitial test\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = new Book(bookId(\"b\"), \"Refactoring\", \"Martin Fowler\"); \n    var permission = new Permission(permissionId(\"p\"), CAN_RENT_BOOK);\n    var role = new Role(roleId(\"r\"), \"Renter\", permission.id);\n    var user = new User(userId(\"u\", \"Alex Mack\", role.id));\n\n    var books = new InMemoryBooksDouble(); \n    var permissions = new InMemoryPermissionsDouble();\n    var roles = new InMemoryRolesDouble();\n    var users = new InMemoryUsersDouble();\n\n    books.add(book); \n    permissions.add(permission);\n    roles.add(role);\n    users.add(user);\n\n    var testee = new RentingService(new ClockDouble(), books, permissions, roles, users /* ... */); \n    // when\n    var result = testee.rentBook(book, user); \n    // then\n    assertThat(result.isRented()).isTrue();\n}\n\n\n\n\n\n\nThe basis for most of our tests are, in this example, books. Therefore, most of our tests instantiate at least one book and with each redundant instantiation we cement the structure of book more and more, since a change would result in adjustments in hundreds of tests.\n\n\n\nThe repositories follow the naming convention +{implementation}+{name of managed entity with plural s}Double. The Double postfix indicates that this is a test double [4] located in src/testFixtures (or src/test). The postfix is not necessary, but it makes finding all created doubles very convenient.\n\n\n\nOur code to be tested needs to load the books from the repository, so they must also be stored there first. How this is done is actually an irrelevant implementation detail for the test. However, redundancy in several tests cements this. It also makes the test unnecessarily long.\n\n\n\nThe more often we instantiate the RentingService, the less interest we have in changing its dependencies. The dependencies of our service are cemented.\n\n\n\nThe method whose behavior we actually want to test. Cementing the structure of this method with multiple tests is a tradeoff we want to make because this time we get something back: Feedback. Feedback on whether the method is pleasant and logical to use.\n\n\n\n\nIn addition to the test smell ‚Äústructure-cementing‚Äù, this test has a few other problems:\n\n\n\n\nlong test: there is a lot to read and therefore many potentially hidden errors.\n\n\nirrelevant details: Does it have to be a specific book or is any book possible? Do the fields have to have the specified values for the test to be successful?\n\n\n\n\nWe will therefore refactor the test in several steps and work our way towards the final TestDsl [Complete test with TestDsl Extension].\n\n\n\n\n1. Refactoring - Factory Methods\n\n\nWe can break the redundancy and focus tests by no longer instantiating objects directly, but using factory methods [Factory Methods].\n\n\nFactory Methods\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = makeBook();\n    var permission = makePermission(CAN_RENT_BOOK);\n    var role = makeRole(permission);\n    var user = makeUser(role);\n\n    var books = new InMemoryBooksDouble();\n    // remaining Test\n    // ...\n}\n\nstatic Book makeBook(){\n    return new Book(bookId(\"b\"), \"Refactoring\", \"Martin Fowler\");\n}\n\n\n\nFor this small example this is fine, but we quickly run into many problems with this approach (which is also known as the object-mother [5] pattern):\n\n\n\n\neither each new use case gets a new method (makeBook(), makeExpensiveBook() etc.).\n\n\nor the method gets dozens of optional parameters without it being clear which parameters are dependent on each other.\n\n\n\n\nThis does not mean that factory methods should not be used. Especially when introducing new structures, factory methods are great because we can create them directly in the test class where we need them. However, if we are more sure about our structure, we should first use the Builder from the next section [Builder Methods] within the factory method and then inline it with our refactoring tools.\n\n\n\n\n2. Refactoring - Simple Builder\n\n\nInstead of the factory method or the object-mother pattern, we prefer to use a builder [Builder Methods].\n\n\nBuilder Methods\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = new BookBuilder().build();\n    var permission = new PermissionBuilder().withPermission(CAN_RENT_BOOK).build();\n    var role = new RoleBuilder().withPermissions(permission).build();\n    var user = new UserBuilder().withRole(role).build();\n\n    var books = new InMemoryBooksDouble();\n    // remaining Test\n    // ...\n}\n\n\n\nIf you call the build() method directly, the entity is assigned default values. With the withX() methods, we can adapt the default values to our specific test if necessary. We are therefore much more flexible than with the Factories/Object Mother pattern, because not every case needs its own method.\n\n\nWith the builder, we have also redirected the redundant dependencies to a test-specific abstraction [Cementing structure by init]. We now only have to make changes to the structure of the entity in the builder, not in n tests. We can maintain the structural changes in the builder because we are protected by the tests that already use the builder. If existing tests become red, we have broken something.\n\n\n\n\n\nFigure 2. Cementing structure by init\n\n\nIn addition to flexible test setup and avoiding the cementing of structure, such a Builder offers us a few more advantages:\n\n\n\n\nthe test no longer mentions irrelevant details. The above test shows us that it needs any book and not a specific one.\n\n\nthe builder highlights essential differences between the tests. By using the with() method, we see that the user in the test absolutely needs the CAN_RENT_BOOK permission.\n\n\nin the builder we have a unique place to store technically meaningful default values [Entity-TestBuilder]. Practical documentation for developers.\n\n\n\n\nEntity-TestBuilder\n\npublic class BookBuilder extends TestBuilder&lt;Book&gt; {\n\n    public BookId id = ids.next(BookId.class);\n    public String title = \"Refactoring\"; \n    public String author = \"Martin Fowler\";\n    public Instant createdOn = clock.now();\n\n    public BookBuilder(Clock clock, Ids ids){ \n        super(clock, ids);\n    }\n\n    public BookBuilder(){ \n        this(globalTestClock, globalTestIds);\n    }\n\n    public Book build(){\n        return new Book(id, title);\n    }\n\n    public BookBuilder with(Consumer&lt;? super BookBuilder&gt; action) { \n        action.accept(this);\n        return this;\n    }\n\n    \n}\n\n\n\n\n\n\nUseful defaults that are representative for the production are stored here.\n\n\n\nWe already design the builder so we can enter the two main sources of non-deterministic tests (time and random values) from outside.\n\n\n\nWith the TestDsl refactoring, this parameterless constructor is omitted.\n\n\n\nThe with() method speeds up the writing of the initial builder. However, you then have to get used to the fact that the builder has public fields. This is a trade-off that can be made for tests. The specific withX() are more flexible because they can be overloaded though.\n\n\n\nAs an alternative to the generic with(), you can introduce field-specific withX() methods below.\n\n\n\n\nHowever, we are not finished yet, because the combination of permission, role and user can be modeled even more strongly and the test can be further focused.\n\n\n\n\n3. Refactoring - Combo Builder\n\n\nWe introduce the concept of the Combo Builder [Using the ComboBuilder] so that we can build several separately stored objects in a coordinated manner.\n\n\nUsing the ComboBuilder\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = new BookBuilder().build(); \n    var userCombo = new UserComboBuilder.with(it -&gt;\n        it.hasPermissions(CAN_RENT_BOOK)\n    ).build();\n    // Combo includes:\n    // var permissions = userCombo.permissions();\n    //   var role = userCombo.role();\n    //   var user = userCombo.user();\n\n    var books = new InMemoryBooksDouble();\n    // remaining Test\n    // ...\n}\n\n\n\nTo keep the complexity of the combo builder low, it only ever builds standard cases [Entity-ComboBuilder]. For more difficult and atypical situations, e.g. if a user has several roles, the individual builders of permission, role and user are used again. This is important because all the special cases will create a lot of unmaintainable code. The rule of thumb is that a builder should never contain if or switch.\n\n\nEntity-ComboBuilder\n\npublic class UserComboBuilder implements TestBuilder&lt;UserCombo&gt; {\n\n    // combination fields\n    private List&lt;Permission&gt; permissions = Collections.emptyList();\n\n    public UserCombo build(){\n        var role = new RoleBuilder().withPermissions(permissions).build();\n        var user = new UserBuilder().withRole(role).build();\n        return new UserCombo(user, role, permissions);\n    }\n\n    public UserBundleBuilder hasPermissions(PermissionCode... permissionCode) {\n        this.permissions = Stream.of(permissionCode)\n            .map(code -&gt; new Permission(code))\n            .toList();\n        return this;\n    }\n}\n\n\n\nUsing the builder has already streamlined the test considerably. However, we still have the implementation detail of the repositories. We still need to store created entities in repositories and the test needs to know how to do this.\n\n\n\n\n4. Refactoring - TestDsl\n\n\nFirst we introduce the TestState.\n\n\nUsing the TestState\n\nprivate TestState a; \n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = a.book(); \n    var userCombo = a.userCombo(it -&gt; it.hasPermission(CAN_RENT_BOOK));\n\n    var books = new InMemoryBooksDouble();\n    var permissions = new InMemoryPermissionsDouble();\n    var roles = new InMemoryRolesDouble();\n    var users = new InMemoryUsersDouble();\n\n    books.add(book);\n    permissions.addAll(userCombo.permissions());\n    roles.add(userCombo.role());\n    users.add(userCombo.user());\n\n    var testee = new RentingService(new ClockDouble(), books, permissions, roles, users /* ... */);\n    // WHEN + THEN\n    // ...\n}\n\n\n\n\n\n\nThe TestState is a class that knows all builders.\n\n\n\nBuild tasks are always delegated to the already written builders.\n\n\n\n\nAt first glance, we only gain some compactness: xyzBuilder() no longer needs to be instantiated and we don&#8217;t need a .build() method. Behind the scenes, however, we have gained much more. The TestState is now a central point that recognizes all created entities. We can therefore ask the state to store all created entities in the repositories and streamline our test even further [Saving state to the floor].\n\n\nSaving state to the floor\n\nprivate TestState a;\nprivate Floor floor; // contains the floor that the application is build on\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = a.book();\n    var userCombo = a.userCombo(it -&gt; it.hasPermission(CAN_RENT_BOOK));\n    a.saveTo(floor);   \n\n    var testee = new RentingService(floor); \n    // WHEN + THEN\n    // ...\n}\n\n\n\n\n\n\nWith this call, we save book, permission, role and user in the respective repositories. Theoretically, the call to a.book(); could already have saved the book in the BookRepository. However, the saveTo() makes saving more explicit and also offers the flexibility to create entities that do not automatically end up in repositories.\n\n\n\nWe group all Ports into the outside world in the so-called Floor, the floor on which our application stands. A repository is such a Port, just like Clock or an external Client. The Floor allows us to flexibly control how our testee communicates with the outside world in tests. We can pull the floor out from under the feet of our application in tests and set up a much more testable floor. In the ports &amp; adapters architecture [6], the floor is synonymous with the driven but not the driving ports. Since it is easy to overlook whether something is driven or driving, the terms were out of the question. Floor was chosen as an identifier because it is short and thus provides an analogy for software architects gardeners who take care of the Forest Floor, the Forest Canopy and the forest. Alternative names for driven (=outcomes) or driving (=triggers) Port were not known at the time.\n\n\n\nWe made the Floor part of our production code. To instantiate service classes, you only ever need the Floor [RentingServices extracts only required dependencies] and no longer have to write the concrete dependencies.\n\n\n\n\nTo simplify the dependency management we pass floor directly to the constructor of our production services [RentingServices extracts only required dependencies]. We don&#8217;t have to do this to utilize the TestDsl. Alternatively, we could have left the constructor of the service as it is and written a configureRentingService(floor) method for tests that assigns dependencies from the Floor. Both ways avoid the structure cementation of the RentingService. If we were to use an DI-Container like Spring to instantiate the service, we would have the same advantage. However, many of these containers make tests slower due to their startup overhead and make test parallelization more difficult due to context caching, which is why they are not a good choice for unit tests. In general we should write unit tests without such containers. This recommendation is also shared by the Spring Framework [7].\n\n\nRentingServices extracts only required dependencies\n\npublic class RentingService {\n    private final Clock clock;\n    private final Books books;\n    // etc.\n\n    public RentingService(Floor floor) {\n        this.clock = floor.clock();\n        this.books = floor.books();\n        // etc.\n    }\n}\n\n\n\nTo ensure that the tests are isolated from each other, we instantiate TestState and Floor for each test [Instantiate TestDsl in BeforeEach].\n\n\nInstantiate TestDsl in BeforeEach\n\nprivate TestState a;\nprivate Floor floor;\n\n@BeforeEach\nvoid init(){\n    var dsl = TestDsl.of(unitFloor());\n    a = dsl.testState();\n    floor = dsl.floor();\n}\n\n\n\nThe floor itself is simply an interface that recognizes all dependencies [Floor of the TestDsl]. The unit test implementation unitFloor() then returns InMemoryDoubles when the methods are called.\n\n\nFloor of the TestDsl\n\npublic interface Floor {\n    Clock clock();\n    Books books();\n    // etc.\n}\n\n\n\nThe sum of these changes is that our test looks very compact [Complete test with TestDsl].\n\n\nComplete test with TestDsl\n\nprivate TestState a;\nprivate Floor floor;\n\n@BeforeEach\nvoid init(){\n    var dsl = TestDsl.of(unitFloor());\n    a = dsl.testState();\n    floor = dsl.floor();\n}\n\n@Test\nvoid should_be_able_to_rent_book(){\n    // given\n    var book = a.book();\n    var userCombo = a.userCombo(it -&gt; it.hasPermission(CAN_RENT_BOOK));\n    a.saveTo(floor);\n\n    var testee = new RentingService(floor);\n    // WHEN\n    var result = testee.rentBook(book, userCombo.user());\n    // THEN\n    assertThat(result.isRented()).isTrue();\n}\n\n\n\nWe have already come a long way with this refactoring:\n\n\n\n\nwe were able to map the setup for our test in just 4 lines.\n\n\nwe were able to write the entire setup in the same place as our test. You can see at a glance which preconditions the test requires and you don&#8217;t have to scroll or open another file to understand the context.\n\n\nwe were able to hide irrelevant details (any book and any user will do) and highlight relevant ones (the user needs the CAN_RENT_BOOK permission).\n\n\nwe have a standardized way to do the test setup for all tests.\n\n\nwe were able to avoid a structure-cementing test setup.\n\n\n\n\nHowever, we can still make one improvement.\n\n\n\n\n5. Refactoring - Extension\n\n\nSo far we have to write redundant initialization code for the TestDsl in the @BeforeEach block in every test. If we are using JUnit5, we can make it reusable for multiple tests with an annotation [Complete test with TestDsl Extension].\n\n\nComplete test with TestDsl Extension\n\n@Unit @Test \nvoid should_be_able_to_rent_book(TestState a, Floor floor){ \n    // given\n    var book = a.book();\n    var userCombo = a.userCombo(it -&gt; it.hasPermission(\"CAN_RENT_BOOK\"));\n    a.saveTo(floor);\n\n    var testee = new RentingService(floor);\n    // WHEN\n    var result = testee.rentBook(book, userCombo.user());\n    // THEN\n    assertThat(result.isRented()).isTrue();\n}\n\n\n\n\n\n\nOur @BeforeEach is completely merged into the annotation @Unit.\n\n\n\nThe annotation turns the two parts of our Dsl into parameters of the test.\n\n\n\n\nThe new annotation registers a JUnit 5 extension [8]. Such an extension can react to the test LifeCycle by implementing special interfaces. We are only interested in ParameterResolver because it resolves the parameters TestState and Floor [resolveParameter() of the TestDsl extension] that our test requires.\n\n\nresolveParameter() of the TestDsl extension\n\n@Target({ ElementType.METHOD })\n@Retention(RetentionPolicy.RUNTIME)\n@org.junit.jupiter.api.extension.ExtendWith(UnitTestExtension.class) \npublic @interface Unit { } \n\nclass UnitTestExtension implements ParameterResolver {\n    @Override\n    public Object resolveParameter(\n            ParameterContext parameterContext,\n            ExtensionContext extensionContext\n        ) throws ParameterResolutionException {\n\n        var storeNamespace = Namespace.create(\n            getClass(), context.getRequiredTestMethod());\n        var store = extensionContext.getStore(store); \n\n        var dsl = store.getOrComputeIfAbsent(\n            \"UNIT_TEST_DSL\",\n            (key) -&gt; testDslOf(unitFloor()), \n            UnitTestDsl.class\n        );\n\n        var parameterType = parameterContext.getParameter().getType(); \n        if (parameterType.equals(TestState.class))\n            return dsl.testState();\n        else if (parameterType.equals(Floor.class))\n            return dsl.floor();\n        else\n            throw new ParameterResolutionException(\"...\");\n    }\n    // ...\n}\n\n\n\n\n\n\nWith @ExtendWith we connect annotation with the extension code.\n\n\n\nA normal Java annotation. The name is freely selectable.\n\n\n\nExtensions must always save state in a store. This is unique per namespace.\n\n\n\nThis creator function is used if no Dsl has yet been created for the test. The resolveParameter() method is called exactly twice per test. Once for the TestState and once for the Floor. We use getOrComputeIfAbsent() so that the same instance of the Dsl is returned.\n\n\n\nWe use the parameterType to recognize what is to be returned.\n\n\n\n\nIn addition to the UnitTest extension shown here, we can of course write another extension, the IntegrationTestExtension. This looks the same, but uses (key) &#8594; testDslOf(integrationFloor()) as the creator function. The TestState remains the same but the implementation of the Floor is an IntegrationFloor which does not contain InMemoryDoubles but Jpa repositories.\n\n\nSince the TestState only knows the Floor interface and not the concrete implementation, we can now make any test by changing a single annotation from an @Integration to an @Unit test. This property of the TestDsl is particularly helpful for legacy code, because this code often contains a lot of domain logic in the database.\n\n\nIn legacy code you can start by writing  integration tests to catch regressions. Once you have pulled the domain logic out of the database and into the application code, you can convert the tests you wrote at the start into unit tests by just changing the annotation. Without a TestDsl, you would have to completely rewrite them at unit level, which is why many teams do not do this, remain stuck with slow integration tests and cannot iterate much faster despite increasing test coverage.\n\n\n\n\nAlternatives\n\n\nTesting without mocks‚Äù [9] follows a similar approach to TestDsl. With this approach, however, you have to modify your production code more because we place special test doubles, the so-called ‚Äúnullables‚Äù [10], directly in the production code.\n\n\nThe refactoring tools of our IDE can also prevent certain forms of structure-cementation from our initial test [Initial test]. ‚ÄúChange Signature‚Äù is the most helpful refactoring against structure cementing. It works great when you need to remove constructor parameters. Adding them, however, is only useful if the default parameter inserted in tests are very simple and have no dependency on other state in the test. These refactoring tools can also create bugs, when default values are not only set in the test code, but also in the production code, and you forget to change them. It is clear that the Dsl-Builder are more flexible than the change signature refactoring and are better at preventing entity cementation. The same applies to the TestState which allows more flexible customization of the Ports. Refactoring tools are therefore not a replacement, but a supplement for the TestDsl.\n\n\nThe refactoring framework Open Rewrite [11] looks promising, but seems to be designed more for framework migrations. It should therefore also be more of a supplement to TestDsl, which focuses on domain logic.\n\n\n\n\nInterim conclusion\n\n\nWith the TestDsl we can make our test setup:\n\n\n\n\nstandardized for all tests,\n\n\ncomplete (nothing needs to be outsourced),\n\n\ncompact (although nothing has been outsourced),\n\n\nfree of irrelevant details,\n\n\nwith relevant details highlighted,\n\n\nreadable,\n\n\nlow-maintenance,\n\n\nparallelizable,\n\n\nfast,\n\n\nand free of structure cementation\n\n\n\n\nThe TestDsl is of course not free. But it is not expensive either. We have to create a foundation with Extension, TestState, Floor and BaseInMemoryDouble. Experience from several JVM and Node projects shows that the maintenance effort is low once this foundation has been laid.\n\n\nIt is rather rare that you have to create new entities. You work much more with existing entities and services and restructure them. The initial investment then pays dividends continuously. Since the entire setup is done via the Dsl [see figure], only the Dsl is affected by structural changes.\n\n\n\n\n\nFigure 3. The TestDsl is between tests and the structure of the production code\n\n\nThe figure also shows what the actual trade-off is that we make with the Dsl: Loss of feedback on our setup. Without Dsl, you notice whether the setup is ‚Äúannoying‚Äù when writing tests. If you have to write a lot of code for testing, you naturally ask yourself whether there is an easier way to do it. There is a natural pressure to improve the structure. This ‚Äúannoying‚Äù setup can now be hidden in the Dsl. It is therefore all the more important to use the Dsl only for the setup, to leave it as dumb as possible, to define as few combo builders as possible and to keep thinking about whether the structure is on the right track when adapting the Dsl.\n\n\n\n\nOutlook\n\n\nIn this part we have seen how to solve structure cementation through redundancy with the TestDsl.\n\n\nIn the part 2, we will take a closer look at the concepts on which the TestDsl is based. We will go into the design of the builder, how to combine the DSL with @SpringBootTest, what the difference between a high- and a low-level TestDsl is, how to keep test doubles synchronized with the production code and why the excessive use of mocking frameworks also leads to structure cementation.\n\n\nIn part 3, we will see how to prevent the other kind structure cementation: testing unstable elements instead of modules.\n\n\nIf you want even more information on the topic, you can view the TestDsl example code on Github [12] or watch the presentation on ‚ÄúBeehive Architecture‚Äù [13] (in üá©üá™), which is also about the TestDsl.\n\n\n\n\n\n\n\n\nThis article was originally published in Java Aktuell 4/24 in üá©üá™. It is translated and republished here with the magazine&#8217;s permission.\n\n\n\n\n\n\n\nReferences\n\n\n\n\n[1] M. Fowler, ‚ÄúAn example of preparatory refactoring.‚Äù 2015. Available: https://martinfowler.com/articles/preparatory-refactoring-example.html\n\n\n[2] A. Belshee, ‚ÄúArlo‚Äôs Commit Notation.‚Äù 2018. Available: https://github.com/RefactoringCombos/ArlosCommitNotation\n\n\n[3] K. Beck, ‚ÄúMastering Programming.‚Äù Available: https://tidyfirst.substack.com/p/mastering-programming\n\n\n[4] G. Meszaros, ‚ÄúTest Double.‚Äù 2011. Available: http://xunitpatterns.com/Test%20Double.html\n\n\n[5] M. Fowler, ‚ÄúObject Mother.‚Äù 2006. Available: https://martinfowler.com/bliki/ObjectMother.html\n\n\n[6] \tA. Cockburn, ‚ÄúHexagonal architecture.‚Äù 2005. Available: https://alistair.cockburn.us/hexagonal-architecture/\n\n\n[7] \tT. Spring, ‚ÄúUnit Testing.‚Äù 2006. Available: https://docs.spring.io/spring-framework/docs/2.0.4/reference/testing.html#unit-testing\n\n\n[8] T. JUnit5, ‚ÄúJUnit 5 User Guide - Extension Model.‚Äù Available: https://junit.org/junit5/docs/current/user-guide/#extensions\n\n\n[9] J. Shore, ‚ÄúTesting Without Mocks: A Pattern Language.‚Äù 2023. Available: https://www.jamesshore.com/v2/projects/nullables/testing-without-mocks\n\n\n[10] \tJ. Shore, ‚ÄúNullables.‚Äù 2023. Available: https://www.jamesshore.com/v2/projects/nullables/testing-without-mocks#nullables\n\n\n[11] \tT. Moderne, ‚ÄúLarge-scale automated source code refactoring.‚Äù 2024. Available: https://docs.openrewrite.org/\n\n\n[12] R. Gross, ‚ÄúTestDsl (Avoid structure-cementing Tests).‚Äù 2024. Available: https://github.com/Richargh/testdsl\n\n\n[13] R. Gross, ‚ÄúBeehive Architecture üá©üá™‚Äù 2023. Available: http://richargh.de/talks/#beehive-architecture"

    },
  
    {

      "title"    : "JORM (Json Object-Relational Mapping) is not REST",
      "url"      : "/posts/JORM-is-not-REST",
      "content"  : "The Richardson Maturity Model is a great model for explaining the basics of building an http Api.\nUnfortunately the indexing of its layers (0, 1, 2, 3) suggests that reaching Level 1 is already REST.\nThat is a problem because it closes people to the decoupling and integration merits that actual REST has and leaves them with an API that can only be described as JORM (Json Object-Relational Mapping): Their API is not designed to solve a problem but to get data from A to B, so the problem can be solved at B.\n\n\nFor Service B to solve the problem it needs to make decisions based on state.\nThat means we have to transfer a lot of state and the resulting json needs a huge schema that needs to stay in sync.\nIt also means that Service B has to interpret that data in the same way that Service A would, which means code duplication between different services and often different teams, which leads to coupled releases and coupled teams.\nThis form of coupling is inherent with RPC (remote procedure call)-style Apis and it is something that REST was designed to solve.\n\n\nWith this in mind I present the updated model, Richard&#8217;s Maturity Model (sorry for the name, couldn&#8217;t resist):\n\n\n\n\n\n\n\nWhen you think REST, think Hypermedia.\nThe inventor of REST, Roy Fielding, described the architectural style quite well in his dissertation in 2000, and explained the point again in 2008 (REST APIs must be hypertext-driven).\n\n\nAn example\n\n\nTo make this more transparent, let&#8217;s see how JORM and REST differ when we model a bank Api for viewing your account balance and transferring money.\n\n\nJORM-Style\n\nGET https://cool-bank.com/api/accounts/1234 (JORM-Style)\n\n{\n  \"id\": \"aa-11\",\n  \"ownerId\": \"b2-d2\",\n  \"balance\": 490.00,\n  \"currency\": \"EUR\",\n  \"transactions\": [\n    {\n      \"id\": \"aa-11-11\",\n      \"source\": \"b2-d2\",\n      \"target\": \"c3-pd\",\n      \"amount\": 10.00,\n      \"currency\": \"EUR\",\n      \"date\": \"2024-08-20T01:23:45.678Z\"\n    }\n  ]\n}\n\n\n\nIt&#8217;s possible the Api is too simplistic but it&#8217;s a good place to start discussing things because this Api is missing some important things:\n\n\n\n\nWhere can we find further information? Where can we lookup the source and target of the transaction?\n\n\nWhat actions are we allowed to take? Can we transfer more money? Can we close the account?\n\n\n\n\nThe first question is usually addressed by something like Api Blueprint or OpenApi which provides documentation for a human to sift through, guess and finally try if GET /api/users/b2-d2 or GET /api/owners/b2-d2 provides the right data for the source of the transaction.\nIt would be more convenient and less error-prone if the Account-Representation would tell us where the data is.\nIt would also make our Api evolvable.\nThe JORM approach leads to code where URLs are constructed via string concatenation, which means the URLs cannot change.\nThe URL is in fact the Api.\nIf we instead not hard-code anything but just follow links that the server supplies then the server can change them at any time.\n\n\nThe second question cannot be addressed by JORM in a satisfying way because it always requires code duplication:\nIf we can and are allowed to withdraw money or close this account is dependent on multiple business rules.\nA transaction is always possible unless the account is closed and unless the balance is below zero, but sometimes below zero is also ok but only up to a certain balance and so on.\nA client would have to implement the same rules as the server and always keep them in sync lest it allows something that the server rejects.\n\n\n\nREST-Style\n\nREST solves these problems, because REST publishes all the possible actions from the current state.\nA client can simply look at the list of actions and decide what to do next.\nIt does not need to know nor care why an action is allowed and thus less information needs to be shared and no duplication occurs:\n\n\nGET https://cool-bank.com/api/accounts/1234 (REST-Style, using Mason Format)\n\n{\n  \"ownerId\": \"b2-d2\",\n  \"balance\": 490.00,\n  \"transactions\": [\n    {\n      \"source\": \"b2-d2\",\n      \"target\": \"c3-pd\",\n      \"amount\": 10.00,\n      \"date\": \"2024-08-20T01:23:45.678Z\",\n\n      \"@controls\": { \n        \"self\": { \"href\": \"https://cool-bank.com/api/transactions/aa-11-11\" }, \n        \"coolb:view-source\": { \"href\": \"https://cool-bank.com/api/transactions/b2-d2\" }, \n        \"coolb:view-target\": { \"href\": \"https://cool-bank.com/api/transactions/c3-pd\" } \n      }\n    }\n  ],\n  \"@controls\": { \n    \"self\": { \"href\": \"https://cool-bank.com/api/accounts/aa-11\" }, \n    \"coolb:close-account\": { \n      \"title\": \"Close account\",\n      \"href\": \"https://cool-bank.com/api/accounts/aa-11\",\n      \"method\": \"DELETE\"\n    }\n  }\n}\n\n\n\n\n\n\nAdditional hypermedia elements\n\n\n\nLink to self\n\n\n\nLink to source and target of the transaction\n\n\n\nThe presence of this control means that we are allowed to close the account\n\n\n\n\nThe response is missing the control for transferring money from a source to a target.\nIt is missing because the account owner is on vacation right now and does not want any transfers.\nOr maybe it is missing because the account is closed.\n\n\nWe don&#8217;t actually need to know the business reason.\nAll our client sees is that the control is missing and therefore it cannot do it.\nWe don&#8217;t need to duplicate why something is not allowed and that means Service A is free to add or remove rules whenever it wants and the client, Service B, just needs to react to the presence of a control or its absence.\n\n\nThis is a supremely powerful concept and why the relatively new REST-style from the year 2000 is better at decoupling teams than the older RPC-Style Apis.\nThe cost is that the services require more protocol knowledge as Oliver Drotbohm describes.\nIf we adapt his drawing so it mentions JORM and REST we get:\n\n\n\n\n\n\n\n\n\n\nSmart Server, Dumb Client\n\n\nThe client only having protocol knowledge gives us very clear benefits when we design a SPAs (Single-Page Applications) or need to support multiple devices such as iOS or Android.\n\n\nA priori the client just needs to know the relevant relations, such as \"coolb:close-account\".\nThe prefix coolb just means that it is a relation of the domain cool bank.\nThere are multiple standardized relations that the client can use such as next or prev for pagination, self for the resource itself or up for the parent of a resource.\n\n\nOnce a client connects it just need to look for the existence of the \"coolb:close-account\" or the \"coolb:transfer-money\" to know it should display the buttons for closing or transferring money.\nIt ignores controls and optional fields that are unfamiliar or renders generic widgets based on the inputs the server requires.\n\n\nAll in all a lot less code is required for each client, because the server controls the interaction and you have a lot less errors to deal with because your iOS, Android or Web Apps cannot mismatch state.\n\n\nIf that seems far-fetched then please consider that you are viewing this post in your browser that allows you to react to arbitrary content without Mozilla, Google, Apple or Microsoft making adaptions in their client.\n\n\nAll your browser has is the protocol knowledge and that is enough.\nIf we design our Apis the same way the web is designed, then we get the same decoupling and scalability benefits that have powered the last 35 years (the web went public in 1991).\nThis is not surprising because Roy Fielding&#8217;s dissertation, which defined the REST architectural style, was defining the core properties of HTTP so he knew which changes would benefit the protocol.\n\n\n\n\nWhat makes HTTP significantly different from RPC is that the requests are directed to resources using a generic interface with standard semantics that can be interpreted by intermediaries almost as well as by the machines that originate services.\n\n\n\n&#8212; Roy Fielding\nhttp://mamund.com/blog/archives/1107\n\n\n\n\n\nThe Why of JORM\n\n\nBy now it should be clear why REST has clear benefits and why a small but vocal group (so called RESTafarians) take every opportunity to point out that most street-REST is not REST (REST: I don&#8217;t Think it Means What You Think it Does).\n\n\nIt seems that this group has switched to using the name Hypermedia and Hypermedia Apis when talking about actual REST though.\nSemantic diffusion has taken its toll but since the REST ideas are so great and there is a dissertation describing them, it is worth bringing back the term REST.\nFor that to work we need a name for the alternative, and since that alternative is close enough to what many object-relational modelling tools give us, the name for the alternative is simply JORM.\n\n\nThe name encourages discussions.\nAs soon as you say, \"Should we build a JORM or a REST Api?\", people get curious.\nCuriosity alone might be enough to get people to research and spread great concepts like Hypermedia controls.\n\n\n\n\nShould everyone adopt REST?\n\n\nNow for the real question: should everyone adopt REST over JORM?\n\n\nTeams that own their clients\n\nI think the sweet spot is when teams own their server (backend) as well as one or more clients (frontend: SPA, iOS or Android app).\nWhen they adopt REST, they can make their clients significantly dumber and by that not only save a lot of code but also iterate faster because their client is decoupled from their server.\n\n\n\nTeams that don&#8217;t own their clients\n\nIt is less clear for company-wide or even global Apis if REST is a good choice for two reasons:\n\n\nREST Apis make it very easy to solve problems because the server exposes all allowed actions in the form of Hypermedia Controls.\nThat however means you have to somehow figure out the problems your clients want to solve.\nAnd then you have to take the time to implement solutions to your clients problems.\n\n\nIf you just expose a lot of state to their outside world, you don&#8217;t have to invest that time.\nYou do have to support that exposed state for a long time though, lest you lose your clients again, and that might take more time in the long run.\n\n\nThe second problem is that most clients are not used to the discoverable nature of REST Apis and demand stable URLs.\nEven without documentation teams often try to retro-engineer the URLs and when they inevitably change, their clients break, which is what Hyrum&#8217;s Law describes:\n\n\n\n\nWith a sufficient number of users of an API, it does not matter what you promise in the contract: all observable behaviors of your system will be depended on by somebody.\n\n\n\n&#8212; Hyrum Wright\nhttps://www.laws-of-software.com/laws/hyrum/\n\n\n\nThat however means the Apis cannot evolve as intended which is why solutions like FIT URLs are proposed where all your URLs are signed and if you don&#8217;t have the right signature for the URL, you get a 404 Not Found, even though the URL exists.\nIt forces people to follow links and it&#8217;s worth looking into, to keep your Api evolvable, but why do I have to force people to use REST?\n\n\n\n\n\nIrony\n\n\n\n\nirony, noun\n\n\nthe use of words to express something other than and especially the opposite of the literal meaning [&#8230;&#8203;]\n\n\n\n&#8212; irony\nhttps://www.merriam-webster.com/dictionary/irony\n\n\n\nREST powers the internet and has allowed it to scale for the last 35 years.\nIt should be perfectly suitable for company or global Apis.\nBut after freeing ourselves from RPC-SOAP, we unintentionally conditioned ourselves to like RPC-JORM but call it REST.\nWhenever we try to rethink our approach, we still go for RPC (grpc) and sometimes even drop designing solutions altogether to instead offload the problem solving to the client (GraphQL).\nIt&#8217;s not that these tools are bad, depending on the use case they might even be a good choice.\nIt is however strange to compare REST, an architectural style, with a tool, specifically one that implements the RPC architectural style (some \"comparisons\" are very good at explaining the difference \"A no nonsense GraphQL and REST comparison\" by Phil Sturgeon).\n\n\nAlso ironic is that people \"in the know\" perceive building a REST Api as too difficult when really it&#8217;s very easy to get started.\nI&#8217;d like to change this perception and have prepared a small Getting Started."

    },
  
    {

      "title"    : "Naming Guidelines",
      "url"      : "/posts/Naming-Guidelines",
      "content"  : "Programming is a team sport where we use code to send messages of intent to our future selves.\nThe messages are the names we have assigned to various function, class and other code elements.\nThe assigned name can then help our future selves figure out the intent of an element and if a new piece of functionality goes here or over there.\nThus naming is inseparable from design.\nA well-chosen name is the difference between one hour of \"I know exactly what to do\" and days and weeks of rework because \"I thought I needed to do this but actually&#8230;&#8203;\".\n\n\n\n\nThere are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors.\n\n\n\n&#8212; Leon Bambrick\n\n\n\nTrue to the above quote I still find namings things very hard.\nFortunately Bob Nystrom has written two great blog posts on the subject: Long Names are Long and Naming Things in Code.\nThese two describe guidelines for naming which I want to reiterate, extend and sometimes even change.\nMost of the stuff I&#8217;ve added are ideas from the community (f.ex. Johannes Seitz).\nI&#8217;m not making any originality vows here :)\n\n\nIn a future post I&#8217;d also like to take a look at Arlo Belshee&#8217;s \"Naming is a Process\" which describes the process of coming up with a good name.\n\n\n\n\n\n\n\n\n\nIf you know about even more great articles, books, etc. please consider contacting me using Twitter and the like.\n\n\n\n\n\n\nGood Names\n\n\nA name has one goal:\n\n\n\n\nIt needs to reveal the authors intention (see Kent Beck&#8217;s Four Rules of Simple Design). Which means:\n\n\n\nIt needs to be clear: you need to know what the name refers to (Long Names are Long).\n\n\nIt needs to be precise: you need to know what it does not refer to (Long Names are Long).\n\n\n\n\n\n\n\nOnce a name has accomplished its goal, any additional characters are redundant.\n\n\nThe following guidelines will help us write terse code that communicates intention.\n\n\nUse one word per concept\n\n\n\n&#10003; Use one word per concept.\n\n\n// Bad (three variations for the same concept: fetching accounts):\nfun fetchActiveAccount(): List&lt;Account&gt;\nfun allActiveAccounts(): List&lt;Account&gt;\nfun retrieveActiveAccountInfo(): List&lt;Account&gt;\n// Better\nfun allActiveAccounts(): List&lt;Account&gt;\n\n\n\n\n\n\n\nOmit words that are obvious given a variable‚Äôs or parameter‚Äôs type\n\n\n\n&#10003; Don&#8217;t put the type in the variable‚Äôs name\n\n\n// Bad:\nval integerId: Int\nval nameString: String\n// Better\nval id: Int\nval name: String\n\n\n\n\n&#10003; Pair Numbers and their unit (5 meter, 20 seconds, 5 ‚Ç¨) so you can never pass seconds to a method that expects milliseconds (length class in the appendix)\n\n\n// Bad:\nval lengthInMillis: Int\n// Better\nval length: Length\n\n\n\n\n&#10003; Express concepts with types and avoid stringly typed code.\n\n\n// Bad:\nclass Person constructor(val name: String, val street: String, val zipCode: String, val city: String){ /* */ }\n\n// Better:\nclass Person constructor(val name: Name, val address: Address){ /* */ }\nclass Address constructor(val street: Street, val zipCode: ZipCode, val city: City){ /* */ }\n\n\n\n\n&#10003; Name collections not by their type but what&#8217;s in them using the (forced) plural form.\n\n\n// Bad:\nval personList: List&lt;Person&gt;\nval furnitureList: List&lt;Furniture&gt;\nval dogPersonHashMap: Map&lt;Dog, Person&gt;\n// Better\nval people: List&lt;Person&gt;\nval furnitures: List&lt;Furniture&gt;\nval dogOwners: Map&lt;Dog, Person&gt;\n\n\n\n\n&#10003; Don‚Äôt add the argument name to function name. It&#8217;s redundant since our type system and IDE tell us everything we need to know.\n\n\n// Bad:\nfun mergeTableCells(cells: List&lt;TableCell&gt;)\n// Better\nfun merge(cells: List&lt;TableCell&gt;)\n\n\n\n\n\nThis also makes the call easier to read: merge(cells) vs mergeTableCells(tableCells)\n\n\n\n\n\n&#10003; Only describe the return in the name if there are identical functions that return different types.\n\n\n// Bad:\nlist.countInt()\n// Better:\nlist.count()\nmessage.valueAsInt()\nmessage.valueAsFloat()\n\n\n\n\n\n\n\nOmit words that don‚Äôt disambiguate the name\n\n\n\nTake a look at recentlyUpdatedAnnualSalesBid\n\n\n\nAre there updated annual sales bids that aren‚Äôt recent?\n\n\nAre there recent annual sales bids that were not updated?\n\n\nAre there recently updated sales bids that aren‚Äôt annual?\n\n\n\n\n\nAnd so on. We can apply such questioning to all of our names to figure out which words are just fluff, don‚Äôt disambiguate the name and should be removed.\n\n\n\n\n\nOmit words that are known from the surrounding context\n\n\n\nClass variables are in the context of their class. Class names are in the context of their component and so on.\n\n\n// Bad:\nclass AnnualHolidaySale constructor(val annualSaleRebate: Rebate){\n    fun promoteHolidaySale() { /* */ }\n}\n\n// Better:\nclass AnnualHolidaySale constructor(val rebate: Rebate){\n    fun promote() { /* */ }\n}\n\n\n\n\n\n\n\nOmit words that don‚Äôt mean much of anything\n\n\n\nWe&#8217;re looking at you manager, instance, amount, state etc.\n\n\nConnection provides exactly the same information as ConnectionManager.\n\n\nIf in doubt ask yourself ‚ÄúWould this name mean the same thing if I removed the word?‚Äù.\n\n\nNever use set-Methods. The Merriam-Webster dictionary has more than 25 definitions of the verb set. It is one of the least-precise words you can use. Consider using names that express intent and give you the ability to protect invariants.\n\n\n// Bad\ncar.setEngineState(EngineState.On)\ncar.setDestination(London)\n// Better\ncar.start()\ncar.plotCourseTo(London)\n\n\n\n\nNever use get-Methods. The Merriam-Webster dictionary has more than 15 definitions of the verb get. Name functions that just return a property and don‚Äôt change state using nouns. Using a get as prefix does not provide any meaningful additional information and is just fluff.\n\n\n// Bad\nobj.getCount()\n// Better\ndogs.count()\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\nUse one word per concept\n\n\nOmit words that are obvious given a variable‚Äôs or parameter‚Äôs type\n\n\nOmit words that don‚Äôt disambiguate the name\n\n\nOmit words that are known from the surrounding context\n\n\nOmit words that don‚Äôt mean much of anything\n\n\n\n\nI hope these guidelines provide value to you.\nMost of them are from Long Names are Long and I&#8217;ve only added little bits here and there.\n\n\n\n\nAppendix: Length class\n\n\nIt&#8217;s not hard to write a class that pairs a number and a unit.\nI&#8217;ve included an example below with lots of useful methods.\nDepending on your domain a money object can be more challenging because you do have to remember your unit and can&#8217;t convert everything to a default unit.\nPlease also not that I used integer precision for my length.\nDepending on your domain you might want to use long or BigDecimal instead.\n\n\n\n// (you can write this much shorter if you use Kotlin data classes or Java records)\nclass Length private constructor(private val rawValueInMeter: Int): Comparable&lt;Length&gt;{\n    // so that Length(4) == Length(4)\n    override fun equals(other: Any?): Boolean {\n        if(other === this) return true\n        else if(other !is Length) return false\n        else return Objects.equals(rawValueInMeter, other.rawValueInMeter)\n    }\n    // so that you can use Length in a Set or Map\n    override fun hashCode(): Int { return Objects.hash(rawValueInMeter) }\n    // for nicer debugging\n    override fun toString(): String { return \"$rawValueInMeter m\" }\n\n    // so that Length(4) &lt; Length(5)\n    override operator fun compareTo(other: Length): Int = this.rawValueInMeter.compareTo(other.rawValueInMeter)\n    // so that Length(4) + Length(5) = Length(9)\n    operator fun plus(other: Length) = Length(rawValueInMeter + other.rawValueInMeter)\n    // so that Length(8) - Length(5) = Length(3)\n    operator fun minus(other: Length) = Length(rawValueInMeter - other.rawValueInMeter)\n\n    companion object {\n        // so that you can write Length.fromMeter(4) and know the unit\n        fun fromMeter(meter: Int) = Length(meter)\n    }\n}"

    },
  
    {

      "title"    : "Contract Tests in Kotlin",
      "url"      : "/posts/Contract-Tests-in-Kotlin",
      "content"  : "I now call these tests port contract tests to differentiate them from api contract tests that verify your understanding of an api. Api contract tests are the things you write when you do consumer-driven contract testing. Before 2018 Martin Fowler used to call them integration contract tests.\n\n\n\n\n\nIn my current Kotlin project we often have two code elements that implement the same interface.\nWe have InMemoryXyzRepositories that double PostgresXyzRepositories during tests.\nWe also have a GuavaEventBus that we want to switch on when our environment does not provide a KafkaEventBus.\n\n\nHow can we be sure that both pieces of code behave the same way and continue to do so?\nThankfully we found an article on Contract Tests by J. B. Rainsberger.\n\n\nA contract test is a test were you document your understanding of the behavior of an interface.\nTo do this, you need an interface, your favorite test framework and at least one interface implementation.\n\n\nI&#8217;ll demonstrate the idea with some code.\nThe complete code can be found on Github.\n\n\n\nabstract class DogsContract { \n    protected abstract fun dogs(): Dogs \n\n    @Test\n    fun `a dog in the repo should be findable by its id`() {\n        // arrange\n        val testling = dogs()\n        val adog = Dog(DogId(\"1\"), \"Spike\")\n        testling.put(adog)\n\n        // act\n        val result = testling.findById(adog.id)\n\n        // assert\n        assertThat(result).isEqualTo(adog)\n    }\n}\n\ninterface Dogs { \n    fun put(dog: Dog)\n    fun findById(id: DogId): Dog?\n}\n\n\n\n\n\n\nCreate an abstract contact, where you document your understanding of the behavior\n\n\n\na way to get your interface implementation; the method might take parameters if you want to initialize your implementation with specific data\n\n\n\nThe interface for which you create the contract\n\n\n\n\n\n\n\n\n\n\nDogs is a repository which can be used to retrieve the domain object Dog.\nI like the convention where the name of the repository is the plural of the domain object for which it is responsible.\nThis keeps my domain clear of technical terms like Repository or Database.\n\n\n\n\n\nAfter you have written your contract, you can write the implementation and the test for the implementation:\n\n\n\nclass InMemoryDogsTest: DogsContract() {\n    override fun dogs(): Dogs { return InMemoryDogs() }\n}\n\nclass InMemoryDogs: Dogs {\n    private val dogs = ConcurrentHashMap&lt;DogId, Dog&gt;(16)\n\n    override fun put(dog: Dog) { dogs.put(dog.id, dog) }\n    override fun findById(id: DogId): Dog? { return dogs.get(id) }\n}\n\n\n\nMaven, Gradle and IntelliJ will run all implementations of DogsContract.\nThe gutter icon in IntelliJ will ask you if you want to run a specific implementation or all of them.\n\n\nI like to put the XyzContract in the same package as the interface and likewise for the XyzTest.\nIf Dogs is in src/main/de.richargh.application, then DogsContract is in src/test/de.richargh.application.\n\n\nI also like to tag my InMemoryDogsTest differently than a RemotePartnerServiceDogsTest.\nThe former gets no annotation because it&#8217;s part of my fast test suite that I want to execute before every commit.\nThe latter gets a @Tag(\"remotepartner\") because I need infrastructure outside my JVM container to run it and I will for the most part let my build pipeline do the executing.\n\n\nThe awesome part is that I can now have two or more implementations of the same interface and they will stay in sync.\nWriting these contract tests does not take much effort on my part\nand they allow me to express contract behavior the same way I express any other behavior."

    },
  

  
    {

      "title"    : "Note Placeholder",
      "url"      : "/notes/Note-Placeholder",
      "content"  : "Without this placeholder no auto-complete is generated."

    }
  
]